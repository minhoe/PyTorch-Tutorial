{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of GPUs available :  4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']=\"0,1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(' # of GPUs available : ', torch.cuda.device_count())\n",
    "\n",
    "log_interval = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR  = './results/'\n",
    "\n",
    "# Input info\n",
    "INPUT_DIR  = '../Data/'\n",
    "INPUT_DIR  = '/input/AIRLab/PaintInsReport/Output'\n",
    "INPUT_FILE = 'MODEL_EMNIST_GRAY'\n",
    "\n",
    "IS_GRAY = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading EMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n",
      "Using downloaded and verified file: ./data/extra_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# EMNIST ByClass:\t\t814,255 characters. 62 unbalanced classes.\n",
    "# SVHN 73257 digits for training, 26032 digits for testing, and 531131 additional,\n",
    "\n",
    "if IS_GRAY is 1:\n",
    "    transform_ = transforms.Compose(\n",
    "        [ transforms.Grayscale(num_output_channels=1),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\n",
    "        ])\n",
    "else:\n",
    "    transform_ = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.SVHN(root='./data', split='train',\n",
    "                                        download=True, transform=transform_)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "# print(trainloader.dataset.data.shape)\n",
    "# trainloader.dataset.data = np.expand_dims(trainloader.dataset.data[:,1,:,:], 1)\n",
    "# print(trainloader.dataset.data.shape)\n",
    "\n",
    "testset = torchvision.datasets.SVHN(root='./data', split='test',\n",
    "                                       download=True, transform=transform_)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
    "                                         shuffle=True, num_workers=4)\n",
    "\n",
    "extraset = torchvision.datasets.SVHN(root='./data', split='extra',\n",
    "                                       download=True, transform=transform_)\n",
    "extraloader = torch.utils.data.DataLoader(extraset, batch_size=256,\n",
    "                                         shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Dataset size :  (73257, 3, 32, 32)\n",
      " Training Label size   :  (73257,)\n",
      " Testing Dataset size :  (26032, 3, 32, 32)\n",
      " Testing Label size   :  (26032,)\n",
      " Extra Dataset size :  (531131, 3, 32, 32)\n",
      " EXtra Label size   :  (531131,)\n"
     ]
    }
   ],
   "source": [
    "print(' Training Dataset size : ', trainloader.dataset.data.shape)\n",
    "print(' Training Label size   : ', trainloader.dataset.labels.shape)\n",
    "\n",
    "print(' Testing Dataset size : ', testloader.dataset.data.shape)\n",
    "print(' Testing Label size   : ', testloader.dataset.labels.shape)\n",
    "\n",
    "print(' Extra Dataset size : ', extraloader.dataset.data.shape)\n",
    "print(' EXtra Label size   : ', extraloader.dataset.labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9     8     3     8     1     1     4     7     7     1     4     7     2     8     5     5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j].item() for j in range(16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "        \n",
    "#         # Layer 1\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 3) # 28x28 -> 26x26  /40x40 -> 38x38 / 60x60 -> 58x58 / 80x80 -> 78x78 / 100x100 -> 98x98\n",
    "#         self.b1    = nn.BatchNorm2d(16)\n",
    "#         self.pool  = nn.MaxPool2d(2, 2)  # 26x26 -> 13x13  /38x38 -> 19x19 / 58x58 -> 29x29 / 78x78 -> 39x39 / 98x98 -> 49x49\n",
    "        \n",
    "#         # Layer 2\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 3)  # 13x13 -> 11x11 /19x19 -> 17x17 / 29x29 -> 27x27 / 39x39 -> 37x37 / 49x49 -> 47x47\n",
    "#         self.b2    = nn.BatchNorm2d(32)\n",
    "#         #self.pool                          # 11x11 -> 5x5  /17x17 -> 8x8 / 27x27 -> 13x13 / 37x37 -> 18x18 / 47x47 -> 23x23\n",
    "        \n",
    "#         # Layer 3\n",
    "#         self.conv3 = nn.Conv2d(32, 64, 3) # 5x5 -> 3x3  / 8x8 -> 6x6 / 13x13 -> 11x11 / 18x18 -> 16x16 / 23x23 -> 21x21\n",
    "#         self.b3    = nn.BatchNorm2d(64)\n",
    "#         #self.pool                          # 3x3 -> 1x1  /6x6 -> 3x3 / 11x11 -> 5x5 / 16x16 -> 8x8 / 21x21 -> 10x10\n",
    "        \n",
    "#         # FC Layers\n",
    "#         self.fc1 = nn.Linear(64 * 1 * 1, 256)\n",
    "#         self.bf1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "#         self.bf2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "#         self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "       \n",
    "#         # Layer 1\n",
    "#         x = self.pool(F.relu(self.b1(self.conv1(x))))\n",
    "        \n",
    "#         # Layer 2\n",
    "#         x = self.pool(F.relu(self.b2(self.conv2(x))))\n",
    "        \n",
    "#         # Layer 3\n",
    "#         x = self.pool(F.relu(self.b3(self.conv3(x))))\n",
    "        \n",
    "#         # Flatten tensors\n",
    "#         x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "#         # FC Layer 1\n",
    "#         x = F.relu(self.bf1(self.fc1(x)))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "        \n",
    "#         # FC Layer 2\n",
    "#         x = F.relu(self.bf2(self.fc2(x)))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "        \n",
    "#         # FC Layer 3\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "#     def num_flat_features(self, x):\n",
    "#         size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "#         num_features = 1\n",
    "#         for s in size:\n",
    "#             num_features *= s\n",
    "#         return num_features\n",
    "\n",
    "# net = Net()\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#     net = nn.DataParallel(net)\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n",
      "DataParallel(\n",
      "  (module): Net(\n",
      "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (b1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (b2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (b3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (bf1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (bf2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3) # 32x32 -> 30x30 / 28x28 -> 26x26  /40x40 -> 38x38 / 60x60 -> 58x58 / 80x80 -> 78x78 / 100x100 -> 98x98\n",
    "        self.b1    = nn.BatchNorm2d(16)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)  # 30x30 -> 15x15 / 26x26 -> 13x13  /38x38 -> 19x19 / 58x58 -> 29x29 / 78x78 -> 39x39 / 98x98 -> 49x49\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)  # 15x15 -> 13x13 / 13x13 -> 11x11 /19x19 -> 17x17 / 29x29 -> 27x27 / 39x39 -> 37x37 / 49x49 -> 47x47\n",
    "        self.b2    = nn.BatchNorm2d(32)\n",
    "        #self.pool                       # 13x13 -> 6x6 / 11x11 -> 5x5  /17x17 -> 8x8 / 27x27 -> 13x13 / 37x37 -> 18x18 / 47x47 -> 23x23\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3) # 6x6 -> 4x4 / 5x5 -> 3x3  / 8x8 -> 6x6 / 13x13 -> 11x11 / 18x18 -> 16x16 / 23x23 -> 21x21\n",
    "        self.b3    = nn.BatchNorm2d(64)\n",
    "        #self.pool                        # 4x4 -> 2x2 / 3x3 -> 1x1  /6x6 -> 3x3 / 11x11 -> 5x5 / 16x16 -> 8x8 / 21x21 -> 10x10\n",
    "        \n",
    "        # FC Layers\n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 256)\n",
    "        self.bf1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bf2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        # Layer 1\n",
    "        x = self.pool(F.relu(self.b1(self.conv1(x))))\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.pool(F.relu(self.b2(self.conv2(x))))\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.pool(F.relu(self.b3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten tensors\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        # FC Layer 1\n",
    "        x = F.relu(self.bf1(self.fc1(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # FC Layer 2\n",
    "        x = F.relu(self.bf2(self.fc2(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # FC Layer 3\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, dataloader):\n",
    "    net.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0.0\n",
    "    \n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # For Multi-gpu processing\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        net.train(True) # Set to Train mode\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Training Accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()    \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % log_interval == 0:    # print every 200 mini-batches\n",
    "            print('Train Epoch : %2d [%6d, %6d] loss: %.3f TrnAcc: %.3f' %\n",
    "                  (epoch, total, len(dataloader.dataset), running_loss / log_interval, correct / total))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    # Calculate Validation Accuracy\n",
    "    total_eval = 0\n",
    "    correct_eval = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images_eval, labels_eval in testloader:\n",
    "            images_eval, labels_eval = images_eval.to(device), labels_eval.to(device)\n",
    "            outputs_eval = net(images_eval)\n",
    "            _, predicted_eval = torch.max(outputs_eval.data, 1)\n",
    "            total_eval += labels_eval.size(0)\n",
    "            correct_eval += (predicted_eval == labels_eval).sum().item() \n",
    "    val_acc = correct_eval / total_eval\n",
    "    print('Test | Size : %6d  | ValAcc: %.3f\\n' %\n",
    "          (len(testloader.dataset), val_acc))\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | Size :  26032  | ValAcc: 0.064\n",
      "\n",
      "Train Epoch :  0 [   256,  73257] loss: 0.012 TrnAcc: 0.082\n",
      "Train Epoch :  0 [ 51456,  73257] loss: 1.373 TrnAcc: 0.550\n",
      "Train Epoch :  0 [   256, 531131] loss: 0.002 TrnAcc: 0.875\n",
      "Train Epoch :  0 [ 51456, 531131] loss: 0.374 TrnAcc: 0.892\n",
      "Train Epoch :  0 [102656, 531131] loss: 0.301 TrnAcc: 0.903\n",
      "Train Epoch :  0 [153856, 531131] loss: 0.263 TrnAcc: 0.910\n",
      "Train Epoch :  0 [205056, 531131] loss: 0.245 TrnAcc: 0.915\n",
      "Train Epoch :  0 [256256, 531131] loss: 0.224 TrnAcc: 0.919\n",
      "Train Epoch :  0 [307456, 531131] loss: 0.210 TrnAcc: 0.923\n",
      "Train Epoch :  0 [358656, 531131] loss: 0.198 TrnAcc: 0.926\n",
      "Train Epoch :  0 [409856, 531131] loss: 0.192 TrnAcc: 0.928\n",
      "Train Epoch :  0 [461056, 531131] loss: 0.180 TrnAcc: 0.930\n",
      "Train Epoch :  0 [512256, 531131] loss: 0.177 TrnAcc: 0.932\n",
      "Test | Size :  26032  | ValAcc: 0.918\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [0] \u001b[0m\n",
      "Train Epoch :  1 [   256,  73257] loss: 0.002 TrnAcc: 0.867\n",
      "Train Epoch :  1 [ 51456,  73257] loss: 0.395 TrnAcc: 0.888\n",
      "Train Epoch :  1 [   256, 531131] loss: 0.001 TrnAcc: 0.941\n",
      "Train Epoch :  1 [ 51456, 531131] loss: 0.171 TrnAcc: 0.952\n",
      "Train Epoch :  1 [102656, 531131] loss: 0.156 TrnAcc: 0.954\n",
      "Train Epoch :  1 [153856, 531131] loss: 0.156 TrnAcc: 0.955\n",
      "Train Epoch :  1 [205056, 531131] loss: 0.155 TrnAcc: 0.956\n",
      "Train Epoch :  1 [256256, 531131] loss: 0.151 TrnAcc: 0.956\n",
      "Train Epoch :  1 [307456, 531131] loss: 0.153 TrnAcc: 0.956\n",
      "Train Epoch :  1 [358656, 531131] loss: 0.147 TrnAcc: 0.957\n",
      "Train Epoch :  1 [409856, 531131] loss: 0.143 TrnAcc: 0.957\n",
      "Train Epoch :  1 [461056, 531131] loss: 0.147 TrnAcc: 0.957\n",
      "Train Epoch :  1 [512256, 531131] loss: 0.143 TrnAcc: 0.958\n",
      "Test | Size :  26032  | ValAcc: 0.937\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [1] \u001b[0m\n",
      "Train Epoch :  2 [   256,  73257] loss: 0.001 TrnAcc: 0.906\n",
      "Train Epoch :  2 [ 51456,  73257] loss: 0.355 TrnAcc: 0.901\n",
      "Train Epoch :  2 [   256, 531131] loss: 0.001 TrnAcc: 0.949\n",
      "Train Epoch :  2 [ 51456, 531131] loss: 0.148 TrnAcc: 0.960\n",
      "Train Epoch :  2 [102656, 531131] loss: 0.134 TrnAcc: 0.961\n",
      "Train Epoch :  2 [153856, 531131] loss: 0.138 TrnAcc: 0.961\n",
      "Train Epoch :  2 [205056, 531131] loss: 0.129 TrnAcc: 0.961\n",
      "Train Epoch :  2 [256256, 531131] loss: 0.130 TrnAcc: 0.962\n",
      "Train Epoch :  2 [307456, 531131] loss: 0.133 TrnAcc: 0.962\n",
      "Train Epoch :  2 [358656, 531131] loss: 0.133 TrnAcc: 0.962\n",
      "Train Epoch :  2 [409856, 531131] loss: 0.135 TrnAcc: 0.962\n",
      "Train Epoch :  2 [461056, 531131] loss: 0.130 TrnAcc: 0.963\n",
      "Train Epoch :  2 [512256, 531131] loss: 0.131 TrnAcc: 0.963\n",
      "Test | Size :  26032  | ValAcc: 0.942\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [2] \u001b[0m\n",
      "Train Epoch :  3 [   256,  73257] loss: 0.001 TrnAcc: 0.922\n",
      "Train Epoch :  3 [ 51456,  73257] loss: 0.330 TrnAcc: 0.908\n",
      "Train Epoch :  3 [   256, 531131] loss: 0.001 TrnAcc: 0.969\n",
      "Train Epoch :  3 [ 51456, 531131] loss: 0.129 TrnAcc: 0.965\n",
      "Train Epoch :  3 [102656, 531131] loss: 0.125 TrnAcc: 0.965\n",
      "Train Epoch :  3 [153856, 531131] loss: 0.126 TrnAcc: 0.965\n",
      "Train Epoch :  3 [205056, 531131] loss: 0.124 TrnAcc: 0.965\n",
      "Train Epoch :  3 [256256, 531131] loss: 0.121 TrnAcc: 0.966\n",
      "Train Epoch :  3 [307456, 531131] loss: 0.125 TrnAcc: 0.966\n",
      "Train Epoch :  3 [358656, 531131] loss: 0.121 TrnAcc: 0.966\n",
      "Train Epoch :  3 [409856, 531131] loss: 0.122 TrnAcc: 0.966\n",
      "Train Epoch :  3 [461056, 531131] loss: 0.116 TrnAcc: 0.966\n",
      "Train Epoch :  3 [512256, 531131] loss: 0.119 TrnAcc: 0.966\n",
      "Test | Size :  26032  | ValAcc: 0.946\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [3] \u001b[0m\n",
      "Train Epoch :  4 [   256,  73257] loss: 0.002 TrnAcc: 0.910\n",
      "Train Epoch :  4 [ 51456,  73257] loss: 0.320 TrnAcc: 0.910\n",
      "Train Epoch :  4 [   256, 531131] loss: 0.001 TrnAcc: 0.969\n",
      "Train Epoch :  4 [ 51456, 531131] loss: 0.122 TrnAcc: 0.966\n",
      "Train Epoch :  4 [102656, 531131] loss: 0.116 TrnAcc: 0.967\n",
      "Train Epoch :  4 [153856, 531131] loss: 0.115 TrnAcc: 0.968\n",
      "Train Epoch :  4 [205056, 531131] loss: 0.117 TrnAcc: 0.968\n",
      "Train Epoch :  4 [256256, 531131] loss: 0.118 TrnAcc: 0.968\n",
      "Train Epoch :  4 [307456, 531131] loss: 0.113 TrnAcc: 0.968\n",
      "Train Epoch :  4 [358656, 531131] loss: 0.113 TrnAcc: 0.968\n",
      "Train Epoch :  4 [409856, 531131] loss: 0.119 TrnAcc: 0.968\n",
      "Train Epoch :  4 [461056, 531131] loss: 0.116 TrnAcc: 0.968\n",
      "Train Epoch :  4 [512256, 531131] loss: 0.110 TrnAcc: 0.968\n",
      "Test | Size :  26032  | ValAcc: 0.947\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [4] \u001b[0m\n",
      "Train Epoch :  5 [   256,  73257] loss: 0.001 TrnAcc: 0.922\n",
      "Train Epoch :  5 [ 51456,  73257] loss: 0.302 TrnAcc: 0.916\n",
      "Train Epoch :  5 [   256, 531131] loss: 0.001 TrnAcc: 0.977\n",
      "Train Epoch :  5 [ 51456, 531131] loss: 0.115 TrnAcc: 0.969\n",
      "Train Epoch :  5 [102656, 531131] loss: 0.109 TrnAcc: 0.970\n",
      "Train Epoch :  5 [153856, 531131] loss: 0.107 TrnAcc: 0.970\n",
      "Train Epoch :  5 [205056, 531131] loss: 0.113 TrnAcc: 0.970\n",
      "Train Epoch :  5 [256256, 531131] loss: 0.117 TrnAcc: 0.969\n",
      "Train Epoch :  5 [307456, 531131] loss: 0.111 TrnAcc: 0.969\n",
      "Train Epoch :  5 [358656, 531131] loss: 0.111 TrnAcc: 0.969\n",
      "Train Epoch :  5 [409856, 531131] loss: 0.109 TrnAcc: 0.969\n",
      "Train Epoch :  5 [461056, 531131] loss: 0.110 TrnAcc: 0.970\n",
      "Train Epoch :  5 [512256, 531131] loss: 0.113 TrnAcc: 0.970\n",
      "Test | Size :  26032  | ValAcc: 0.949\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [5] \u001b[0m\n",
      "Train Epoch :  6 [   256,  73257] loss: 0.002 TrnAcc: 0.914\n",
      "Train Epoch :  6 [ 51456,  73257] loss: 0.297 TrnAcc: 0.918\n",
      "Train Epoch :  6 [   256, 531131] loss: 0.001 TrnAcc: 0.969\n",
      "Train Epoch :  6 [ 51456, 531131] loss: 0.116 TrnAcc: 0.967\n",
      "Train Epoch :  6 [102656, 531131] loss: 0.100 TrnAcc: 0.970\n",
      "Train Epoch :  6 [153856, 531131] loss: 0.109 TrnAcc: 0.970\n",
      "Train Epoch :  6 [205056, 531131] loss: 0.103 TrnAcc: 0.971\n",
      "Train Epoch :  6 [256256, 531131] loss: 0.101 TrnAcc: 0.971\n",
      "Train Epoch :  6 [307456, 531131] loss: 0.104 TrnAcc: 0.971\n",
      "Train Epoch :  6 [358656, 531131] loss: 0.111 TrnAcc: 0.971\n",
      "Train Epoch :  6 [409856, 531131] loss: 0.103 TrnAcc: 0.971\n",
      "Train Epoch :  6 [461056, 531131] loss: 0.111 TrnAcc: 0.971\n",
      "Train Epoch :  6 [512256, 531131] loss: 0.111 TrnAcc: 0.971\n",
      "Test | Size :  26032  | ValAcc: 0.948\n",
      "\n",
      "Train Epoch :  7 [   256,  73257] loss: 0.001 TrnAcc: 0.914\n",
      "Train Epoch :  7 [ 51456,  73257] loss: 0.292 TrnAcc: 0.919\n",
      "Train Epoch :  7 [   256, 531131] loss: 0.001 TrnAcc: 0.961\n",
      "Train Epoch :  7 [ 51456, 531131] loss: 0.102 TrnAcc: 0.972\n",
      "Train Epoch :  7 [102656, 531131] loss: 0.103 TrnAcc: 0.972\n",
      "Train Epoch :  7 [153856, 531131] loss: 0.105 TrnAcc: 0.972\n",
      "Train Epoch :  7 [205056, 531131] loss: 0.104 TrnAcc: 0.972\n",
      "Train Epoch :  7 [256256, 531131] loss: 0.104 TrnAcc: 0.972\n",
      "Train Epoch :  7 [307456, 531131] loss: 0.106 TrnAcc: 0.972\n",
      "Train Epoch :  7 [358656, 531131] loss: 0.104 TrnAcc: 0.972\n",
      "Train Epoch :  7 [409856, 531131] loss: 0.104 TrnAcc: 0.972\n",
      "Train Epoch :  7 [461056, 531131] loss: 0.105 TrnAcc: 0.972\n",
      "Train Epoch :  7 [512256, 531131] loss: 0.100 TrnAcc: 0.972\n",
      "Test | Size :  26032  | ValAcc: 0.950\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [7] \u001b[0m\n",
      "Train Epoch :  8 [   256,  73257] loss: 0.002 TrnAcc: 0.910\n",
      "Train Epoch :  8 [ 51456,  73257] loss: 0.282 TrnAcc: 0.922\n",
      "Train Epoch :  8 [   256, 531131] loss: 0.001 TrnAcc: 0.961\n",
      "Train Epoch :  8 [ 51456, 531131] loss: 0.106 TrnAcc: 0.971\n",
      "Train Epoch :  8 [102656, 531131] loss: 0.099 TrnAcc: 0.972\n",
      "Train Epoch :  8 [153856, 531131] loss: 0.101 TrnAcc: 0.972\n",
      "Train Epoch :  8 [205056, 531131] loss: 0.098 TrnAcc: 0.972\n",
      "Train Epoch :  8 [256256, 531131] loss: 0.102 TrnAcc: 0.972\n",
      "Train Epoch :  8 [307456, 531131] loss: 0.101 TrnAcc: 0.972\n",
      "Train Epoch :  8 [358656, 531131] loss: 0.098 TrnAcc: 0.972\n",
      "Train Epoch :  8 [409856, 531131] loss: 0.104 TrnAcc: 0.972\n",
      "Train Epoch :  8 [461056, 531131] loss: 0.099 TrnAcc: 0.972\n",
      "Train Epoch :  8 [512256, 531131] loss: 0.102 TrnAcc: 0.972\n",
      "Test | Size :  26032  | ValAcc: 0.951\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [8] \u001b[0m\n",
      "Train Epoch :  9 [   256,  73257] loss: 0.001 TrnAcc: 0.938\n",
      "Train Epoch :  9 [ 51456,  73257] loss: 0.278 TrnAcc: 0.922\n",
      "Train Epoch :  9 [   256, 531131] loss: 0.001 TrnAcc: 0.957\n",
      "Train Epoch :  9 [ 51456, 531131] loss: 0.102 TrnAcc: 0.972\n",
      "Train Epoch :  9 [102656, 531131] loss: 0.099 TrnAcc: 0.973\n",
      "Train Epoch :  9 [153856, 531131] loss: 0.098 TrnAcc: 0.973\n",
      "Train Epoch :  9 [205056, 531131] loss: 0.099 TrnAcc: 0.973\n",
      "Train Epoch :  9 [256256, 531131] loss: 0.099 TrnAcc: 0.973\n",
      "Train Epoch :  9 [307456, 531131] loss: 0.099 TrnAcc: 0.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch :  9 [358656, 531131] loss: 0.096 TrnAcc: 0.973\n",
      "Train Epoch :  9 [409856, 531131] loss: 0.102 TrnAcc: 0.973\n",
      "Train Epoch :  9 [461056, 531131] loss: 0.093 TrnAcc: 0.973\n",
      "Train Epoch :  9 [512256, 531131] loss: 0.100 TrnAcc: 0.973\n",
      "Test | Size :  26032  | ValAcc: 0.951\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [9] \u001b[0m\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "test() # Show initial performance\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    train(epoch, trainloader)\n",
    "    train(epoch, extraloader)\n",
    "    val_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        # Save model\n",
    "        net.train()\n",
    "#         torch.save(net.module.state_dict(), './results/model_190314.pth')\n",
    "#         torch.save(optimizer.state_dict(), './results/optimizer_190314.pth')\n",
    "        torch.save({\n",
    "                    'epoch': best_epoch,\n",
    "                    'model_state_dict': net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_acc': best_val_acc\n",
    "                    }, \n",
    "                    './results/model_190314.pth')        \n",
    "        \n",
    "        print (\"\\x1b[31m BEST EPOCH UPDATED!! [%d] \\x1b[0m\" % (best_epoch))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "module.conv1.weight \t torch.Size([16, 3, 3, 3])\n",
      "module.conv1.bias \t torch.Size([16])\n",
      "module.b1.weight \t torch.Size([16])\n",
      "module.b1.bias \t torch.Size([16])\n",
      "module.b1.running_mean \t torch.Size([16])\n",
      "module.b1.running_var \t torch.Size([16])\n",
      "module.b1.num_batches_tracked \t torch.Size([])\n",
      "module.conv2.weight \t torch.Size([32, 16, 3, 3])\n",
      "module.conv2.bias \t torch.Size([32])\n",
      "module.b2.weight \t torch.Size([32])\n",
      "module.b2.bias \t torch.Size([32])\n",
      "module.b2.running_mean \t torch.Size([32])\n",
      "module.b2.running_var \t torch.Size([32])\n",
      "module.b2.num_batches_tracked \t torch.Size([])\n",
      "module.conv3.weight \t torch.Size([64, 32, 3, 3])\n",
      "module.conv3.bias \t torch.Size([64])\n",
      "module.b3.weight \t torch.Size([64])\n",
      "module.b3.bias \t torch.Size([64])\n",
      "module.b3.running_mean \t torch.Size([64])\n",
      "module.b3.running_var \t torch.Size([64])\n",
      "module.b3.num_batches_tracked \t torch.Size([])\n",
      "module.fc1.weight \t torch.Size([256, 256])\n",
      "module.fc1.bias \t torch.Size([256])\n",
      "module.bf1.weight \t torch.Size([256])\n",
      "module.bf1.bias \t torch.Size([256])\n",
      "module.bf1.running_mean \t torch.Size([256])\n",
      "module.bf1.running_var \t torch.Size([256])\n",
      "module.bf1.num_batches_tracked \t torch.Size([])\n",
      "module.fc2.weight \t torch.Size([128, 256])\n",
      "module.fc2.bias \t torch.Size([128])\n",
      "module.bf2.weight \t torch.Size([128])\n",
      "module.bf2.bias \t torch.Size([128])\n",
      "module.bf2.running_mean \t torch.Size([128])\n",
      "module.bf2.running_var \t torch.Size([128])\n",
      "module.bf2.num_batches_tracked \t torch.Size([])\n",
      "module.fc3.weight \t torch.Size([10, 128])\n",
      "module.fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {140402548532784: {'step': 23620, 'exp_avg': tensor([[[[ 1.6396e-03, -3.9467e-04, -7.5014e-05],\n",
      "          [ 2.0531e-03, -3.2381e-04,  2.2919e-04],\n",
      "          [ 1.6603e-03, -3.7165e-04, -3.1738e-05]],\n",
      "\n",
      "         [[ 2.3146e-03, -8.8156e-05,  5.7628e-04],\n",
      "          [ 2.9299e-03,  1.9066e-04,  1.2242e-03],\n",
      "          [ 3.0732e-03,  6.4943e-04,  1.4500e-03]],\n",
      "\n",
      "         [[-8.3960e-04, -3.5545e-03, -3.6439e-03],\n",
      "          [-5.6476e-04, -3.6526e-03, -3.4634e-03],\n",
      "          [-8.6095e-04, -3.5146e-03, -3.3958e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3633e-04,  1.2503e-04, -1.9259e-04],\n",
      "          [ 7.1067e-04,  1.0391e-04, -1.8660e-04],\n",
      "          [ 6.1101e-04,  7.7236e-05, -1.6269e-04]],\n",
      "\n",
      "         [[ 1.4184e-03,  7.5519e-04,  3.5044e-04],\n",
      "          [ 1.3941e-03,  7.1928e-04,  3.1788e-04],\n",
      "          [ 1.1754e-03,  6.1249e-04,  2.4449e-04]],\n",
      "\n",
      "         [[ 1.3213e-03,  7.3357e-04,  3.5442e-04],\n",
      "          [ 1.3125e-03,  6.8368e-04,  3.3311e-04],\n",
      "          [ 1.1541e-03,  5.8666e-04,  2.3616e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1639e-03,  2.6496e-03,  1.7264e-03],\n",
      "          [ 5.9375e-03,  5.0730e-03,  4.3085e-03],\n",
      "          [ 9.0698e-03,  8.9370e-03,  8.7650e-03]],\n",
      "\n",
      "         [[-1.8942e-03, -3.7113e-03, -4.5856e-03],\n",
      "          [ 7.0279e-05, -8.7507e-04, -1.5433e-03],\n",
      "          [ 4.1272e-03,  3.9264e-03,  4.1343e-03]],\n",
      "\n",
      "         [[-2.0607e-03, -3.7277e-03, -3.8181e-03],\n",
      "          [-3.4100e-04, -1.2036e-03, -1.3082e-03],\n",
      "          [ 3.3099e-03,  3.0124e-03,  3.3189e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3550e-04,  2.0766e-04,  1.6913e-04],\n",
      "          [ 2.4716e-05,  1.2126e-04,  1.3922e-04],\n",
      "          [-1.0157e-04,  1.3798e-05,  6.1018e-05]],\n",
      "\n",
      "         [[ 1.8267e-04,  2.4031e-04,  2.1220e-04],\n",
      "          [ 8.6023e-05,  1.7061e-04,  2.0024e-04],\n",
      "          [-6.9255e-06,  8.8541e-05,  1.4825e-04]],\n",
      "\n",
      "         [[ 2.8693e-04,  3.1903e-04,  2.8705e-04],\n",
      "          [ 1.7938e-04,  2.2880e-04,  2.7055e-04],\n",
      "          [ 9.3199e-05,  1.6391e-04,  2.1767e-04]]],\n",
      "\n",
      "\n",
      "        [[[-8.9150e-05, -1.6400e-04, -7.1922e-04],\n",
      "          [ 2.2832e-04,  3.9902e-04,  1.0645e-04],\n",
      "          [ 3.7843e-04,  8.0869e-04,  1.2931e-03]],\n",
      "\n",
      "         [[-7.7836e-04, -6.1833e-04, -1.2842e-03],\n",
      "          [-3.0235e-04, -1.6568e-06, -3.5788e-04],\n",
      "          [-1.5668e-04,  4.6747e-04,  6.6223e-04]],\n",
      "\n",
      "         [[ 7.4860e-04,  2.2272e-04, -8.8992e-04],\n",
      "          [ 1.0547e-03,  8.4532e-04,  1.9734e-04],\n",
      "          [ 1.4019e-03,  1.4941e-03,  1.4284e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4573e-05,  3.9615e-05, -6.0816e-05],\n",
      "          [-1.6910e-04, -1.8199e-05,  1.0577e-04],\n",
      "          [-2.0061e-04,  6.2764e-06,  2.7009e-04]],\n",
      "\n",
      "         [[ 6.2358e-05,  1.9053e-05, -9.0021e-05],\n",
      "          [-1.6676e-04, -4.1163e-05,  7.3778e-05],\n",
      "          [-2.2415e-04, -1.7680e-05,  2.4747e-04]],\n",
      "\n",
      "         [[-2.3630e-04, -2.0577e-04, -1.8464e-04],\n",
      "          [-4.6809e-04, -2.9980e-04, -6.2636e-05],\n",
      "          [-5.4648e-04, -2.9900e-04,  8.6594e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1884e-03,  5.2817e-03,  6.4236e-03],\n",
      "          [ 5.4690e-03,  5.5766e-03,  6.3286e-03],\n",
      "          [ 5.0174e-03,  5.5024e-03,  6.2218e-03]],\n",
      "\n",
      "         [[ 6.0072e-03,  6.3139e-03,  7.3526e-03],\n",
      "          [ 6.6294e-03,  6.7286e-03,  7.2687e-03],\n",
      "          [ 6.0677e-03,  7.0460e-03,  7.5236e-03]],\n",
      "\n",
      "         [[ 8.5621e-03,  8.0964e-03,  8.1339e-03],\n",
      "          [ 8.8380e-03,  8.1023e-03,  7.8985e-03],\n",
      "          [ 7.9587e-03,  8.0535e-03,  7.8471e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9732e-03,  3.9148e-03,  3.6080e-03],\n",
      "          [ 2.5374e-03,  3.6430e-03,  3.2462e-03],\n",
      "          [ 1.3714e-03,  2.2749e-03,  2.6024e-03]],\n",
      "\n",
      "         [[ 2.8509e-03,  3.7743e-03,  3.3448e-03],\n",
      "          [ 2.5030e-03,  3.7223e-03,  3.2260e-03],\n",
      "          [ 1.5662e-03,  2.6319e-03,  2.6931e-03]],\n",
      "\n",
      "         [[ 3.6740e-03,  4.0878e-03,  3.1189e-03],\n",
      "          [ 3.3000e-03,  3.8465e-03,  2.8448e-03],\n",
      "          [ 2.3397e-03,  2.7692e-03,  2.2393e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.3524e-03, -3.6943e-03, -3.1449e-03],\n",
      "          [-3.4006e-03, -2.4880e-03, -2.9012e-03],\n",
      "          [-2.9485e-03, -1.6831e-03, -3.2257e-03]],\n",
      "\n",
      "         [[-6.1428e-03, -5.3777e-03, -4.9429e-03],\n",
      "          [-5.4544e-03, -4.5927e-03, -5.2897e-03],\n",
      "          [-5.3115e-03, -4.5513e-03, -6.0698e-03]],\n",
      "\n",
      "         [[-3.3005e-04,  1.4481e-03,  3.2091e-03],\n",
      "          [ 5.7370e-04,  2.4381e-03,  3.1649e-03],\n",
      "          [ 8.6330e-04,  2.6195e-03,  2.2120e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.7594e-03, -3.1724e-03, -3.0656e-03],\n",
      "          [-3.1412e-03, -2.5727e-03, -2.6315e-03],\n",
      "          [-3.5005e-03, -2.9388e-03, -1.9722e-03]],\n",
      "\n",
      "         [[-4.6886e-03, -4.3056e-03, -4.2435e-03],\n",
      "          [-4.2374e-03, -3.9019e-03, -4.2544e-03],\n",
      "          [-4.7197e-03, -4.4482e-03, -3.7489e-03]],\n",
      "\n",
      "         [[-7.2875e-03, -6.9549e-03, -7.2152e-03],\n",
      "          [-6.2712e-03, -6.0457e-03, -6.6885e-03],\n",
      "          [-6.4538e-03, -6.3578e-03, -6.1515e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3299e-04,  1.8222e-04,  3.7148e-04],\n",
      "          [ 3.1474e-05,  1.5600e-04,  3.7947e-04],\n",
      "          [-9.2694e-05,  7.7475e-05,  3.2151e-04]],\n",
      "\n",
      "         [[ 4.3499e-05,  6.6885e-05,  2.2293e-04],\n",
      "          [-4.3015e-05,  5.9754e-05,  2.3848e-04],\n",
      "          [-1.8042e-04, -3.3697e-05,  1.8058e-04]],\n",
      "\n",
      "         [[ 1.3707e-04,  1.8111e-04,  3.4615e-04],\n",
      "          [ 7.6118e-05,  1.9144e-04,  3.8034e-04],\n",
      "          [-2.7364e-05,  1.2979e-04,  3.3146e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.1187e-03, -3.5255e-03, -3.7806e-03],\n",
      "          [-4.2581e-03, -4.1768e-03, -3.9842e-03],\n",
      "          [-3.9824e-03, -4.3019e-03, -4.5180e-03]],\n",
      "\n",
      "         [[-1.9529e-03, -2.7507e-03, -3.0936e-03],\n",
      "          [-2.7430e-03, -3.1997e-03, -3.1658e-03],\n",
      "          [-2.2494e-03, -3.1024e-03, -3.5345e-03]],\n",
      "\n",
      "         [[-8.2327e-04, -1.4270e-03, -1.7742e-03],\n",
      "          [-1.7829e-03, -2.0917e-03, -2.1021e-03],\n",
      "          [-1.4049e-03, -2.0547e-03, -2.4476e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2472e-02, -1.0431e-02, -8.6417e-03],\n",
      "          [-1.0425e-02, -9.6289e-03, -9.0905e-03],\n",
      "          [-8.2799e-03, -8.0898e-03, -9.5559e-03]],\n",
      "\n",
      "         [[-9.9261e-03, -7.1870e-03, -4.2122e-03],\n",
      "          [-7.5795e-03, -6.3098e-03, -5.5391e-03],\n",
      "          [-5.6824e-03, -5.8709e-03, -7.1361e-03]],\n",
      "\n",
      "         [[ 1.2073e-03,  2.7735e-03,  5.0090e-03],\n",
      "          [ 2.7675e-03,  3.4212e-03,  4.1695e-03],\n",
      "          [ 3.2077e-03,  3.3823e-03,  2.4571e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1201e-04,  6.3389e-04,  6.1393e-04],\n",
      "          [ 4.0567e-04,  5.9443e-04,  5.9558e-04],\n",
      "          [ 2.8787e-04,  5.1255e-04,  5.7626e-04]],\n",
      "\n",
      "         [[ 2.6502e-04,  3.6802e-04,  3.2964e-04],\n",
      "          [ 1.6187e-04,  3.4503e-04,  3.3266e-04],\n",
      "          [ 2.5928e-05,  2.3727e-04,  3.1602e-04]],\n",
      "\n",
      "         [[ 5.8805e-04,  7.2238e-04,  7.5748e-04],\n",
      "          [ 5.0461e-04,  6.9803e-04,  7.5035e-04],\n",
      "          [ 3.7341e-04,  6.0596e-04,  7.2960e-04]]],\n",
      "\n",
      "\n",
      "        [[[-8.4708e-05, -6.2474e-05, -1.1265e-04],\n",
      "          [-3.2418e-05, -1.3044e-05, -6.1529e-05],\n",
      "          [ 7.8416e-06,  3.4773e-05, -1.1724e-05]],\n",
      "\n",
      "         [[-1.0642e-04, -7.6342e-05, -1.3007e-04],\n",
      "          [-6.4767e-05, -4.1970e-05, -8.9434e-05],\n",
      "          [-2.8650e-05, -1.1797e-06, -5.1204e-05]],\n",
      "\n",
      "         [[-1.1894e-04, -9.6395e-05, -1.5026e-04],\n",
      "          [-7.7324e-05, -5.6473e-05, -1.0444e-04],\n",
      "          [-4.5954e-05, -1.9915e-05, -6.7281e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5185e-03,  5.3384e-03,  4.4255e-04],\n",
      "          [ 5.8153e-03,  6.2074e-03,  1.2938e-03],\n",
      "          [ 4.7307e-03,  5.0869e-03,  1.5318e-04]],\n",
      "\n",
      "         [[ 4.3417e-03,  4.8273e-03, -3.5215e-04],\n",
      "          [ 5.0645e-03,  4.8159e-03, -6.6576e-04],\n",
      "          [ 2.4723e-03,  2.2110e-03, -2.5440e-03]],\n",
      "\n",
      "         [[-1.5254e-03, -1.4576e-03, -6.3634e-03],\n",
      "          [-3.4362e-04, -7.6194e-04, -5.6898e-03],\n",
      "          [-1.9799e-03, -2.2640e-03, -6.7730e-03]]]], device='cuda:0'), 'exp_avg_sq': tensor([[[[2.2413e-03, 2.3241e-03, 2.4494e-03],\n",
      "          [2.3408e-03, 2.3761e-03, 2.4283e-03],\n",
      "          [2.4194e-03, 2.3916e-03, 2.3673e-03]],\n",
      "\n",
      "         [[2.4265e-03, 2.4970e-03, 2.6201e-03],\n",
      "          [2.5358e-03, 2.5540e-03, 2.6040e-03],\n",
      "          [2.6079e-03, 2.5705e-03, 2.5440e-03]],\n",
      "\n",
      "         [[2.7163e-03, 2.7734e-03, 2.8925e-03],\n",
      "          [2.8162e-03, 2.8298e-03, 2.8860e-03],\n",
      "          [2.8798e-03, 2.8489e-03, 2.8409e-03]]],\n",
      "\n",
      "\n",
      "        [[[3.2085e-05, 2.2768e-05, 1.7901e-05],\n",
      "          [3.5066e-05, 2.6831e-05, 2.2106e-05],\n",
      "          [3.8557e-05, 3.2263e-05, 2.8187e-05]],\n",
      "\n",
      "         [[3.0044e-05, 1.9636e-05, 1.3661e-05],\n",
      "          [3.3660e-05, 2.4276e-05, 1.8495e-05],\n",
      "          [3.7745e-05, 3.0390e-05, 2.5368e-05]],\n",
      "\n",
      "         [[3.7028e-05, 2.7456e-05, 2.1906e-05],\n",
      "          [4.0158e-05, 3.1307e-05, 2.5866e-05],\n",
      "          [4.3822e-05, 3.6702e-05, 3.1889e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.0156e-03, 2.0817e-03, 2.0691e-03],\n",
      "          [2.0098e-03, 2.0613e-03, 2.0350e-03],\n",
      "          [2.0377e-03, 2.0783e-03, 2.0395e-03]],\n",
      "\n",
      "         [[2.1145e-03, 2.1801e-03, 2.1655e-03],\n",
      "          [2.1108e-03, 2.1614e-03, 2.1325e-03],\n",
      "          [2.1410e-03, 2.1796e-03, 2.1371e-03]],\n",
      "\n",
      "         [[2.3437e-03, 2.3907e-03, 2.3745e-03],\n",
      "          [2.3374e-03, 2.3717e-03, 2.3463e-03],\n",
      "          [2.3598e-03, 2.3854e-03, 2.3466e-03]]],\n",
      "\n",
      "\n",
      "        [[[2.4338e-06, 1.7383e-06, 1.2725e-06],\n",
      "          [2.3762e-06, 1.6399e-06, 1.1684e-06],\n",
      "          [2.3584e-06, 1.6315e-06, 1.1574e-06]],\n",
      "\n",
      "         [[3.1804e-06, 2.6336e-06, 2.2308e-06],\n",
      "          [3.1170e-06, 2.5393e-06, 2.1338e-06],\n",
      "          [3.0876e-06, 2.5118e-06, 2.1056e-06]],\n",
      "\n",
      "         [[4.1440e-06, 3.8443e-06, 3.6178e-06],\n",
      "          [4.0927e-06, 3.7838e-06, 3.5648e-06],\n",
      "          [4.0607e-06, 3.7552e-06, 3.5354e-06]]],\n",
      "\n",
      "\n",
      "        [[[6.2994e-04, 6.0841e-04, 5.5749e-04],\n",
      "          [6.3529e-04, 6.0295e-04, 5.4581e-04],\n",
      "          [6.4574e-04, 6.0903e-04, 5.4694e-04]],\n",
      "\n",
      "         [[6.6039e-04, 6.3689e-04, 5.8256e-04],\n",
      "          [6.6622e-04, 6.2987e-04, 5.7016e-04],\n",
      "          [6.7444e-04, 6.3338e-04, 5.7011e-04]],\n",
      "\n",
      "         [[7.1383e-04, 6.9658e-04, 6.5479e-04],\n",
      "          [7.1820e-04, 6.9049e-04, 6.4393e-04],\n",
      "          [7.2296e-04, 6.9141e-04, 6.4083e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.7720e-06, 1.2524e-06, 1.9869e-06],\n",
      "          [1.4833e-06, 1.1352e-06, 2.0384e-06],\n",
      "          [1.5777e-06, 1.3608e-06, 2.4606e-06]],\n",
      "\n",
      "         [[2.2797e-06, 1.7576e-06, 2.6283e-06],\n",
      "          [2.0152e-06, 1.6402e-06, 2.6423e-06],\n",
      "          [2.1586e-06, 1.9125e-06, 3.1211e-06]],\n",
      "\n",
      "         [[6.5096e-06, 6.1135e-06, 6.8540e-06],\n",
      "          [6.3238e-06, 5.9566e-06, 6.8140e-06],\n",
      "          [6.4667e-06, 6.1892e-06, 7.1907e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.5413e-03, 1.5727e-03, 1.6035e-03],\n",
      "          [1.5864e-03, 1.5833e-03, 1.5689e-03],\n",
      "          [1.6217e-03, 1.5812e-03, 1.5210e-03]],\n",
      "\n",
      "         [[1.6224e-03, 1.6619e-03, 1.7022e-03],\n",
      "          [1.6620e-03, 1.6664e-03, 1.6578e-03],\n",
      "          [1.6897e-03, 1.6557e-03, 1.5984e-03]],\n",
      "\n",
      "         [[1.8524e-03, 1.8710e-03, 1.8948e-03],\n",
      "          [1.8824e-03, 1.8721e-03, 1.8574e-03],\n",
      "          [1.9084e-03, 1.8637e-03, 1.8081e-03]]],\n",
      "\n",
      "\n",
      "        [[[6.7190e-04, 7.0725e-04, 7.0901e-04],\n",
      "          [6.8217e-04, 7.1079e-04, 7.0265e-04],\n",
      "          [6.9188e-04, 7.1926e-04, 7.0547e-04]],\n",
      "\n",
      "         [[6.9849e-04, 7.3619e-04, 7.3714e-04],\n",
      "          [7.0691e-04, 7.3835e-04, 7.3069e-04],\n",
      "          [7.1612e-04, 7.4599e-04, 7.3270e-04]],\n",
      "\n",
      "         [[7.7811e-04, 8.0344e-04, 8.0183e-04],\n",
      "          [7.8505e-04, 8.0482e-04, 7.9493e-04],\n",
      "          [7.9256e-04, 8.1088e-04, 7.9431e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.6508e-03, 1.6360e-03, 1.5827e-03],\n",
      "          [1.5668e-03, 1.5893e-03, 1.5801e-03],\n",
      "          [1.5088e-03, 1.5623e-03, 1.5932e-03]],\n",
      "\n",
      "         [[1.7772e-03, 1.7630e-03, 1.7069e-03],\n",
      "          [1.6778e-03, 1.7010e-03, 1.6900e-03],\n",
      "          [1.6007e-03, 1.6586e-03, 1.6885e-03]],\n",
      "\n",
      "         [[1.9795e-03, 1.9600e-03, 1.9227e-03],\n",
      "          [1.8949e-03, 1.9050e-03, 1.9033e-03],\n",
      "          [1.8222e-03, 1.8605e-03, 1.8923e-03]]],\n",
      "\n",
      "\n",
      "        [[[6.8708e-04, 7.0850e-04, 6.8793e-04],\n",
      "          [6.7118e-04, 6.9902e-04, 6.8348e-04],\n",
      "          [6.6281e-04, 6.9924e-04, 6.9412e-04]],\n",
      "\n",
      "         [[7.2229e-04, 7.4598e-04, 7.2780e-04],\n",
      "          [7.1023e-04, 7.4037e-04, 7.2878e-04],\n",
      "          [7.0569e-04, 7.4589e-04, 7.4231e-04]],\n",
      "\n",
      "         [[7.8341e-04, 7.9868e-04, 7.8081e-04],\n",
      "          [7.7495e-04, 7.9665e-04, 7.8369e-04],\n",
      "          [7.7369e-04, 8.0412e-04, 7.9894e-04]]],\n",
      "\n",
      "\n",
      "        [[[5.9302e-07, 6.2860e-07, 9.0768e-07],\n",
      "          [5.2382e-07, 5.8589e-07, 8.9748e-07],\n",
      "          [5.4451e-07, 6.2243e-07, 9.7467e-07]],\n",
      "\n",
      "         [[2.1508e-07, 2.7503e-07, 5.8542e-07],\n",
      "          [1.4967e-07, 2.1486e-07, 5.4488e-07],\n",
      "          [1.7435e-07, 2.4444e-07, 6.1051e-07]],\n",
      "\n",
      "         [[3.4766e-07, 3.9244e-07, 7.1782e-07],\n",
      "          [2.7810e-07, 3.2820e-07, 6.7580e-07],\n",
      "          [3.0501e-07, 3.6638e-07, 7.4928e-07]]],\n",
      "\n",
      "\n",
      "        [[[1.8911e-04, 1.7885e-04, 1.8649e-04],\n",
      "          [1.8868e-04, 1.7740e-04, 1.8159e-04],\n",
      "          [1.8982e-04, 1.8109e-04, 1.8073e-04]],\n",
      "\n",
      "         [[1.9286e-04, 1.8125e-04, 1.8969e-04],\n",
      "          [1.9276e-04, 1.7920e-04, 1.8451e-04],\n",
      "          [1.9477e-04, 1.8199e-04, 1.8300e-04]],\n",
      "\n",
      "         [[2.1175e-04, 2.0268e-04, 2.0947e-04],\n",
      "          [2.0888e-04, 1.9802e-04, 2.0372e-04],\n",
      "          [2.0882e-04, 1.9883e-04, 1.9992e-04]]],\n",
      "\n",
      "\n",
      "        [[[5.8457e-03, 5.6856e-03, 5.6021e-03],\n",
      "          [5.8910e-03, 5.6829e-03, 5.5993e-03],\n",
      "          [5.7818e-03, 5.5530e-03, 5.4678e-03]],\n",
      "\n",
      "         [[6.1136e-03, 5.9522e-03, 5.8526e-03],\n",
      "          [6.1666e-03, 5.9541e-03, 5.8538e-03],\n",
      "          [6.0620e-03, 5.8156e-03, 5.7164e-03]],\n",
      "\n",
      "         [[6.6864e-03, 6.6602e-03, 6.6303e-03],\n",
      "          [6.7436e-03, 6.6551e-03, 6.6224e-03],\n",
      "          [6.6640e-03, 6.5296e-03, 6.4890e-03]]],\n",
      "\n",
      "\n",
      "        [[[2.7409e-06, 3.0924e-06, 4.0677e-06],\n",
      "          [2.7586e-06, 3.1648e-06, 4.2120e-06],\n",
      "          [2.8068e-06, 3.2626e-06, 4.3071e-06]],\n",
      "\n",
      "         [[5.5376e-07, 1.0703e-06, 2.5903e-06],\n",
      "          [5.7896e-07, 1.1691e-06, 2.7630e-06],\n",
      "          [7.4188e-07, 1.3965e-06, 2.9627e-06]],\n",
      "\n",
      "         [[1.9580e-06, 2.5354e-06, 3.9897e-06],\n",
      "          [1.9780e-06, 2.6012e-06, 4.1074e-06],\n",
      "          [2.1512e-06, 2.8093e-06, 4.2543e-06]]],\n",
      "\n",
      "\n",
      "        [[[9.8298e-07, 8.8590e-07, 8.4195e-07],\n",
      "          [8.9985e-07, 8.0524e-07, 7.7956e-07],\n",
      "          [8.3952e-07, 7.6053e-07, 7.4529e-07]],\n",
      "\n",
      "         [[8.3025e-07, 6.9699e-07, 6.2744e-07],\n",
      "          [7.2510e-07, 5.9078e-07, 5.4130e-07],\n",
      "          [6.4757e-07, 5.3026e-07, 4.9453e-07]],\n",
      "\n",
      "         [[6.1957e-07, 4.5805e-07, 3.7221e-07],\n",
      "          [4.9678e-07, 3.2791e-07, 2.5916e-07],\n",
      "          [4.0192e-07, 2.4561e-07, 1.9132e-07]]],\n",
      "\n",
      "\n",
      "        [[[4.5405e-03, 4.3394e-03, 4.2923e-03],\n",
      "          [4.4725e-03, 4.3660e-03, 4.3792e-03],\n",
      "          [4.3425e-03, 4.3189e-03, 4.4023e-03]],\n",
      "\n",
      "         [[4.7787e-03, 4.5610e-03, 4.5118e-03],\n",
      "          [4.6996e-03, 4.5815e-03, 4.5968e-03],\n",
      "          [4.5641e-03, 4.5289e-03, 4.6075e-03]],\n",
      "\n",
      "         [[5.2286e-03, 5.0342e-03, 4.9776e-03],\n",
      "          [5.1711e-03, 5.0578e-03, 5.0471e-03],\n",
      "          [5.0590e-03, 5.0094e-03, 5.0585e-03]]]], device='cuda:0')}, 140402548531416: {'step': 23620, 'exp_avg': tensor([ 3.6928e-09,  2.5550e-09, -4.6005e-08, -1.0163e-09,  4.4644e-09,\n",
      "         7.3115e-10,  3.7907e-09, -1.3736e-09, -1.4850e-08, -1.1256e-09,\n",
      "         4.1898e-10,  6.1448e-09,  1.7757e-08, -2.9052e-11, -1.1915e-10,\n",
      "        -1.9106e-08], device='cuda:0'), 'exp_avg_sq': tensor([2.0810e-15, 5.2428e-17, 1.3474e-15, 2.8177e-18, 8.0464e-16, 1.2298e-17,\n",
      "        1.1467e-15, 5.0105e-16, 1.4975e-15, 6.3127e-16, 6.9683e-18, 5.6395e-16,\n",
      "        5.1770e-15, 6.0938e-18, 6.6135e-19, 4.7272e-15], device='cuda:0')}, 140402548531344: {'step': 23620, 'exp_avg': tensor([ 0.0044, -0.0022,  0.0021,  0.0017, -0.0040,  0.0004, -0.0007,  0.0041,\n",
      "        -0.0021, -0.0004, -0.0063, -0.0008, -0.0003,  0.0019,  0.0106, -0.0010],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([0.0005, 0.0003, 0.0005, 0.0003, 0.0003, 0.0003, 0.0006, 0.0004, 0.0004,\n",
      "        0.0005, 0.0002, 0.0002, 0.0005, 0.0002, 0.0009, 0.0007],\n",
      "       device='cuda:0')}, 140402548534152: {'step': 23620, 'exp_avg': tensor([ 0.0047,  0.0034,  0.0002,  0.0030, -0.0019,  0.0036, -0.0018, -0.0020,\n",
      "        -0.0079, -0.0039, -0.0041, -0.0012, -0.0018,  0.0010,  0.0005,  0.0027],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([4.3506e-04, 2.0747e-04, 7.5964e-04, 2.7063e-04, 1.5978e-04, 2.0016e-04,\n",
      "        7.3130e-04, 6.1971e-04, 3.4337e-04, 5.5076e-04, 1.3314e-04, 1.0415e-04,\n",
      "        2.6825e-04, 1.1112e-04, 4.7983e-05, 5.1829e-04], device='cuda:0')}, 140402548533720: {'step': 23620, 'exp_avg': tensor([[[[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[-2.3025e-04,  1.4751e-04,  9.4245e-04],\n",
      "          [-7.4406e-05,  7.7633e-04,  1.2953e-03],\n",
      "          [ 4.7554e-04,  1.2615e-03,  1.2951e-03]],\n",
      "\n",
      "         [[-1.4223e-04, -2.4498e-05,  3.2950e-04],\n",
      "          [-1.2227e-04, -7.2509e-05,  2.0980e-04],\n",
      "          [ 5.9508e-05, -9.6118e-05,  1.9147e-04]],\n",
      "\n",
      "         [[ 5.0915e-04,  2.4167e-04, -8.8453e-04],\n",
      "          [ 1.0496e-03,  1.1501e-03,  3.3904e-05],\n",
      "          [ 1.1591e-03,  1.7338e-03,  9.9067e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4413e-05, -6.1216e-05, -4.1465e-05],\n",
      "          [-4.1126e-05, -3.6691e-05, -3.9673e-05],\n",
      "          [-1.3741e-05, -2.0266e-05, -2.2155e-05]],\n",
      "\n",
      "         [[ 3.1537e-05, -1.6904e-05,  7.0475e-06],\n",
      "          [ 3.6201e-05, -1.4779e-05, -1.2909e-05],\n",
      "          [ 2.3729e-05,  1.0799e-05, -1.8958e-05]],\n",
      "\n",
      "         [[-1.7482e-03, -6.7347e-04,  9.3664e-04],\n",
      "          [-1.6511e-03, -6.4340e-04,  1.0676e-03],\n",
      "          [-1.1553e-03, -3.4318e-04,  1.1583e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5151e-03,  1.7501e-03,  1.3582e-03],\n",
      "          [-1.1619e-03, -1.4442e-03, -9.6803e-04],\n",
      "          [-1.4308e-03, -1.8422e-03, -8.6552e-04]],\n",
      "\n",
      "         [[-1.1229e-04, -2.3807e-04, -3.9032e-04],\n",
      "          [-4.7475e-04, -7.0113e-04, -8.0635e-04],\n",
      "          [-3.1732e-04, -6.4957e-04, -7.4581e-04]],\n",
      "\n",
      "         [[ 2.4137e-03,  1.1270e-03,  1.5729e-04],\n",
      "          [ 2.2206e-03,  9.4759e-04,  1.7005e-04],\n",
      "          [ 1.9284e-03,  1.7879e-03,  1.0789e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2191e-05, -2.0680e-04, -1.7719e-04],\n",
      "          [-2.3008e-05, -1.8824e-04, -1.6702e-04],\n",
      "          [ 1.7753e-05, -7.2750e-05, -8.3011e-05]],\n",
      "\n",
      "         [[ 2.2279e-07, -4.1919e-05, -8.0360e-05],\n",
      "          [ 2.2864e-05, -2.3518e-05, -6.3127e-05],\n",
      "          [ 8.0592e-05,  1.7043e-05, -4.9388e-05]],\n",
      "\n",
      "         [[ 1.2994e-03,  1.2181e-03,  1.2282e-03],\n",
      "          [-3.3389e-03, -3.8351e-03, -2.2974e-03],\n",
      "          [-3.0404e-03, -3.9848e-03, -2.8070e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.0772e-04,  1.4036e-06,  1.3786e-04],\n",
      "          [ 1.5756e-03,  6.4164e-04,  2.2914e-04],\n",
      "          [ 9.6372e-05, -6.4090e-04, -1.0178e-03]],\n",
      "\n",
      "         [[ 2.2977e-04,  1.1903e-04,  2.8675e-04],\n",
      "          [ 3.8338e-04,  2.0517e-04,  3.0962e-04],\n",
      "          [ 2.0494e-04,  3.3726e-05, -2.2588e-05]],\n",
      "\n",
      "         [[ 7.6784e-04, -1.3723e-04, -4.9190e-04],\n",
      "          [ 7.1594e-04,  1.2722e-04, -3.5959e-05],\n",
      "          [-4.8528e-04,  2.3769e-04,  4.4739e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0417e-05, -3.2105e-05, -4.3045e-05],\n",
      "          [ 9.6796e-06, -9.9400e-06,  2.3686e-05],\n",
      "          [ 2.5292e-05, -3.1842e-06,  4.7689e-05]],\n",
      "\n",
      "         [[ 1.0290e-04,  6.3784e-05,  9.6473e-05],\n",
      "          [ 6.0315e-05,  5.1480e-05,  6.7363e-05],\n",
      "          [ 7.7971e-05,  8.0188e-05,  8.6486e-05]],\n",
      "\n",
      "         [[-4.3447e-04, -8.9879e-04, -1.2998e-04],\n",
      "          [ 1.3967e-03,  1.0992e-04, -6.5771e-05],\n",
      "          [ 7.8719e-04, -4.2011e-04, -1.3869e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1205e-05, -6.4823e-04,  6.9098e-04],\n",
      "          [ 3.7527e-04,  3.5294e-04,  8.0530e-04],\n",
      "          [-1.1680e-04, -1.5895e-03, -1.0811e-03]],\n",
      "\n",
      "         [[-3.1863e-05,  1.3739e-04, -1.5411e-05],\n",
      "          [ 1.0862e-04,  1.9209e-04,  5.0336e-05],\n",
      "          [-2.2068e-04, -1.2146e-04, -2.1801e-04]],\n",
      "\n",
      "         [[ 7.0610e-04, -7.7783e-05,  1.4258e-03],\n",
      "          [ 2.2671e-04, -9.0515e-06,  1.1946e-03],\n",
      "          [ 2.6532e-04, -1.2484e-03, -4.2095e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0319e-05,  7.7855e-05,  9.9501e-05],\n",
      "          [ 3.8867e-05,  4.9077e-05,  1.0049e-04],\n",
      "          [ 1.5407e-05, -9.3428e-06,  3.8355e-05]],\n",
      "\n",
      "         [[-1.0080e-05,  4.0131e-06,  2.4926e-07],\n",
      "          [-3.3483e-05, -4.5281e-05, -1.7389e-05],\n",
      "          [-2.9481e-05, -2.3601e-05,  1.6309e-05]],\n",
      "\n",
      "         [[-7.2616e-04, -8.0994e-04, -1.2105e-03],\n",
      "          [-2.2482e-04,  2.1764e-04, -1.9339e-04],\n",
      "          [-1.0691e-03, -1.7034e-03, -2.2058e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1985e-03, -3.9219e-05,  5.1444e-04],\n",
      "          [ 1.4404e-03,  1.1064e-03, -4.4050e-04],\n",
      "          [ 1.5791e-03, -4.3121e-04, -1.6938e-03]],\n",
      "\n",
      "         [[-1.6687e-04, -9.3633e-06, -6.0128e-04],\n",
      "          [-1.1052e-04,  8.6132e-05, -8.2995e-04],\n",
      "          [-1.6736e-04,  6.5023e-05, -2.3698e-04]],\n",
      "\n",
      "         [[-2.4007e-03, -1.5799e-03,  6.4427e-04],\n",
      "          [-2.0442e-03, -1.2835e-03,  9.3789e-05],\n",
      "          [-2.3811e-03, -2.1174e-03, -4.7168e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0604e-05, -7.2724e-05,  5.5590e-05],\n",
      "          [-9.2221e-05, -1.1638e-05,  1.4574e-04],\n",
      "          [-4.4204e-05,  7.8026e-05,  2.1130e-04]],\n",
      "\n",
      "         [[ 7.0252e-05,  1.0675e-06, -1.4365e-04],\n",
      "          [ 1.5220e-05,  6.1302e-06, -7.5706e-05],\n",
      "          [-4.7305e-05,  1.3566e-05, -5.0919e-05]],\n",
      "\n",
      "         [[-2.1082e-03, -1.2828e-03, -2.5804e-03],\n",
      "          [ 3.0991e-04, -4.1161e-04, -3.1408e-03],\n",
      "          [ 1.8743e-03,  1.3186e-03, -2.3564e-04]]]], device='cuda:0'), 'exp_avg_sq': tensor([[[[3.1048e-18, 3.3215e-18, 1.9351e-18],\n",
      "          [2.2383e-18, 1.9341e-18, 2.0461e-18],\n",
      "          [2.6098e-18, 2.5342e-18, 3.5142e-18]],\n",
      "\n",
      "         [[2.5938e-19, 3.6634e-19, 4.4435e-19],\n",
      "          [2.3869e-19, 3.5414e-19, 4.7418e-19],\n",
      "          [2.4639e-19, 3.5332e-19, 4.8097e-19]],\n",
      "\n",
      "         [[6.2199e-19, 5.8240e-19, 6.2385e-19],\n",
      "          [5.9493e-19, 4.4964e-19, 6.2072e-19],\n",
      "          [8.9380e-19, 5.0830e-19, 7.3717e-19]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.2805e-19, 3.7396e-19, 5.4190e-19],\n",
      "          [2.8552e-19, 2.8784e-19, 5.5089e-19],\n",
      "          [3.0809e-19, 2.8764e-19, 4.9481e-19]],\n",
      "\n",
      "         [[1.4488e-21, 2.1090e-21, 2.1261e-21],\n",
      "          [1.4602e-21, 2.4843e-21, 2.1688e-21],\n",
      "          [1.5409e-21, 2.2196e-21, 2.6187e-21]],\n",
      "\n",
      "         [[7.0283e-19, 9.1008e-19, 1.0526e-18],\n",
      "          [7.4778e-19, 1.0377e-18, 1.0839e-18],\n",
      "          [5.5372e-19, 9.7054e-19, 1.2421e-18]]],\n",
      "\n",
      "\n",
      "        [[[2.5334e-05, 1.7433e-05, 2.4500e-05],\n",
      "          [3.1829e-05, 3.1765e-05, 3.7939e-05],\n",
      "          [2.4321e-05, 2.6911e-05, 2.6801e-05]],\n",
      "\n",
      "         [[1.6800e-06, 1.5617e-06, 1.5134e-06],\n",
      "          [1.7649e-06, 1.9033e-06, 2.0183e-06],\n",
      "          [1.2526e-06, 1.4284e-06, 1.5952e-06]],\n",
      "\n",
      "         [[3.3193e-05, 1.4745e-05, 2.3136e-05],\n",
      "          [3.4631e-05, 1.5468e-05, 2.2216e-05],\n",
      "          [3.2528e-05, 1.7870e-05, 1.8805e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.1204e-07, 2.1965e-07, 2.5014e-07],\n",
      "          [1.9590e-07, 1.9930e-07, 2.2624e-07],\n",
      "          [1.7857e-07, 1.5363e-07, 1.5398e-07]],\n",
      "\n",
      "         [[7.3420e-08, 7.1731e-08, 6.9664e-08],\n",
      "          [6.8880e-08, 6.5505e-08, 6.4755e-08],\n",
      "          [7.0942e-08, 6.9370e-08, 7.1596e-08]],\n",
      "\n",
      "         [[2.8389e-05, 2.7522e-05, 2.8892e-05],\n",
      "          [3.4168e-05, 4.1151e-05, 4.7741e-05],\n",
      "          [2.3354e-05, 3.2566e-05, 3.6191e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.1365e-05, 4.3452e-05, 4.2590e-05],\n",
      "          [4.0703e-05, 4.4244e-05, 3.3534e-05],\n",
      "          [4.4683e-05, 3.7854e-05, 2.1497e-05]],\n",
      "\n",
      "         [[1.6519e-06, 1.7878e-06, 2.0237e-06],\n",
      "          [1.6989e-06, 1.6269e-06, 1.8698e-06],\n",
      "          [1.7029e-06, 1.4120e-06, 1.5753e-06]],\n",
      "\n",
      "         [[2.9726e-05, 3.2377e-05, 2.9426e-05],\n",
      "          [3.5052e-05, 3.3065e-05, 2.2428e-05],\n",
      "          [3.6766e-05, 2.8094e-05, 1.4093e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.0618e-07, 3.3400e-07, 2.5730e-07],\n",
      "          [3.1962e-07, 2.9234e-07, 1.8183e-07],\n",
      "          [2.9086e-07, 2.0388e-07, 1.0991e-07]],\n",
      "\n",
      "         [[8.1649e-08, 7.7033e-08, 7.8594e-08],\n",
      "          [7.9619e-08, 7.5174e-08, 7.6974e-08],\n",
      "          [7.5709e-08, 7.2061e-08, 7.6023e-08]],\n",
      "\n",
      "         [[2.9687e-05, 4.1374e-05, 5.0205e-05],\n",
      "          [3.3977e-05, 4.0171e-05, 4.5609e-05],\n",
      "          [3.8274e-05, 3.6082e-05, 3.4979e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.7041e-05, 1.5572e-05, 2.4889e-05],\n",
      "          [1.6168e-05, 1.5613e-05, 2.2275e-05],\n",
      "          [1.2579e-05, 8.8082e-06, 1.4232e-05]],\n",
      "\n",
      "         [[2.2334e-06, 2.5337e-06, 2.2970e-06],\n",
      "          [1.7633e-06, 2.4030e-06, 2.2917e-06],\n",
      "          [1.2076e-06, 1.8768e-06, 2.0556e-06]],\n",
      "\n",
      "         [[8.4654e-06, 2.5055e-06, 1.6659e-05],\n",
      "          [1.3939e-05, 2.2318e-06, 1.2525e-05],\n",
      "          [2.3178e-05, 3.7622e-06, 9.3360e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.4162e-07, 1.8635e-07, 3.1641e-07],\n",
      "          [1.3135e-07, 1.4244e-07, 2.4852e-07],\n",
      "          [1.4847e-07, 1.2389e-07, 1.9999e-07]],\n",
      "\n",
      "         [[8.6488e-08, 8.5014e-08, 8.5442e-08],\n",
      "          [9.0020e-08, 8.7571e-08, 8.6330e-08],\n",
      "          [9.1956e-08, 8.9466e-08, 8.7255e-08]],\n",
      "\n",
      "         [[4.5935e-05, 4.9966e-05, 4.2837e-05],\n",
      "          [3.7197e-05, 5.2776e-05, 4.5937e-05],\n",
      "          [1.8207e-05, 3.4557e-05, 3.7172e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.0347e-05, 7.5009e-06, 9.6973e-06],\n",
      "          [9.6327e-06, 4.6173e-06, 2.1200e-05],\n",
      "          [8.7062e-06, 1.6580e-05, 3.4272e-05]],\n",
      "\n",
      "         [[6.9063e-07, 6.8396e-07, 8.9222e-07],\n",
      "          [6.6553e-07, 7.7828e-07, 1.0671e-06],\n",
      "          [1.0791e-06, 1.1887e-06, 1.3330e-06]],\n",
      "\n",
      "         [[2.6598e-05, 1.0812e-05, 1.4855e-05],\n",
      "          [1.8662e-05, 7.9624e-06, 2.4136e-05],\n",
      "          [1.3305e-05, 1.4064e-05, 3.2011e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.3640e-07, 7.4867e-08, 8.9495e-08],\n",
      "          [1.4132e-07, 1.0376e-07, 1.5868e-07],\n",
      "          [1.7112e-07, 1.8968e-07, 2.4708e-07]],\n",
      "\n",
      "         [[6.1587e-08, 6.0293e-08, 6.3106e-08],\n",
      "          [6.0707e-08, 5.7270e-08, 6.1273e-08],\n",
      "          [5.8602e-08, 5.5389e-08, 6.0847e-08]],\n",
      "\n",
      "         [[1.4123e-05, 1.0169e-05, 9.9348e-06],\n",
      "          [7.4576e-06, 6.6188e-06, 1.3496e-05],\n",
      "          [1.3075e-05, 1.7035e-05, 2.7946e-05]]],\n",
      "\n",
      "\n",
      "        [[[9.0880e-05, 9.1584e-05, 1.1730e-04],\n",
      "          [7.2470e-05, 7.4502e-05, 1.0346e-04],\n",
      "          [5.9768e-05, 6.3590e-05, 9.8895e-05]],\n",
      "\n",
      "         [[4.8201e-06, 5.4799e-06, 5.5803e-06],\n",
      "          [5.0127e-06, 6.2700e-06, 6.2866e-06],\n",
      "          [5.5458e-06, 6.7953e-06, 7.0914e-06]],\n",
      "\n",
      "         [[1.2268e-04, 1.0652e-04, 1.2587e-04],\n",
      "          [1.1393e-04, 1.0306e-04, 1.1753e-04],\n",
      "          [1.0289e-04, 9.0192e-05, 9.6747e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[9.2994e-07, 8.8686e-07, 9.7800e-07],\n",
      "          [9.1324e-07, 7.8757e-07, 8.8629e-07],\n",
      "          [9.2955e-07, 7.3720e-07, 8.1685e-07]],\n",
      "\n",
      "         [[2.2557e-07, 2.3093e-07, 2.3836e-07],\n",
      "          [2.1852e-07, 2.1769e-07, 2.2478e-07],\n",
      "          [2.2296e-07, 2.1144e-07, 2.2121e-07]],\n",
      "\n",
      "         [[7.5564e-05, 8.9221e-05, 1.1517e-04],\n",
      "          [8.4584e-05, 1.1659e-04, 1.2783e-04],\n",
      "          [1.0798e-04, 1.5113e-04, 1.6437e-04]]]], device='cuda:0')}, 140402548533648: {'step': 23620, 'exp_avg': tensor([-5.6052e-45, -9.3797e-10,  8.7465e-10, -2.6510e-10,  1.5443e-10,\n",
      "         1.1396e-09,  7.0421e-12, -5.4216e-10, -1.4976e-10,  5.2206e-11,\n",
      "         5.5062e-10,  3.4464e-10,  5.6570e-10, -1.6309e-10,  2.9684e-10,\n",
      "         8.3622e-10,  1.1506e-09, -2.2417e-12,  2.2097e-10, -3.1735e-10,\n",
      "        -4.3503e-10, -4.3238e-10,  5.2930e-10,  4.0984e-10,  6.6021e-10,\n",
      "        -1.3938e-10, -1.5846e-09,  9.3672e-11,  1.2507e-10, -9.7987e-10,\n",
      "         6.7780e-10, -6.2503e-10], device='cuda:0'), 'exp_avg_sq': tensor([5.0790e-31, 3.4364e-18, 4.7126e-18, 4.7259e-19, 6.0052e-18, 5.6373e-18,\n",
      "        6.1545e-18, 3.0907e-18, 7.5475e-18, 7.0842e-18, 5.6942e-18, 1.0089e-18,\n",
      "        6.5917e-18, 1.4814e-18, 4.4043e-18, 9.0426e-18, 5.1179e-18, 5.9031e-18,\n",
      "        1.3407e-18, 4.7119e-18, 6.8790e-18, 5.7634e-18, 3.1819e-18, 9.6163e-18,\n",
      "        7.9837e-18, 4.0751e-18, 9.1021e-18, 3.9701e-18, 1.5360e-18, 5.8815e-18,\n",
      "        3.4839e-18, 1.6552e-17], device='cuda:0')}, 140402548532712: {'step': 23620, 'exp_avg': tensor([ 5.6052e-45,  3.9260e-04,  6.5214e-04, -3.3116e-03, -9.2691e-03,\n",
      "        -4.4711e-03, -2.0144e-03,  1.8079e-02,  3.3308e-04,  7.6029e-03,\n",
      "         5.5010e-04, -9.2447e-04, -5.9715e-03,  4.1982e-03,  1.0337e-03,\n",
      "         2.0687e-03, -8.3671e-04, -2.8961e-03, -9.6779e-03,  4.9076e-03,\n",
      "         9.0547e-06,  1.5246e-02, -7.9238e-03, -1.4521e-02, -1.2793e-02,\n",
      "        -1.1402e-03,  7.4277e-03,  1.7621e-02,  1.7213e-03, -1.2507e-03,\n",
      "        -1.0637e-03,  1.6446e-03], device='cuda:0'), 'exp_avg_sq': tensor([7.4675e-16, 8.6859e-04, 7.1495e-04, 1.3784e-03, 7.6913e-04, 6.2575e-04,\n",
      "        7.2769e-04, 1.1098e-03, 7.8130e-04, 6.3101e-04, 5.3703e-04, 1.4066e-03,\n",
      "        4.6699e-04, 1.6326e-03, 1.2306e-03, 3.1260e-04, 7.2955e-04, 8.1864e-04,\n",
      "        6.6478e-04, 7.4200e-04, 8.3099e-04, 7.7083e-04, 1.2161e-03, 7.4620e-04,\n",
      "        5.5747e-04, 8.8509e-04, 6.3502e-04, 9.3054e-04, 9.2867e-04, 6.4700e-04,\n",
      "        7.1240e-04, 6.2824e-04], device='cuda:0')}, 140402548531704: {'step': 23620, 'exp_avg': tensor([ 5.6052e-45, -7.1687e-03,  1.8030e-03, -4.1749e-03, -1.1347e-02,\n",
      "        -4.0526e-03, -2.8092e-03,  1.5832e-02,  5.7705e-03,  7.0205e-03,\n",
      "         1.0627e-04, -6.2519e-03, -2.5624e-03,  6.0836e-03,  9.6605e-04,\n",
      "        -3.4929e-03, -7.5050e-04, -3.9664e-03, -5.4569e-03,  7.5436e-03,\n",
      "         5.1460e-03,  1.4862e-02, -6.3107e-03, -1.4565e-02, -1.3718e-02,\n",
      "        -2.8107e-03,  7.6171e-03,  1.5291e-02,  1.7007e-03, -7.1179e-04,\n",
      "        -4.6185e-03, -4.0366e-03], device='cuda:0'), 'exp_avg_sq': tensor([2.1663e-16, 7.9132e-04, 7.1040e-04, 8.2477e-04, 6.7858e-04, 6.3579e-04,\n",
      "        7.6386e-04, 8.7065e-04, 5.9894e-04, 6.5206e-04, 7.0016e-04, 8.8000e-04,\n",
      "        5.9797e-04, 9.6707e-04, 1.0648e-03, 4.7872e-04, 8.8436e-04, 7.0009e-04,\n",
      "        6.9122e-04, 8.1586e-04, 7.2759e-04, 6.6592e-04, 8.9591e-04, 7.8941e-04,\n",
      "        7.1630e-04, 7.0509e-04, 7.1677e-04, 9.6032e-04, 9.3812e-04, 6.7007e-04,\n",
      "        6.4518e-04, 4.2840e-04], device='cuda:0')}, 140402548532568: {'step': 23620, 'exp_avg': tensor([[[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-2.8338e-04, -1.9625e-04,  3.3691e-04],\n",
      "          [ 2.2055e-04,  2.1511e-04,  2.7550e-04],\n",
      "          [ 2.2383e-04,  2.3412e-04,  7.1930e-04]],\n",
      "\n",
      "         [[ 8.3794e-04, -2.5332e-04, -4.6609e-04],\n",
      "          [-5.0417e-05, -1.5544e-04,  3.7760e-05],\n",
      "          [-9.4180e-05,  1.0349e-04, -1.0439e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2341e-04,  3.4946e-04,  2.4360e-04],\n",
      "          [ 6.8952e-05, -3.2612e-05, -6.8537e-04],\n",
      "          [ 3.9133e-04, -1.5100e-04,  4.5076e-04]],\n",
      "\n",
      "         [[-7.9513e-04,  6.8833e-04,  4.5529e-04],\n",
      "          [-3.3526e-04, -3.5992e-04, -5.1856e-04],\n",
      "          [-4.0958e-04, -9.6753e-04, -2.1174e-03]],\n",
      "\n",
      "         [[-5.2898e-04,  2.5401e-04, -1.8240e-04],\n",
      "          [-4.7929e-04, -6.7106e-04, -3.9781e-04],\n",
      "          [-2.4817e-04, -4.7165e-05,  2.1194e-04]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-1.7700e-04, -2.9666e-04, -2.8074e-04],\n",
      "          [ 3.0892e-04, -7.9930e-06,  1.2171e-04],\n",
      "          [ 2.6857e-04, -2.4718e-04, -2.8797e-04]],\n",
      "\n",
      "         [[-7.2033e-05, -2.3196e-04,  2.5749e-04],\n",
      "          [-7.2511e-05,  1.6635e-04,  2.7192e-04],\n",
      "          [ 1.4155e-04, -1.2078e-04,  3.0755e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0907e-04,  4.8676e-06, -8.8615e-06],\n",
      "          [ 3.2225e-04,  1.4981e-04,  3.2415e-04],\n",
      "          [ 1.5682e-04,  2.4222e-04, -1.8023e-05]],\n",
      "\n",
      "         [[-6.1529e-04,  4.7831e-05,  2.1735e-04],\n",
      "          [ 5.9936e-05, -7.2835e-05,  5.1141e-06],\n",
      "          [ 4.7727e-05, -2.1345e-04,  1.5774e-04]],\n",
      "\n",
      "         [[ 1.9383e-04,  2.7113e-04,  8.1833e-05],\n",
      "          [ 2.3305e-04, -4.1828e-05, -1.7123e-05],\n",
      "          [-9.7231e-05, -2.2240e-05, -1.9257e-06]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 3.8000e-05,  1.7931e-04, -1.4734e-04],\n",
      "          [ 6.0709e-04,  7.1508e-04, -4.7841e-05],\n",
      "          [-2.6304e-04,  2.0068e-04, -9.2487e-05]],\n",
      "\n",
      "         [[ 4.0123e-04, -5.4121e-04, -8.2728e-04],\n",
      "          [ 9.2016e-04, -2.4661e-04, -9.0022e-04],\n",
      "          [ 1.2072e-04, -1.4656e-04, -1.6707e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4061e-04,  3.5747e-05,  2.1108e-04],\n",
      "          [ 4.0693e-04,  4.2696e-04,  3.8242e-04],\n",
      "          [ 3.8654e-04,  8.3688e-04,  1.3377e-05]],\n",
      "\n",
      "         [[-4.5573e-04,  7.1493e-04, -5.0729e-05],\n",
      "          [ 7.6768e-04, -1.3911e-05,  5.8310e-04],\n",
      "          [ 2.4000e-04,  7.9320e-04,  6.3261e-04]],\n",
      "\n",
      "         [[ 8.3979e-04,  4.9412e-04,  3.7205e-04],\n",
      "          [ 3.6074e-04,  1.2143e-04,  4.5962e-04],\n",
      "          [ 1.0297e-03, -4.8411e-05, -1.1571e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-1.1531e-05,  2.6957e-04, -1.9982e-05],\n",
      "          [-3.0649e-04,  1.8605e-04,  3.6412e-05],\n",
      "          [ 5.5700e-04, -3.8852e-04, -4.7568e-04]],\n",
      "\n",
      "         [[-7.2989e-05,  6.1179e-04,  1.6125e-04],\n",
      "          [ 2.5778e-04,  3.8789e-05,  3.5178e-04],\n",
      "          [ 4.5896e-04, -1.7628e-04, -1.7656e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5843e-04,  2.2468e-05,  8.1458e-05],\n",
      "          [-3.4949e-04,  5.1252e-04,  5.9237e-05],\n",
      "          [ 2.5323e-04, -2.4121e-04, -2.3872e-04]],\n",
      "\n",
      "         [[-1.1317e-04, -8.4013e-04, -1.2547e-04],\n",
      "          [-1.2828e-03, -1.1925e-04, -2.1660e-04],\n",
      "          [-1.6574e-03,  7.3490e-04,  7.5690e-05]],\n",
      "\n",
      "         [[-3.8538e-04,  5.4073e-05, -1.3678e-04],\n",
      "          [ 8.2872e-04,  5.2480e-04,  3.5636e-04],\n",
      "          [ 3.3398e-04,  4.2413e-04, -4.3093e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-3.8201e-04, -5.4890e-04,  3.8176e-04],\n",
      "          [ 1.8484e-04,  1.6287e-04,  3.6846e-04],\n",
      "          [-2.7276e-05, -1.6212e-04,  4.5014e-04]],\n",
      "\n",
      "         [[-5.3622e-05, -2.6608e-04,  2.2339e-05],\n",
      "          [-5.6988e-04, -7.9790e-04,  1.3305e-04],\n",
      "          [-6.6589e-04, -2.5160e-04,  1.1452e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4618e-04, -7.1841e-05,  2.7213e-04],\n",
      "          [ 4.2360e-04, -2.1815e-04, -3.8964e-05],\n",
      "          [ 2.5450e-04, -2.4991e-04,  5.5573e-04]],\n",
      "\n",
      "         [[-1.0041e-03,  9.9574e-05, -4.3956e-04],\n",
      "          [-1.0452e-03,  2.6588e-04, -1.9101e-05],\n",
      "          [-8.7452e-05,  2.1199e-04, -3.3594e-04]],\n",
      "\n",
      "         [[ 5.9840e-04,  7.5922e-04, -1.5186e-04],\n",
      "          [ 7.4454e-04,  5.4268e-04, -1.2041e-04],\n",
      "          [ 6.8477e-04,  5.4003e-04,  1.9962e-04]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 2.7542e-05, -1.7131e-04, -8.3528e-05],\n",
      "          [ 5.1573e-05,  7.4433e-05, -7.4233e-05],\n",
      "          [ 1.3938e-04,  2.6508e-04, -7.2996e-05]],\n",
      "\n",
      "         [[ 2.3626e-04,  2.8852e-04, -1.8137e-04],\n",
      "          [-1.8399e-04, -8.1380e-05,  2.4655e-04],\n",
      "          [ 2.2290e-04,  3.0206e-05,  1.8824e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.9122e-05, -3.2166e-04,  3.1974e-04],\n",
      "          [-6.1892e-05, -1.7275e-04,  3.6898e-04],\n",
      "          [ 2.4657e-05,  2.5029e-04,  9.2184e-05]],\n",
      "\n",
      "         [[ 2.8941e-04, -5.6759e-05,  2.7219e-04],\n",
      "          [-3.1163e-05,  1.8143e-04,  1.0233e-04],\n",
      "          [-3.6538e-05,  2.4808e-04,  5.2702e-06]],\n",
      "\n",
      "         [[-6.8625e-05, -1.7518e-04,  8.1988e-05],\n",
      "          [ 1.4565e-04, -1.5501e-04, -5.0590e-04],\n",
      "          [ 6.1188e-05, -1.9227e-04, -5.1462e-04]]]], device='cuda:0'), 'exp_avg_sq': tensor([[[[1.5992e-19, 2.5111e-19, 2.2783e-19],\n",
      "          [1.3512e-19, 2.2552e-19, 4.2320e-19],\n",
      "          [1.7034e-19, 2.3532e-19, 3.5312e-19]],\n",
      "\n",
      "         [[9.2833e-07, 1.8014e-06, 1.7800e-06],\n",
      "          [5.4496e-07, 1.5667e-06, 2.8559e-06],\n",
      "          [1.9128e-06, 5.1934e-06, 4.3224e-06]],\n",
      "\n",
      "         [[5.2443e-06, 4.1689e-06, 3.4162e-06],\n",
      "          [2.9323e-06, 2.2878e-06, 3.6471e-06],\n",
      "          [3.2526e-06, 3.0963e-06, 3.8441e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.9852e-06, 1.3507e-06, 2.7170e-06],\n",
      "          [1.7014e-06, 1.5749e-06, 2.8605e-06],\n",
      "          [2.6383e-06, 3.1346e-06, 2.9812e-06]],\n",
      "\n",
      "         [[9.2973e-06, 1.0552e-05, 4.5600e-06],\n",
      "          [4.7604e-06, 4.1158e-06, 3.0012e-06],\n",
      "          [2.4549e-06, 2.0842e-06, 4.0739e-06]],\n",
      "\n",
      "         [[1.9114e-06, 2.3526e-06, 3.3577e-06],\n",
      "          [4.3428e-06, 6.6667e-06, 4.7792e-06],\n",
      "          [6.3478e-06, 7.9594e-06, 6.0284e-06]]],\n",
      "\n",
      "\n",
      "        [[[2.2044e-21, 1.5566e-21, 1.6047e-21],\n",
      "          [1.4292e-21, 2.9646e-21, 4.3229e-21],\n",
      "          [1.5142e-21, 2.0015e-21, 3.7063e-21]],\n",
      "\n",
      "         [[2.3075e-06, 1.9952e-06, 7.2381e-07],\n",
      "          [2.7131e-06, 2.8054e-06, 1.6063e-06],\n",
      "          [1.3574e-06, 2.3920e-06, 2.9863e-06]],\n",
      "\n",
      "         [[4.4464e-06, 5.2747e-06, 3.2093e-06],\n",
      "          [6.2671e-06, 5.2460e-06, 4.4854e-06],\n",
      "          [3.3076e-06, 4.0207e-06, 5.9088e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.4474e-06, 1.3283e-06, 1.3087e-06],\n",
      "          [3.2568e-06, 2.4914e-06, 1.7546e-06],\n",
      "          [2.6307e-06, 2.4179e-06, 2.2766e-06]],\n",
      "\n",
      "         [[4.4931e-06, 3.0987e-06, 4.0194e-06],\n",
      "          [1.6207e-06, 2.3734e-06, 2.4297e-06],\n",
      "          [2.9612e-06, 5.5045e-06, 2.8825e-06]],\n",
      "\n",
      "         [[5.2803e-06, 3.4998e-06, 2.5091e-06],\n",
      "          [3.8627e-06, 3.5748e-06, 2.8474e-06],\n",
      "          [5.7560e-06, 6.6764e-06, 5.1819e-06]]],\n",
      "\n",
      "\n",
      "        [[[4.5276e-21, 3.9961e-21, 4.5688e-21],\n",
      "          [3.3149e-21, 4.1769e-21, 1.9605e-21],\n",
      "          [2.9381e-21, 2.7149e-21, 1.6050e-21]],\n",
      "\n",
      "         [[3.7441e-06, 2.2195e-06, 9.3333e-07],\n",
      "          [3.0962e-06, 1.4895e-06, 1.3523e-06],\n",
      "          [1.8799e-06, 1.1175e-06, 1.6769e-06]],\n",
      "\n",
      "         [[3.9127e-06, 3.3610e-06, 3.2158e-06],\n",
      "          [5.1131e-06, 4.4551e-06, 4.9856e-06],\n",
      "          [4.6197e-06, 6.1226e-06, 6.0674e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.2181e-06, 1.7337e-06, 1.6205e-06],\n",
      "          [2.9168e-06, 1.6498e-06, 9.4183e-07],\n",
      "          [2.5156e-06, 1.3918e-06, 1.4824e-06]],\n",
      "\n",
      "         [[8.6553e-06, 8.7308e-06, 5.7629e-06],\n",
      "          [6.8844e-06, 6.2767e-06, 5.4978e-06],\n",
      "          [7.1294e-06, 6.1134e-06, 3.8961e-06]],\n",
      "\n",
      "         [[5.1584e-06, 2.0471e-06, 1.7795e-06],\n",
      "          [3.1222e-06, 1.5501e-06, 2.4782e-06],\n",
      "          [4.5350e-06, 2.8943e-06, 3.6405e-06]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.1049e-20, 1.7577e-20, 1.8336e-20],\n",
      "          [1.0959e-20, 1.6892e-20, 1.5773e-20],\n",
      "          [7.4403e-21, 1.3191e-20, 1.3749e-20]],\n",
      "\n",
      "         [[1.6246e-06, 1.4148e-06, 1.9354e-06],\n",
      "          [2.3942e-06, 2.4686e-06, 1.7121e-06],\n",
      "          [1.4544e-06, 2.1357e-06, 1.3942e-06]],\n",
      "\n",
      "         [[3.0033e-06, 5.3057e-06, 5.7250e-06],\n",
      "          [3.1399e-06, 5.3340e-06, 4.1147e-06],\n",
      "          [1.9627e-06, 1.9164e-06, 1.8963e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.4183e-06, 1.6737e-06, 2.6537e-06],\n",
      "          [2.0173e-06, 1.7571e-06, 2.8350e-06],\n",
      "          [1.1583e-06, 1.1901e-06, 2.2766e-06]],\n",
      "\n",
      "         [[6.3798e-06, 5.6797e-06, 3.6661e-06],\n",
      "          [7.8167e-06, 5.4641e-06, 4.1013e-06],\n",
      "          [8.0728e-06, 6.9422e-06, 4.7624e-06]],\n",
      "\n",
      "         [[4.2756e-06, 3.6681e-06, 4.1914e-06],\n",
      "          [4.3487e-06, 4.3821e-06, 3.8913e-06],\n",
      "          [6.4497e-06, 5.5688e-06, 4.6025e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.8736e-19, 1.1935e-19, 2.1058e-19],\n",
      "          [2.3475e-19, 1.8504e-19, 1.2699e-19],\n",
      "          [1.2451e-19, 1.4018e-19, 2.0946e-19]],\n",
      "\n",
      "         [[1.3644e-06, 1.3837e-06, 1.2591e-06],\n",
      "          [9.1648e-07, 1.4684e-06, 1.3281e-06],\n",
      "          [1.4531e-06, 2.8395e-06, 3.2832e-06]],\n",
      "\n",
      "         [[3.8752e-06, 5.4472e-06, 4.5920e-06],\n",
      "          [3.5199e-06, 5.0205e-06, 3.3219e-06],\n",
      "          [3.2445e-06, 4.7263e-06, 3.8910e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.5713e-06, 1.8438e-06, 1.4138e-06],\n",
      "          [2.4031e-06, 2.2919e-06, 1.7050e-06],\n",
      "          [2.0457e-06, 2.4654e-06, 2.4961e-06]],\n",
      "\n",
      "         [[2.7537e-06, 1.3044e-06, 2.9571e-06],\n",
      "          [2.7952e-06, 1.2398e-06, 2.4882e-06],\n",
      "          [2.6329e-06, 1.1230e-06, 1.8941e-06]],\n",
      "\n",
      "         [[2.3922e-06, 2.7307e-06, 2.2488e-06],\n",
      "          [2.7386e-06, 3.7901e-06, 2.9761e-06],\n",
      "          [4.4240e-06, 4.9019e-06, 3.5705e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.8787e-20, 4.4835e-20, 3.2670e-20],\n",
      "          [4.6302e-20, 3.9554e-20, 4.0674e-20],\n",
      "          [3.8623e-20, 5.3173e-20, 4.9223e-20]],\n",
      "\n",
      "         [[1.0098e-06, 1.1852e-06, 6.6834e-07],\n",
      "          [7.3261e-07, 6.2885e-07, 6.4411e-07],\n",
      "          [1.6020e-06, 1.0780e-06, 4.7927e-07]],\n",
      "\n",
      "         [[2.4321e-06, 2.3514e-06, 2.5490e-06],\n",
      "          [1.5818e-06, 9.4061e-07, 9.5347e-07],\n",
      "          [2.0792e-06, 1.3425e-06, 1.4453e-06]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.7030e-06, 1.7788e-06, 9.6082e-07],\n",
      "          [1.5406e-06, 1.3469e-06, 8.9719e-07],\n",
      "          [1.7848e-06, 1.3152e-06, 5.3114e-07]],\n",
      "\n",
      "         [[2.7945e-06, 2.0692e-06, 1.9662e-06],\n",
      "          [1.3365e-06, 3.2470e-06, 2.4266e-06],\n",
      "          [1.3918e-06, 2.6017e-06, 1.8190e-06]],\n",
      "\n",
      "         [[1.9009e-06, 1.8880e-06, 1.7070e-06],\n",
      "          [2.4167e-06, 1.9003e-06, 1.8139e-06],\n",
      "          [2.4936e-06, 2.5914e-06, 2.2363e-06]]]], device='cuda:0')}, 140402548532208: {'step': 23620, 'exp_avg': tensor([ 7.7481e-10,  1.5613e-10, -3.8181e-10, -2.8172e-10,  1.4696e-10,\n",
      "         6.3560e-10, -5.2512e-10, -7.5299e-10, -1.6454e-10,  1.5829e-10,\n",
      "         7.5608e-10, -4.7813e-10,  3.9945e-10,  3.1871e-10,  2.1138e-10,\n",
      "        -5.6410e-10, -1.0757e-09,  3.4901e-10, -5.5715e-10, -6.4255e-10,\n",
      "         4.7154e-11, -2.3628e-12, -1.3023e-09,  5.5198e-10,  7.1336e-10,\n",
      "        -7.7452e-12, -5.8659e-10, -4.1531e-10,  6.6535e-10,  4.1908e-12,\n",
      "         5.8050e-10, -1.7895e-10, -2.9985e-11, -1.2600e-10, -1.5196e-09,\n",
      "         1.7373e-10,  2.6358e-11,  1.3862e-10, -1.3999e-11, -2.1471e-10,\n",
      "         6.2637e-10,  2.3432e-10, -7.2884e-10,  4.1664e-10, -4.4328e-10,\n",
      "        -4.8281e-10, -2.4949e-10, -5.5160e-10,  3.6947e-10, -3.7111e-10,\n",
      "         1.0425e-09, -3.0058e-11,  5.8716e-11,  7.3772e-10,  3.4055e-10,\n",
      "        -3.0806e-10, -6.8078e-10, -7.1587e-11,  1.6396e-10, -1.6409e-09,\n",
      "        -5.7694e-10, -2.1575e-10,  6.0246e-10,  7.4282e-10], device='cuda:0'), 'exp_avg_sq': tensor([6.4995e-18, 4.3504e-18, 5.4963e-18, 3.5556e-18, 3.4291e-18, 4.2229e-18,\n",
      "        9.1370e-18, 6.1462e-18, 3.7255e-18, 4.3815e-18, 4.3474e-18, 9.8306e-18,\n",
      "        4.4531e-18, 4.9829e-18, 4.3744e-18, 4.2007e-18, 6.2950e-18, 7.3766e-18,\n",
      "        1.2673e-17, 4.8481e-18, 4.6671e-18, 3.2847e-18, 5.3342e-18, 7.3845e-18,\n",
      "        8.0986e-18, 3.9040e-18, 4.4991e-18, 2.2363e-18, 6.6609e-18, 6.1104e-18,\n",
      "        6.5748e-18, 3.9648e-18, 2.1658e-18, 4.9671e-18, 6.8379e-18, 3.9693e-18,\n",
      "        3.1047e-18, 2.5373e-18, 3.7521e-18, 7.8393e-18, 6.5832e-18, 4.2638e-18,\n",
      "        5.0125e-18, 3.2093e-18, 5.8973e-18, 3.3206e-18, 3.3928e-18, 5.0906e-18,\n",
      "        5.6261e-18, 4.3578e-18, 4.4728e-18, 6.0902e-18, 7.6487e-18, 4.4491e-18,\n",
      "        3.0291e-18, 4.4792e-18, 2.6649e-18, 7.3315e-18, 8.2162e-18, 7.9691e-18,\n",
      "        4.5328e-18, 5.0729e-18, 4.3527e-18, 2.5903e-18], device='cuda:0')}, 140402548531848: {'step': 23620, 'exp_avg': tensor([-6.9493e-03, -5.9668e-03, -7.8536e-04, -1.0124e-03,  2.8119e-03,\n",
      "         7.1631e-03,  7.7794e-03, -5.5362e-03,  2.2227e-04, -5.3385e-03,\n",
      "         2.1596e-03,  1.4851e-03, -4.7207e-03, -1.8074e-03, -1.1553e-02,\n",
      "         9.9574e-05,  3.4415e-03,  5.5069e-03, -3.0697e-04, -3.4596e-03,\n",
      "        -7.2972e-03,  2.3906e-03,  2.1187e-03, -7.4342e-03,  8.9352e-03,\n",
      "        -1.1199e-02, -2.4120e-05,  7.8533e-03,  2.3503e-04,  1.9164e-03,\n",
      "        -2.9931e-03, -7.6355e-03,  2.6248e-03,  1.2155e-04,  3.5467e-03,\n",
      "         5.2337e-03, -4.2014e-03, -2.1297e-03, -4.2279e-03,  5.3513e-03,\n",
      "         5.7589e-03,  5.2745e-03,  3.0935e-03, -3.6750e-03,  3.4428e-03,\n",
      "        -3.3324e-03,  1.5934e-03, -8.7230e-03, -3.2074e-03, -1.0958e-04,\n",
      "         7.1509e-04,  5.7898e-03, -3.0935e-04, -4.4883e-03,  4.4205e-03,\n",
      "         1.4374e-04,  3.4905e-03,  4.0391e-04, -3.3441e-03,  8.9007e-03,\n",
      "        -4.5261e-03,  8.5169e-03, -3.9156e-04,  1.8233e-03], device='cuda:0'), 'exp_avg_sq': tensor([0.0003, 0.0006, 0.0006, 0.0006, 0.0004, 0.0006, 0.0004, 0.0002, 0.0003,\n",
      "        0.0003, 0.0004, 0.0003, 0.0004, 0.0006, 0.0004, 0.0003, 0.0003, 0.0010,\n",
      "        0.0005, 0.0004, 0.0005, 0.0003, 0.0004, 0.0004, 0.0005, 0.0007, 0.0003,\n",
      "        0.0004, 0.0007, 0.0003, 0.0002, 0.0003, 0.0002, 0.0004, 0.0002, 0.0003,\n",
      "        0.0004, 0.0002, 0.0003, 0.0002, 0.0003, 0.0003, 0.0003, 0.0003, 0.0004,\n",
      "        0.0003, 0.0003, 0.0003, 0.0006, 0.0007, 0.0003, 0.0004, 0.0003, 0.0003,\n",
      "        0.0003, 0.0004, 0.0003, 0.0002, 0.0006, 0.0003, 0.0004, 0.0005, 0.0004,\n",
      "        0.0003], device='cuda:0')}, 140402548531992: {'step': 23620, 'exp_avg': tensor([-5.3467e-03, -4.4442e-03,  3.7735e-03,  7.5731e-04, -1.5499e-04,\n",
      "         6.5804e-03,  5.4774e-03, -6.5662e-03, -1.6781e-03, -5.7246e-03,\n",
      "         9.9263e-04,  6.7937e-04, -2.8624e-03, -6.7363e-04, -6.9869e-03,\n",
      "         1.8000e-05,  9.5254e-04,  1.8216e-03,  6.9076e-04, -3.1245e-03,\n",
      "        -3.5891e-03, -1.8808e-04,  1.3787e-03, -3.2579e-03,  5.7912e-03,\n",
      "        -5.5333e-03, -4.4782e-03,  3.3325e-03,  1.3963e-03,  2.1140e-03,\n",
      "        -1.8764e-03, -5.3950e-03,  1.0623e-03,  4.7178e-03,  2.3794e-03,\n",
      "         4.9943e-03, -2.0520e-03, -3.1349e-03, -4.8880e-04,  4.8335e-03,\n",
      "         5.3921e-03,  2.4309e-04,  2.7595e-03, -3.4861e-03,  5.5474e-04,\n",
      "        -3.4833e-03,  1.4907e-03, -6.4068e-03, -1.7121e-03, -8.7929e-04,\n",
      "        -4.2622e-04,  4.6498e-03,  6.4644e-04, -1.1074e-03,  1.1347e-03,\n",
      "         8.1820e-04,  3.6467e-03,  2.2395e-03, -3.2721e-03,  3.6214e-03,\n",
      "         1.3489e-03,  2.7166e-03, -1.5501e-03,  3.2518e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.8873e-04, 2.7814e-04, 2.8517e-04, 2.3349e-04, 2.3178e-04, 2.3870e-04,\n",
      "        1.8016e-04, 1.4296e-04, 1.5474e-04, 2.1951e-04, 1.6825e-04, 2.2420e-04,\n",
      "        2.3589e-04, 2.3227e-04, 1.9202e-04, 2.0410e-04, 1.8720e-04, 3.2063e-04,\n",
      "        2.0439e-04, 1.9928e-04, 2.5294e-04, 1.9335e-04, 2.2210e-04, 2.1722e-04,\n",
      "        2.5626e-04, 2.6385e-04, 2.1934e-04, 2.2624e-04, 3.2664e-04, 1.8942e-04,\n",
      "        1.7248e-04, 1.5721e-04, 1.2066e-04, 2.5410e-04, 1.5220e-04, 1.4914e-04,\n",
      "        2.0343e-04, 8.9441e-05, 1.7931e-04, 1.7046e-04, 2.1977e-04, 1.9117e-04,\n",
      "        1.8878e-04, 1.9585e-04, 1.9276e-04, 1.9045e-04, 1.4184e-04, 1.7925e-04,\n",
      "        2.8804e-04, 2.7147e-04, 1.7511e-04, 1.8081e-04, 1.6138e-04, 2.0484e-04,\n",
      "        1.8971e-04, 2.5365e-04, 1.8805e-04, 1.3876e-04, 2.0513e-04, 2.0213e-04,\n",
      "        2.2842e-04, 2.1624e-04, 1.7959e-04, 1.5383e-04], device='cuda:0')}, 140402548531488: {'step': 23620, 'exp_avg': tensor([[-4.9863e-04, -1.6473e-04, -1.0984e-04,  ..., -7.0925e-05,\n",
      "         -5.9149e-05, -9.6619e-05],\n",
      "        [-9.6902e-05, -9.5249e-05,  1.1349e-04,  ..., -1.4675e-04,\n",
      "         -9.9830e-05,  4.5773e-06],\n",
      "        [ 5.3710e-04,  7.2016e-05,  1.5901e-04,  ..., -4.1096e-05,\n",
      "          6.1970e-05,  6.3461e-05],\n",
      "        ...,\n",
      "        [-1.5889e-04, -7.0550e-05, -7.1164e-05,  ..., -5.3121e-05,\n",
      "         -8.8833e-05,  1.3639e-05],\n",
      "        [-1.6686e-04, -1.2928e-05, -2.0422e-04,  ...,  1.1218e-04,\n",
      "         -2.4392e-07,  7.9807e-05],\n",
      "        [-5.6959e-05,  7.4751e-07, -3.6355e-05,  ...,  1.1389e-04,\n",
      "          4.9039e-06, -5.8396e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[3.9070e-07, 2.1268e-07, 2.0771e-07,  ..., 1.4883e-07, 8.8892e-08,\n",
      "         9.8844e-08],\n",
      "        [4.0651e-07, 1.6055e-07, 1.3346e-07,  ..., 1.1164e-07, 8.0749e-08,\n",
      "         8.6944e-08],\n",
      "        [7.1446e-07, 3.0346e-07, 3.9079e-07,  ..., 2.1010e-07, 1.4299e-07,\n",
      "         1.5030e-07],\n",
      "        ...,\n",
      "        [1.8026e-07, 1.1453e-07, 1.5441e-07,  ..., 9.2773e-08, 8.6950e-08,\n",
      "         7.3557e-08],\n",
      "        [1.5967e-07, 6.3205e-08, 1.9035e-07,  ..., 1.0459e-07, 1.0420e-07,\n",
      "         6.8385e-08],\n",
      "        [2.3019e-07, 2.3408e-07, 2.6314e-07,  ..., 1.2712e-07, 9.5700e-08,\n",
      "         8.5372e-08]], device='cuda:0')}, 140402548534080: {'step': 23620, 'exp_avg': tensor([ 4.1703e-11, -8.1887e-11, -2.5545e-11,  6.8619e-11,  7.6421e-11,\n",
      "         4.3473e-11,  7.0954e-11,  1.8550e-10,  6.5286e-11,  2.2934e-11,\n",
      "        -1.1146e-11,  7.1072e-11,  3.7315e-12,  3.4570e-11, -2.1699e-11,\n",
      "         3.7755e-11, -8.8776e-11,  1.0689e-12, -4.4618e-11,  2.5851e-11,\n",
      "        -3.7372e-11,  6.5164e-11, -1.8134e-11, -7.5627e-11, -3.0595e-11,\n",
      "        -4.1512e-12, -7.3596e-12, -8.4810e-12, -2.6531e-11,  2.3632e-11,\n",
      "         2.8331e-11, -2.3427e-11, -2.6265e-11,  2.6058e-11,  1.9317e-11,\n",
      "        -5.2290e-11,  7.0027e-11,  1.2782e-10, -4.9200e-11,  7.5469e-11,\n",
      "         2.5814e-11, -3.6096e-11, -1.4361e-11,  1.3291e-10,  4.0642e-11,\n",
      "        -8.0857e-11, -1.9171e-11, -9.7773e-11, -2.1564e-11, -2.9860e-11,\n",
      "        -3.3109e-11,  6.0450e-11,  2.5709e-11, -5.8476e-11, -4.8819e-11,\n",
      "        -1.4763e-10, -8.2217e-11,  7.0013e-11, -3.4756e-11,  1.6069e-11,\n",
      "         6.3406e-11,  3.2313e-11,  4.0493e-11,  5.2824e-11,  1.4460e-10,\n",
      "        -1.7180e-10, -5.7752e-11, -6.6630e-11, -1.1205e-10,  1.1344e-10,\n",
      "         7.6586e-11, -7.5853e-11, -1.5038e-11,  1.2784e-11,  4.6119e-11,\n",
      "        -7.7145e-11, -5.6616e-12, -1.1215e-10, -1.3351e-11, -6.3439e-11,\n",
      "         1.2818e-10,  4.7993e-11,  3.7063e-11, -3.3623e-11,  3.5631e-11,\n",
      "        -7.4206e-11, -7.0119e-11, -1.7981e-10, -5.5432e-11,  7.4458e-11,\n",
      "         1.5426e-11,  7.4874e-11,  4.1748e-11,  1.9359e-11, -2.7445e-11,\n",
      "        -4.1304e-12,  3.5613e-11,  5.4822e-11, -6.5454e-11,  3.5727e-11,\n",
      "         6.8202e-11,  1.6572e-10,  2.1195e-12,  5.7593e-12, -4.5790e-11,\n",
      "         2.6631e-11,  6.6243e-11,  1.1312e-10, -6.4082e-11,  7.7980e-11,\n",
      "         1.5028e-11, -6.8060e-11,  8.1735e-11,  1.4349e-10, -2.3761e-10,\n",
      "         4.2236e-11, -2.1979e-11, -7.2640e-12, -4.4101e-11, -1.1012e-11,\n",
      "        -2.3022e-11, -8.2337e-11,  7.1836e-11, -6.2572e-11, -1.2919e-10,\n",
      "         1.1103e-10,  1.3951e-10, -5.9154e-12,  9.0894e-11,  8.5635e-11,\n",
      "         2.4006e-10, -1.5143e-10, -1.7047e-10, -8.1299e-11,  4.4586e-11,\n",
      "         2.1886e-11, -1.2724e-10, -4.0033e-11,  1.2861e-10, -8.6673e-12,\n",
      "         2.7017e-12,  5.6975e-11, -3.4975e-11, -1.2230e-12,  6.6754e-11,\n",
      "         9.0030e-11,  2.0545e-10,  1.3971e-10,  3.1129e-11,  1.4917e-10,\n",
      "        -1.9990e-10,  5.8036e-11,  2.9103e-11,  8.6768e-11, -8.7242e-11,\n",
      "        -9.6557e-12,  1.2442e-10, -8.3239e-11,  2.4762e-12,  1.4933e-10,\n",
      "         5.8715e-11,  7.1330e-11, -6.4189e-11, -1.9263e-11,  2.9791e-11,\n",
      "        -4.1649e-11,  4.9387e-11, -8.9388e-11, -7.9115e-12, -1.0283e-11,\n",
      "         5.4746e-12, -1.6913e-12,  6.0183e-11,  4.9534e-11,  1.5871e-10,\n",
      "         2.5279e-11, -1.5575e-10, -6.1971e-11,  8.0530e-11,  2.1110e-11,\n",
      "        -1.0393e-10,  4.9375e-11, -1.4374e-11,  1.7982e-10, -3.4071e-11,\n",
      "         6.5846e-11, -1.2229e-11,  8.6373e-11,  1.6466e-10, -3.2963e-11,\n",
      "        -2.8832e-11,  6.5410e-12,  2.5125e-12, -5.2954e-11, -5.0546e-11,\n",
      "         2.6093e-10,  6.2773e-11, -9.5969e-11, -8.2290e-11,  5.3478e-10,\n",
      "         9.2969e-11, -3.7460e-10, -2.9403e-13,  3.9790e-11, -6.5757e-11,\n",
      "         4.3385e-11,  1.7994e-10,  8.3721e-11,  8.3685e-11, -1.2964e-11,\n",
      "         5.2797e-11, -9.6834e-12,  6.1915e-11, -1.9628e-11, -1.7627e-11,\n",
      "         2.0898e-11,  1.0993e-10, -8.8193e-11, -9.3193e-12,  3.2379e-11,\n",
      "        -3.0930e-11,  1.1617e-10,  2.1001e-11, -1.5099e-10,  6.1339e-11,\n",
      "         1.3787e-11,  7.1867e-12, -2.1494e-10, -5.6052e-45,  9.6109e-11,\n",
      "         2.8223e-11, -4.3415e-12,  1.2296e-10, -9.9768e-11,  2.1920e-11,\n",
      "        -2.2507e-10,  6.6835e-11,  1.0371e-10, -1.3073e-10,  2.5963e-11,\n",
      "        -7.7103e-11, -1.8750e-11,  1.7957e-11, -1.1692e-10, -1.7739e-10,\n",
      "         1.0627e-10, -1.5448e-11,  1.9884e-10,  5.2852e-11,  1.7791e-11,\n",
      "         2.8843e-11, -2.9745e-11,  2.1310e-11, -6.3104e-11,  8.3004e-11,\n",
      "         2.0391e-11], device='cuda:0'), 'exp_avg_sq': tensor([8.3650e-20, 1.1138e-19, 1.5843e-19, 1.7879e-19, 6.7291e-20, 9.1711e-20,\n",
      "        1.5452e-19, 1.2101e-19, 8.4880e-20, 1.4465e-19, 1.1709e-19, 5.6709e-20,\n",
      "        1.5434e-19, 8.9159e-20, 1.1292e-19, 5.0041e-20, 1.7908e-19, 2.0465e-19,\n",
      "        1.7544e-19, 3.6244e-20, 7.1871e-20, 8.1482e-20, 7.8096e-20, 4.4192e-19,\n",
      "        8.4435e-20, 1.0676e-19, 6.6889e-20, 7.8038e-20, 8.0490e-20, 3.0708e-19,\n",
      "        1.1056e-19, 7.8502e-20, 2.0122e-19, 1.1969e-19, 8.5519e-20, 8.6838e-20,\n",
      "        7.4686e-20, 2.2353e-19, 1.2704e-19, 1.4759e-19, 1.4359e-19, 1.9244e-19,\n",
      "        9.5489e-20, 1.7124e-19, 5.1148e-20, 1.3832e-19, 8.3102e-20, 3.4688e-19,\n",
      "        1.0547e-19, 1.8082e-19, 7.7973e-20, 1.4735e-19, 1.7077e-19, 1.1612e-19,\n",
      "        1.7138e-19, 1.2759e-19, 1.4237e-19, 4.5056e-20, 4.6914e-20, 8.6220e-20,\n",
      "        5.4058e-20, 2.0438e-19, 7.2511e-20, 7.3548e-20, 9.6322e-20, 9.1313e-20,\n",
      "        1.3571e-19, 1.6077e-19, 1.0606e-19, 2.3170e-19, 7.2148e-20, 1.2588e-19,\n",
      "        8.7934e-20, 9.5311e-20, 7.3579e-20, 1.0872e-19, 1.0062e-19, 1.3992e-19,\n",
      "        1.9178e-19, 1.7442e-19, 2.5796e-19, 2.2952e-19, 8.5649e-20, 1.7833e-19,\n",
      "        5.7420e-20, 7.0484e-20, 2.2698e-19, 1.1244e-19, 8.0503e-20, 8.1463e-20,\n",
      "        6.7815e-20, 4.2081e-19, 7.4191e-20, 9.5558e-20, 7.7369e-20, 1.3428e-19,\n",
      "        5.0128e-19, 1.1287e-19, 8.6016e-20, 1.5911e-19, 1.2143e-19, 1.2177e-18,\n",
      "        1.1353e-19, 6.0722e-20, 1.1781e-19, 8.5748e-20, 7.4647e-20, 2.5864e-19,\n",
      "        1.1100e-19, 9.0440e-20, 1.3146e-19, 8.4974e-20, 1.1930e-19, 1.3503e-19,\n",
      "        4.6393e-19, 1.2994e-19, 8.4558e-20, 8.0301e-20, 1.5190e-19, 9.4633e-20,\n",
      "        5.3095e-20, 4.6277e-19, 1.2607e-19, 1.0486e-19, 9.5524e-20, 1.5023e-19,\n",
      "        1.9624e-19, 1.3604e-19, 2.7215e-19, 1.5207e-19, 1.5052e-19, 1.9277e-19,\n",
      "        1.7348e-19, 1.0172e-19, 1.6782e-19, 1.4032e-19, 1.6200e-19, 2.2106e-19,\n",
      "        1.5493e-19, 3.3774e-19, 1.1074e-19, 1.0145e-19, 1.5029e-19, 1.6114e-19,\n",
      "        1.8428e-19, 1.1225e-19, 1.5946e-19, 1.7865e-19, 5.0726e-19, 8.3307e-20,\n",
      "        8.1011e-20, 1.4773e-19, 1.1830e-19, 2.5116e-19, 1.1896e-19, 1.1054e-19,\n",
      "        1.2802e-19, 1.0299e-19, 6.4418e-20, 2.5070e-19, 1.7767e-19, 4.4567e-19,\n",
      "        7.8205e-20, 7.4489e-20, 1.0722e-19, 8.7187e-20, 5.1663e-20, 1.8473e-19,\n",
      "        5.1676e-20, 1.1624e-19, 3.7776e-20, 1.4675e-19, 5.5085e-20, 8.5215e-20,\n",
      "        5.5317e-20, 6.7946e-20, 5.4539e-20, 6.0393e-20, 1.3882e-19, 6.3877e-20,\n",
      "        1.1753e-19, 1.0529e-19, 1.1563e-19, 1.2168e-19, 1.9449e-19, 6.8439e-20,\n",
      "        7.3071e-20, 1.2485e-19, 1.4016e-19, 3.7426e-20, 5.2558e-20, 6.5515e-20,\n",
      "        8.5607e-20, 9.6989e-20, 3.6724e-19, 1.7363e-19, 3.8846e-20, 2.1748e-19,\n",
      "        8.7026e-20, 1.8783e-18, 2.2605e-19, 4.1952e-19, 6.7097e-20, 2.0163e-19,\n",
      "        1.9382e-19, 2.0837e-19, 2.0963e-19, 5.0405e-20, 1.1507e-19, 1.2234e-19,\n",
      "        7.1402e-20, 7.8321e-20, 1.5779e-19, 2.4534e-19, 6.2956e-20, 1.8475e-19,\n",
      "        7.1655e-20, 2.9496e-19, 5.7735e-20, 8.9697e-20, 1.1848e-19, 1.1023e-19,\n",
      "        8.3427e-20, 9.9330e-20, 9.2316e-20, 1.5644e-19, 8.0510e-20, 7.8550e-20,\n",
      "        5.6762e-34, 4.7436e-20, 9.0952e-20, 1.0115e-19, 2.1976e-19, 1.6998e-19,\n",
      "        1.1802e-19, 3.1180e-19, 7.7443e-20, 7.0035e-20, 5.8688e-20, 1.6242e-19,\n",
      "        4.0161e-20, 9.5330e-20, 1.1830e-19, 2.5258e-19, 1.0989e-19, 1.6300e-19,\n",
      "        1.1032e-19, 2.0021e-19, 1.4022e-19, 2.3799e-19, 1.0283e-19, 7.3848e-20,\n",
      "        1.5459e-19, 8.8859e-20, 1.7267e-19, 6.4358e-20], device='cuda:0')}, 140402548535232: {'step': 23620, 'exp_avg': tensor([ 3.2472e-04, -3.5696e-04,  2.4294e-03,  8.1591e-04,  7.5428e-04,\n",
      "        -1.1081e-03, -2.0370e-04, -8.5100e-04,  1.7426e-04, -5.5177e-04,\n",
      "        -3.7395e-04,  1.2908e-03, -6.1514e-04, -2.6598e-04,  9.3498e-04,\n",
      "         1.0569e-03,  1.0339e-03, -1.0849e-03,  1.6920e-03, -8.3142e-04,\n",
      "         1.4975e-03, -5.4320e-04, -4.5669e-04,  6.2793e-05, -2.3415e-04,\n",
      "         5.4526e-04,  1.3823e-04, -6.1944e-04,  9.2591e-05,  9.0547e-04,\n",
      "        -1.6012e-04, -2.3854e-04,  1.3887e-04, -4.4271e-04,  1.4601e-04,\n",
      "         3.1348e-04, -1.6705e-04, -1.1814e-03, -1.7787e-04, -7.1773e-04,\n",
      "         4.4223e-03,  1.3364e-03, -4.0331e-05, -1.8647e-03,  8.9290e-04,\n",
      "        -1.2424e-04,  8.7509e-04,  1.9056e-04, -1.0820e-03,  7.9743e-05,\n",
      "        -3.3398e-04, -1.1785e-03,  1.7784e-04,  5.9947e-04,  4.5430e-04,\n",
      "        -1.9883e-03, -4.6166e-04,  4.1740e-04,  8.8827e-04,  5.3675e-04,\n",
      "        -2.9160e-05, -9.4474e-04, -2.0351e-05,  8.0464e-04,  1.4613e-03,\n",
      "        -2.1693e-04,  6.4674e-04,  2.3999e-04,  2.7466e-04, -1.0272e-03,\n",
      "         3.7017e-04,  1.2578e-03,  5.5117e-04, -6.2104e-05,  2.6597e-04,\n",
      "         8.3883e-04,  7.7269e-05,  9.7675e-04,  1.9524e-03, -2.0127e-04,\n",
      "         1.1317e-03, -1.2433e-04,  1.3408e-03, -2.4154e-04, -4.2485e-04,\n",
      "         2.6354e-04,  2.7588e-04,  3.2738e-04, -6.4374e-04, -4.6127e-04,\n",
      "        -2.6719e-03,  4.6052e-04, -1.5098e-03, -2.8641e-04,  3.7032e-04,\n",
      "        -9.6306e-04,  4.8433e-04,  2.7883e-04,  1.2655e-04, -1.5238e-03,\n",
      "         1.9171e-04, -9.7917e-04, -8.3258e-04, -1.0488e-03,  9.9376e-04,\n",
      "        -7.5348e-04, -6.3642e-04,  9.9871e-04, -5.1285e-04,  4.6871e-04,\n",
      "        -1.3838e-04,  4.7376e-04,  1.0423e-03, -2.7132e-04,  1.0676e-03,\n",
      "        -2.7152e-04,  1.7796e-03, -6.4132e-04, -2.9203e-04, -8.3935e-05,\n",
      "        -2.3213e-03, -2.9046e-04,  3.3086e-04,  6.8799e-04,  9.5960e-04,\n",
      "        -2.0762e-03,  4.4064e-04, -7.8426e-04, -7.3011e-04, -1.0490e-03,\n",
      "         1.8061e-03,  3.0745e-04,  6.6616e-04,  2.5697e-04, -2.3710e-03,\n",
      "        -4.5844e-04, -5.7559e-04,  3.3243e-04,  1.5823e-04, -3.8628e-04,\n",
      "        -6.6855e-04,  1.4614e-04,  2.2531e-04,  9.0408e-05, -5.8739e-04,\n",
      "        -5.9661e-04, -5.6382e-04, -7.7465e-04,  5.5156e-04,  1.4115e-03,\n",
      "         9.1525e-04,  6.4367e-04,  2.5046e-04, -4.8187e-05,  2.6147e-04,\n",
      "        -8.6658e-04,  9.2612e-04,  8.7166e-04,  5.8414e-04, -1.2964e-03,\n",
      "         4.9877e-04,  1.0695e-03, -2.1489e-04,  3.7383e-05, -6.0354e-04,\n",
      "        -9.3471e-05,  1.0764e-05, -3.8714e-04,  4.1074e-04,  8.2935e-04,\n",
      "        -1.1761e-03,  2.3448e-04,  1.6007e-04,  1.9346e-04,  3.5130e-04,\n",
      "         4.5249e-04, -4.5616e-04, -1.7674e-04,  3.1190e-04,  1.7975e-04,\n",
      "         5.8314e-04,  4.1021e-04, -5.5315e-04, -1.7039e-03, -2.1954e-04,\n",
      "         8.7192e-04,  2.3469e-03,  2.7922e-04,  4.8152e-04,  2.5644e-05,\n",
      "        -1.6024e-03,  1.7281e-03,  1.0706e-03, -2.5189e-05,  1.2042e-03,\n",
      "         1.2574e-03,  2.5851e-05, -1.3135e-03, -1.0204e-03,  1.1416e-03,\n",
      "        -6.7605e-04, -1.3751e-03,  1.0713e-04,  6.2394e-05, -1.1408e-04,\n",
      "        -4.1653e-04, -2.1190e-03,  1.0817e-03,  4.3946e-04, -4.0502e-04,\n",
      "        -3.3347e-04,  2.1362e-04,  7.7423e-04, -1.0153e-03,  5.0588e-04,\n",
      "        -1.9566e-04,  3.8614e-04,  2.3784e-04, -8.9454e-04,  5.2840e-04,\n",
      "         4.3816e-04,  1.1493e-03,  9.6960e-05, -4.3067e-04,  4.8503e-04,\n",
      "        -1.1521e-03, -1.0430e-03,  1.5399e-03,  5.6052e-45, -1.5845e-04,\n",
      "         1.0103e-04, -7.5519e-04,  3.7171e-05, -1.0294e-04,  2.2375e-04,\n",
      "         1.6420e-04, -7.6257e-05, -2.8191e-05,  6.1674e-04,  3.7053e-04,\n",
      "         1.8002e-03,  1.0916e-04, -7.5097e-04, -3.1512e-04, -1.0347e-03,\n",
      "        -5.1025e-04, -4.9895e-04,  1.7102e-04,  1.1861e-03,  1.6807e-03,\n",
      "         2.8161e-04, -1.7191e-03, -1.7993e-05,  1.0296e-04, -1.1852e-03,\n",
      "         5.1281e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.5359e-05, 1.3653e-05, 2.4404e-05, 2.3833e-05, 1.4837e-05, 7.3490e-06,\n",
      "        8.6916e-06, 1.7101e-05, 1.2295e-05, 2.4891e-05, 1.3444e-05, 1.7693e-05,\n",
      "        2.8676e-05, 1.1144e-05, 1.4502e-05, 1.5912e-05, 1.4739e-05, 9.9143e-06,\n",
      "        2.8990e-05, 1.2892e-05, 1.9268e-05, 1.3794e-05, 8.7793e-06, 2.0409e-05,\n",
      "        9.4962e-06, 9.0355e-06, 1.4289e-05, 1.1212e-05, 1.4658e-05, 2.2661e-05,\n",
      "        9.3662e-06, 1.8157e-05, 1.6219e-05, 8.9903e-06, 1.3628e-05, 6.9059e-06,\n",
      "        1.2976e-05, 2.1714e-05, 1.1035e-05, 1.8750e-05, 2.7642e-05, 1.8410e-05,\n",
      "        1.1701e-05, 1.1036e-05, 1.1289e-05, 1.0370e-05, 9.1898e-06, 1.5930e-05,\n",
      "        9.8539e-06, 1.0372e-05, 1.7360e-05, 1.1364e-05, 1.9797e-05, 1.4854e-05,\n",
      "        2.5766e-05, 9.5464e-06, 1.6415e-05, 1.0579e-05, 2.0542e-05, 1.3005e-05,\n",
      "        7.7119e-06, 1.8361e-05, 1.9624e-05, 8.1842e-06, 1.1555e-05, 1.3466e-05,\n",
      "        2.4298e-05, 1.3623e-05, 1.1642e-05, 2.1347e-05, 8.2205e-06, 2.6228e-05,\n",
      "        2.2884e-05, 1.3054e-05, 5.2140e-06, 1.7000e-05, 1.7731e-05, 9.8427e-06,\n",
      "        1.6848e-05, 2.1140e-05, 1.5497e-05, 1.4852e-05, 2.4966e-05, 2.0751e-05,\n",
      "        1.2281e-05, 2.6305e-05, 2.1747e-05, 1.9271e-05, 2.1285e-05, 1.4905e-05,\n",
      "        2.0430e-05, 2.0846e-05, 1.5585e-05, 1.3897e-05, 5.3884e-06, 1.5572e-05,\n",
      "        1.6292e-05, 2.1687e-05, 1.6502e-05, 2.5685e-05, 8.2696e-06, 3.3078e-05,\n",
      "        1.1781e-05, 9.1260e-06, 1.9490e-05, 1.0834e-05, 2.7168e-05, 1.4638e-05,\n",
      "        1.0904e-05, 9.9496e-06, 1.1244e-05, 1.0931e-05, 1.1874e-05, 1.5162e-05,\n",
      "        1.6438e-05, 1.2654e-05, 1.0799e-05, 1.4642e-05, 2.4143e-05, 2.1318e-05,\n",
      "        1.1948e-05, 1.9868e-05, 2.0788e-05, 1.6209e-05, 2.5658e-05, 1.6736e-05,\n",
      "        1.4335e-05, 1.0216e-05, 3.4075e-05, 1.6629e-05, 1.4160e-05, 8.4299e-06,\n",
      "        9.1299e-06, 1.4818e-05, 9.7772e-06, 2.5261e-05, 9.2162e-06, 1.1607e-05,\n",
      "        1.1236e-05, 1.3042e-05, 1.4557e-05, 1.4018e-05, 1.1802e-05, 2.4995e-05,\n",
      "        2.2809e-05, 1.5047e-05, 1.1691e-05, 1.3926e-05, 1.8608e-05, 8.1318e-06,\n",
      "        1.2684e-05, 1.6465e-05, 7.2372e-06, 2.7525e-05, 9.8217e-06, 8.6253e-06,\n",
      "        1.0607e-05, 1.7981e-05, 1.9531e-05, 1.8112e-05, 1.9283e-05, 2.8924e-05,\n",
      "        2.7948e-05, 8.0511e-06, 9.5033e-06, 2.1326e-05, 1.2268e-05, 1.5394e-05,\n",
      "        1.4535e-05, 9.9452e-06, 8.6907e-06, 1.0659e-05, 6.5917e-06, 8.7481e-06,\n",
      "        8.9873e-06, 1.9271e-05, 5.8407e-06, 1.5386e-05, 1.4583e-05, 1.0685e-05,\n",
      "        1.6403e-05, 1.2441e-05, 9.6491e-06, 8.1906e-06, 9.6752e-06, 1.6579e-05,\n",
      "        2.4622e-05, 2.5340e-05, 1.2337e-05, 1.1666e-05, 3.6452e-05, 2.0425e-05,\n",
      "        9.9211e-06, 1.0682e-05, 1.7585e-05, 1.2063e-05, 1.5504e-05, 2.3736e-05,\n",
      "        1.1374e-05, 6.2763e-05, 2.1905e-05, 1.6307e-05, 7.6848e-06, 1.4445e-05,\n",
      "        1.9388e-05, 1.9438e-05, 1.6054e-05, 1.2108e-05, 1.4130e-05, 1.0393e-05,\n",
      "        1.7823e-05, 2.6355e-05, 1.5865e-05, 1.3244e-05, 1.1382e-05, 1.9639e-05,\n",
      "        1.0946e-05, 1.5439e-05, 1.8802e-05, 1.4437e-05, 1.8906e-05, 1.6737e-05,\n",
      "        9.5538e-06, 2.3827e-05, 1.7094e-05, 1.2711e-05, 1.3386e-05, 1.7696e-05,\n",
      "        8.3257e-18, 7.8591e-06, 7.8581e-06, 1.0400e-05, 1.8365e-05, 1.2389e-05,\n",
      "        8.3877e-06, 9.7508e-06, 1.6571e-05, 1.3081e-05, 1.9199e-05, 2.0896e-05,\n",
      "        1.1588e-05, 2.3727e-05, 1.6437e-05, 3.1158e-05, 9.9477e-06, 1.6577e-05,\n",
      "        1.5975e-05, 1.4124e-05, 1.2859e-05, 1.3364e-05, 8.4310e-06, 1.3410e-05,\n",
      "        2.4309e-05, 8.5696e-06, 1.0029e-05, 1.0096e-05], device='cuda:0')}, 140402548535160: {'step': 23620, 'exp_avg': tensor([ 3.9981e-04,  5.9655e-04,  1.5615e-03, -1.6448e-04,  1.3966e-03,\n",
      "        -1.3097e-03,  6.3433e-04, -9.0278e-04,  4.5109e-04, -5.8305e-04,\n",
      "        -1.8137e-04,  9.2076e-04, -1.1225e-03, -3.2626e-04,  1.3453e-03,\n",
      "         2.1540e-04,  1.0039e-03, -1.0951e-03,  1.4499e-03, -7.9240e-04,\n",
      "         1.7920e-03, -8.7497e-04, -3.0681e-04, -2.5678e-04, -1.5856e-04,\n",
      "         5.6841e-04, -2.7458e-04, -4.7092e-04, -4.8150e-04,  1.4304e-03,\n",
      "         1.8993e-04,  3.8536e-05,  1.8877e-04, -7.1608e-04, -1.0914e-03,\n",
      "         6.6392e-04,  9.7917e-05, -1.1453e-03, -2.5317e-04, -4.8412e-04,\n",
      "         3.8406e-03,  1.6385e-03, -6.4345e-04, -1.6835e-03,  1.0648e-05,\n",
      "         6.5342e-05,  9.8379e-04,  1.8333e-04, -1.6780e-03, -1.4036e-04,\n",
      "        -1.2781e-03, -1.0385e-03,  6.8049e-04,  1.6413e-03,  5.6614e-04,\n",
      "        -2.3993e-03, -1.2292e-04,  1.2554e-03,  6.1098e-04, -7.4489e-04,\n",
      "        -9.6053e-05, -6.2225e-04, -5.6450e-04,  7.2200e-04,  1.6705e-03,\n",
      "        -7.4971e-04,  2.0313e-03, -3.0766e-04,  9.3429e-05, -6.1362e-04,\n",
      "        -1.8009e-04,  6.5006e-04,  6.1726e-04, -2.9975e-04, -3.5002e-05,\n",
      "         1.3933e-03, -6.0179e-04,  1.4128e-03,  1.7271e-03, -2.3991e-04,\n",
      "         5.9309e-04, -6.0630e-04,  1.3657e-03, -2.1213e-04, -2.1205e-04,\n",
      "         6.2778e-04,  1.7875e-04,  6.8440e-04, -9.2969e-04, -6.0476e-04,\n",
      "        -3.0550e-03,  4.3002e-04, -1.2840e-03, -5.5417e-04,  5.3947e-04,\n",
      "        -4.0313e-04,  3.0646e-04,  1.0572e-04, -3.0961e-04, -1.7915e-03,\n",
      "         8.0472e-05, -7.4328e-04, -8.7857e-04, -4.7027e-04,  6.8471e-04,\n",
      "        -1.1434e-03, -3.9898e-04,  1.1358e-03, -6.5752e-04,  5.1279e-04,\n",
      "        -5.9513e-04,  1.0328e-03,  1.9604e-03, -2.2312e-04,  8.1268e-04,\n",
      "         7.1635e-05,  1.0077e-03, -4.4446e-04, -2.4227e-04,  1.9227e-05,\n",
      "        -1.7118e-03, -1.0482e-04,  9.0402e-04,  2.7476e-04,  6.8449e-04,\n",
      "        -2.5834e-03,  4.6925e-04, -1.2142e-03, -4.0715e-04, -9.9274e-04,\n",
      "         1.6130e-03,  6.7758e-04,  9.9444e-04,  2.6899e-04, -2.6972e-03,\n",
      "         1.4868e-04, -1.0731e-03,  1.5300e-04,  7.4170e-04, -1.3063e-04,\n",
      "         2.2531e-04,  4.2461e-04,  4.2114e-04, -1.8324e-04, -1.9682e-04,\n",
      "        -1.3384e-04, -3.8165e-04, -8.5677e-04,  5.3885e-04,  1.3052e-03,\n",
      "         2.6407e-04,  9.3334e-04, -1.3860e-04,  1.8290e-04,  5.7764e-04,\n",
      "        -7.9209e-04,  2.7107e-04,  5.9879e-04,  5.8490e-04, -1.6088e-03,\n",
      "         1.2497e-03,  1.3315e-03, -4.3149e-04, -3.3678e-04, -1.5963e-04,\n",
      "        -2.7740e-04,  1.0033e-03, -9.8409e-04,  5.3412e-04,  1.1307e-03,\n",
      "        -1.3727e-03,  9.1170e-05,  2.2541e-03, -1.7749e-04,  3.3074e-04,\n",
      "         7.5199e-04, -1.4169e-03,  1.1402e-03,  7.1380e-05,  4.6025e-04,\n",
      "         1.6759e-03,  6.3024e-04, -9.0472e-04, -1.7810e-03, -3.8335e-04,\n",
      "         1.4795e-03,  1.8211e-03,  5.4500e-04,  3.4272e-05,  2.5052e-04,\n",
      "        -1.2159e-03,  2.0865e-03,  1.2626e-03,  5.9136e-04,  1.0656e-03,\n",
      "         1.5676e-03,  3.0505e-05, -1.0004e-03, -1.4712e-03,  8.5620e-04,\n",
      "        -8.1270e-04, -1.2992e-03,  3.2425e-06, -1.0632e-04, -1.9309e-04,\n",
      "        -2.3734e-04, -8.4987e-04,  1.8225e-03,  1.5000e-04, -1.2974e-04,\n",
      "        -2.2534e-04,  2.8217e-04,  3.5487e-04, -1.2404e-03,  2.9202e-04,\n",
      "         1.1226e-04, -3.1243e-04,  2.5587e-04,  3.1517e-04,  6.4867e-04,\n",
      "         3.5447e-04,  1.4088e-03,  6.3535e-04, -2.6273e-04, -1.4911e-04,\n",
      "        -1.3399e-03, -1.2375e-03,  3.0193e-03,  5.6052e-45,  9.2130e-04,\n",
      "         4.6344e-04, -1.1290e-03, -5.7240e-05, -2.0030e-05, -2.9678e-05,\n",
      "         4.7747e-04, -4.1541e-05, -3.1808e-04, -7.8497e-05,  3.7003e-04,\n",
      "         1.1170e-03,  2.0303e-04, -4.6461e-04, -1.8901e-04, -2.0848e-03,\n",
      "        -6.4163e-04, -3.5903e-04,  1.0723e-04,  2.4404e-03,  2.2209e-03,\n",
      "         5.5616e-04, -1.7126e-03,  5.4701e-04,  8.9330e-04, -7.5032e-04,\n",
      "         6.1636e-04], device='cuda:0'), 'exp_avg_sq': tensor([2.8309e-05, 1.8306e-05, 2.0572e-05, 2.7744e-05, 1.5757e-05, 1.2096e-05,\n",
      "        1.0567e-05, 1.9886e-05, 1.1925e-05, 3.2254e-05, 1.5369e-05, 2.1654e-05,\n",
      "        2.9541e-05, 9.2324e-06, 1.3055e-05, 2.8198e-05, 1.9504e-05, 1.1606e-05,\n",
      "        3.3084e-05, 2.2900e-05, 1.7024e-05, 1.5627e-05, 1.7190e-05, 2.4721e-05,\n",
      "        1.2093e-05, 1.3231e-05, 1.9540e-05, 2.2906e-05, 2.7855e-05, 1.9806e-05,\n",
      "        1.4018e-05, 3.4903e-05, 1.2847e-05, 1.3366e-05, 2.2159e-05, 1.1934e-05,\n",
      "        1.4013e-05, 2.1672e-05, 1.3455e-05, 1.7955e-05, 2.6448e-05, 3.2396e-05,\n",
      "        1.7974e-05, 1.0319e-05, 1.7319e-05, 1.0218e-05, 8.8077e-06, 1.4103e-05,\n",
      "        9.9417e-06, 1.1327e-05, 2.2907e-05, 1.6559e-05, 2.4614e-05, 2.3953e-05,\n",
      "        2.7482e-05, 1.1939e-05, 1.5599e-05, 2.6578e-05, 2.5861e-05, 1.9436e-05,\n",
      "        1.5044e-05, 1.7715e-05, 2.7493e-05, 9.3541e-06, 1.5788e-05, 1.7980e-05,\n",
      "        2.6675e-05, 1.2451e-05, 2.2007e-05, 1.6906e-05, 8.6476e-06, 2.1200e-05,\n",
      "        2.2061e-05, 2.0714e-05, 1.1742e-05, 1.9375e-05, 2.3805e-05, 2.0472e-05,\n",
      "        1.8020e-05, 1.4201e-05, 1.6297e-05, 1.7140e-05, 3.2495e-05, 2.0374e-05,\n",
      "        2.9950e-05, 3.1412e-05, 1.6206e-05, 2.1978e-05, 3.9665e-05, 3.2742e-05,\n",
      "        2.4695e-05, 2.4431e-05, 1.3745e-05, 1.7403e-05, 1.2189e-05, 1.9797e-05,\n",
      "        1.4868e-05, 3.6146e-05, 2.5420e-05, 2.3258e-05, 1.1498e-05, 2.1913e-05,\n",
      "        2.0403e-05, 1.6846e-05, 1.5319e-05, 2.1036e-05, 3.1127e-05, 1.1581e-05,\n",
      "        1.2758e-05, 1.5026e-05, 1.7366e-05, 1.7283e-05, 2.4314e-05, 2.2788e-05,\n",
      "        1.5209e-05, 1.3321e-05, 1.2329e-05, 2.2867e-05, 2.9328e-05, 1.9740e-05,\n",
      "        1.3056e-05, 1.7685e-05, 2.2613e-05, 1.8312e-05, 2.1680e-05, 1.4967e-05,\n",
      "        1.6292e-05, 1.4895e-05, 2.2029e-05, 1.8502e-05, 1.5416e-05, 1.0023e-05,\n",
      "        9.4907e-06, 1.1281e-05, 1.1368e-05, 3.3088e-05, 1.5764e-05, 1.3782e-05,\n",
      "        1.2755e-05, 1.6157e-05, 2.8394e-05, 1.5568e-05, 1.4937e-05, 2.0210e-05,\n",
      "        2.3004e-05, 1.4707e-05, 1.5932e-05, 1.6038e-05, 1.2335e-05, 1.0842e-05,\n",
      "        2.1463e-05, 2.4772e-05, 1.5493e-05, 1.7298e-05, 1.2876e-05, 1.3669e-05,\n",
      "        1.0288e-05, 1.6713e-05, 1.4630e-05, 1.7597e-05, 2.7598e-05, 2.4353e-05,\n",
      "        3.0797e-05, 1.8527e-05, 1.2159e-05, 1.8696e-05, 2.6116e-05, 1.7889e-05,\n",
      "        2.0039e-05, 1.3142e-05, 1.8398e-05, 1.3437e-05, 1.8224e-05, 1.2585e-05,\n",
      "        1.9056e-05, 2.8483e-05, 8.6127e-06, 3.0667e-05, 1.9284e-05, 1.6975e-05,\n",
      "        2.8270e-05, 1.1251e-05, 1.5057e-05, 1.5144e-05, 1.2695e-05, 3.1486e-05,\n",
      "        3.0842e-05, 3.7159e-05, 1.4524e-05, 1.4780e-05, 2.8352e-05, 3.1701e-05,\n",
      "        1.3534e-05, 1.8342e-05, 1.6146e-05, 1.2225e-05, 1.9939e-05, 3.4404e-05,\n",
      "        1.9799e-05, 2.1735e-05, 2.1613e-05, 1.8715e-05, 1.0252e-05, 1.9508e-05,\n",
      "        1.5699e-05, 2.3433e-05, 1.8876e-05, 2.1439e-05, 1.6460e-05, 1.3945e-05,\n",
      "        2.4246e-05, 2.8449e-05, 2.2878e-05, 1.3152e-05, 2.2916e-05, 1.8640e-05,\n",
      "        1.5816e-05, 1.6363e-05, 3.2214e-05, 2.1948e-05, 3.0930e-05, 2.7637e-05,\n",
      "        1.6617e-05, 2.6163e-05, 1.7351e-05, 1.9718e-05, 2.6717e-05, 2.0510e-05,\n",
      "        7.4387e-18, 1.7591e-05, 8.1522e-06, 1.2443e-05, 1.2331e-05, 1.3542e-05,\n",
      "        9.4395e-06, 9.9920e-06, 2.5325e-05, 2.4421e-05, 2.8181e-05, 1.9505e-05,\n",
      "        1.3836e-05, 2.3349e-05, 2.6786e-05, 2.5753e-05, 1.5767e-05, 1.4326e-05,\n",
      "        3.0605e-05, 1.8769e-05, 1.6367e-05, 1.6967e-05, 1.1124e-05, 2.0378e-05,\n",
      "        2.9743e-05, 1.7788e-05, 1.5312e-05, 1.5241e-05], device='cuda:0')}, 140402548532064: {'step': 23620, 'exp_avg': tensor([[ 1.8119e-05,  3.9050e-05,  2.1846e-05,  ...,  6.5921e-05,\n",
      "          5.5509e-05,  2.4740e-05],\n",
      "        [-7.2794e-05, -2.0552e-06,  3.2788e-06,  ...,  7.3895e-05,\n",
      "         -1.2070e-04, -7.9585e-05],\n",
      "        [ 3.2207e-05, -1.3845e-05,  7.2914e-06,  ...,  2.6894e-05,\n",
      "         -8.8168e-06,  5.1961e-05],\n",
      "        ...,\n",
      "        [-2.4227e-05, -6.0796e-05,  2.1039e-05,  ..., -9.6039e-05,\n",
      "         -1.1052e-04, -1.0770e-04],\n",
      "        [-1.4545e-04, -1.2236e-04, -1.5596e-05,  ..., -2.5431e-05,\n",
      "         -3.9739e-05, -6.7098e-05],\n",
      "        [ 6.9717e-05,  1.1276e-05,  7.5882e-06,  ...,  8.6091e-05,\n",
      "          8.0300e-06,  9.6392e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[2.8265e-08, 6.2853e-08, 5.8727e-08,  ..., 1.2441e-07, 4.1481e-08,\n",
      "         6.4669e-08],\n",
      "        [1.6511e-07, 1.5664e-07, 1.0891e-07,  ..., 1.5019e-07, 2.4675e-07,\n",
      "         1.0143e-07],\n",
      "        [9.3877e-08, 8.5181e-08, 7.2908e-08,  ..., 1.2281e-07, 1.7246e-07,\n",
      "         1.2228e-07],\n",
      "        ...,\n",
      "        [8.3370e-08, 1.5063e-07, 8.9556e-08,  ..., 2.0439e-07, 1.7783e-07,\n",
      "         4.6805e-08],\n",
      "        [1.1275e-07, 1.0804e-07, 6.3153e-08,  ..., 5.1313e-08, 2.0304e-07,\n",
      "         8.9510e-08],\n",
      "        [6.4517e-08, 2.8499e-08, 4.2944e-08,  ..., 7.4608e-08, 1.4585e-07,\n",
      "         9.3234e-08]], device='cuda:0')}, 140402548533072: {'step': 23620, 'exp_avg': tensor([-2.6707e-12,  1.3145e-11,  1.5296e-11,  1.6435e-11, -5.5501e-12,\n",
      "         8.1328e-12,  1.7810e-11,  3.0122e-11, -1.3217e-11,  6.3562e-11,\n",
      "         8.3234e-12,  1.9184e-12,  2.3646e-11, -3.0076e-11,  1.5497e-11,\n",
      "        -4.0854e-11,  4.6636e-11, -1.9344e-12, -6.7499e-11,  2.2819e-11,\n",
      "        -5.6052e-45,  4.1986e-13, -2.1700e-11, -4.5945e-11,  2.2135e-11,\n",
      "         6.4808e-12,  4.3200e-11,  2.7546e-11,  2.2021e-11, -2.6158e-11,\n",
      "         2.3249e-11,  1.6780e-11, -2.4923e-11, -7.1868e-14,  3.0219e-11,\n",
      "         2.3320e-11,  2.8854e-12,  1.8050e-11, -5.7876e-12, -4.0834e-11,\n",
      "        -3.0638e-11, -2.9625e-11, -5.2675e-11,  1.2732e-12,  5.2741e-11,\n",
      "        -5.2476e-12,  1.2684e-11, -5.2359e-11, -1.6999e-11, -2.2054e-12,\n",
      "         4.1874e-11, -3.3621e-11, -3.1024e-11,  4.2560e-12, -6.0524e-13,\n",
      "         6.3808e-11, -9.2170e-12,  3.1895e-11,  4.6051e-12, -1.7149e-11,\n",
      "        -1.5980e-11,  8.7533e-12,  1.2462e-11,  9.7646e-12, -4.5640e-11,\n",
      "        -1.4562e-11,  1.3536e-11,  2.9396e-11,  6.3010e-12, -2.4217e-11,\n",
      "         2.4232e-11, -3.5591e-11, -1.7724e-11, -3.1766e-11, -1.0987e-11,\n",
      "         3.5750e-11,  9.4974e-12,  4.6239e-11, -4.2157e-11,  8.9146e-12,\n",
      "         3.0384e-11,  2.6238e-12, -2.0962e-11, -1.2125e-10, -9.9320e-12,\n",
      "         2.7090e-11,  3.7705e-11,  4.4069e-11, -2.1627e-11, -5.1261e-11,\n",
      "        -2.8257e-11,  1.9795e-11,  7.5994e-11,  8.8009e-12, -3.7237e-11,\n",
      "        -7.1007e-13,  1.8080e-12, -2.4797e-11, -9.1793e-11, -1.5556e-11,\n",
      "        -2.4518e-11, -6.3418e-12,  6.7973e-12, -2.3638e-12,  2.6979e-11,\n",
      "         4.3457e-11, -4.7271e-11,  7.9078e-12, -1.5931e-12,  3.9111e-14,\n",
      "        -4.0327e-11,  1.9170e-11, -9.4473e-11,  2.1160e-11, -3.9290e-11,\n",
      "         2.8023e-11,  6.0599e-12, -5.7097e-12,  1.5360e-12,  3.2995e-11,\n",
      "         2.5331e-11,  2.5523e-11,  3.7113e-11,  4.0415e-11, -5.6460e-12,\n",
      "        -8.6369e-11, -3.3790e-11,  6.7892e-12], device='cuda:0'), 'exp_avg_sq': tensor([1.6333e-20, 1.9415e-20, 1.6551e-20, 2.0976e-20, 2.6743e-20, 1.4919e-20,\n",
      "        1.9159e-20, 1.5759e-20, 1.8169e-20, 1.2950e-20, 1.3595e-20, 9.2844e-21,\n",
      "        1.9466e-20, 2.2524e-20, 1.8040e-20, 1.7874e-20, 1.6472e-20, 1.7803e-20,\n",
      "        2.0685e-20, 1.7361e-20, 3.5039e-34, 1.4824e-20, 2.9309e-20, 2.2608e-20,\n",
      "        2.4302e-20, 2.1431e-20, 1.8892e-20, 1.5570e-20, 1.8740e-20, 1.6014e-20,\n",
      "        1.3814e-20, 1.9791e-20, 2.3993e-20, 1.2176e-20, 1.4537e-20, 1.7450e-20,\n",
      "        1.2558e-20, 2.3999e-20, 2.2967e-20, 1.9448e-20, 2.2489e-20, 1.5712e-20,\n",
      "        2.4119e-20, 1.3833e-20, 1.1810e-20, 1.5875e-20, 2.1338e-20, 1.8555e-20,\n",
      "        1.8821e-20, 1.2330e-20, 1.9645e-20, 2.5586e-20, 2.1863e-20, 1.7572e-20,\n",
      "        1.7104e-20, 2.2354e-20, 1.7743e-20, 2.3913e-20, 1.8613e-20, 1.7900e-20,\n",
      "        1.8487e-20, 1.3066e-20, 1.9905e-20, 1.3888e-20, 1.5676e-20, 2.2877e-20,\n",
      "        1.2857e-20, 1.8882e-20, 2.9975e-20, 2.2193e-20, 1.4084e-20, 1.1614e-20,\n",
      "        2.0470e-20, 1.1581e-20, 1.7930e-20, 1.8242e-20, 1.0028e-20, 1.8313e-20,\n",
      "        1.8844e-20, 2.4011e-20, 1.6818e-20, 1.0762e-20, 2.2002e-20, 1.7009e-20,\n",
      "        1.7646e-20, 2.0889e-20, 2.3985e-20, 1.9723e-20, 1.4752e-20, 2.0325e-20,\n",
      "        1.2500e-20, 1.2608e-20, 1.3864e-20, 2.2448e-20, 1.8272e-20, 1.8475e-20,\n",
      "        1.9336e-20, 1.8639e-20, 2.7693e-20, 1.9519e-20, 1.5325e-20, 1.4856e-20,\n",
      "        2.1812e-20, 2.4946e-20, 2.5431e-20, 2.1716e-20, 1.1765e-20, 1.4658e-20,\n",
      "        1.3870e-20, 1.6671e-20, 1.8828e-20, 2.2154e-20, 2.3991e-20, 1.9525e-20,\n",
      "        2.3471e-20, 2.8895e-20, 8.7031e-21, 1.7883e-20, 1.9490e-20, 1.4843e-20,\n",
      "        1.7300e-20, 1.6938e-20, 2.6797e-20, 1.4274e-20, 1.2700e-20, 2.2457e-20,\n",
      "        1.2832e-20, 1.2067e-20], device='cuda:0')}, 140402548535016: {'step': 23620, 'exp_avg': tensor([-2.6196e-04, -5.7030e-05, -4.0394e-04, -2.5156e-04,  5.0445e-04,\n",
      "        -9.6229e-05,  8.0947e-04,  1.2105e-03, -6.3986e-04,  2.9661e-04,\n",
      "        -7.4554e-05, -5.4582e-04, -2.3532e-04,  4.1987e-04, -5.7744e-04,\n",
      "        -1.7368e-05,  9.7342e-05, -2.6479e-05, -6.1189e-04, -9.5060e-04,\n",
      "         5.6052e-45, -2.9408e-04,  5.8242e-06, -2.9820e-04, -2.6494e-04,\n",
      "        -7.8054e-05,  7.6199e-05, -5.8505e-05, -2.7338e-04,  5.3412e-04,\n",
      "         4.5231e-05, -6.7810e-05,  6.2748e-04,  1.8629e-04,  1.1045e-03,\n",
      "         8.1915e-05,  3.1888e-04, -1.5493e-04, -6.7772e-06, -8.7508e-05,\n",
      "         1.3643e-04,  5.3662e-05,  2.4579e-04, -5.5931e-05,  4.4598e-04,\n",
      "         3.7575e-04,  6.9176e-04, -3.5761e-04,  6.8916e-04,  2.9381e-05,\n",
      "         5.1890e-04, -3.8964e-05,  7.9808e-05, -5.5456e-04, -1.0478e-03,\n",
      "        -9.2075e-05, -9.3003e-05, -5.0760e-04,  7.2186e-04, -3.8653e-04,\n",
      "         4.8486e-04,  2.5252e-04, -1.2554e-04,  6.0157e-05,  4.1178e-04,\n",
      "         2.1820e-04, -4.8524e-05,  1.9738e-04,  4.6674e-04,  1.7754e-04,\n",
      "         3.7544e-04,  5.6410e-04,  8.3474e-05,  3.7226e-05, -3.3421e-04,\n",
      "        -9.0917e-05, -9.7030e-05, -3.0432e-04,  8.2670e-04, -3.5855e-04,\n",
      "        -4.0176e-04,  5.9102e-04,  3.1283e-04,  3.5292e-06,  1.0296e-04,\n",
      "        -2.8326e-04,  4.7368e-05, -3.3052e-05, -2.4387e-04, -5.5362e-04,\n",
      "         2.6180e-04,  4.1442e-04,  4.3032e-04, -1.7714e-04,  6.4839e-04,\n",
      "         7.7691e-05, -6.9164e-06, -3.9586e-05,  4.4876e-04,  2.3026e-04,\n",
      "        -2.1468e-04, -2.9198e-04, -4.8219e-04, -3.1257e-04,  4.7758e-05,\n",
      "         5.3338e-04,  2.8934e-05, -5.6934e-05,  1.9993e-04,  2.1022e-04,\n",
      "         4.9224e-04,  1.7552e-04, -2.6066e-04,  1.2343e-03,  1.0221e-03,\n",
      "         1.7657e-04,  5.5262e-05,  2.3571e-04,  1.0268e-05, -4.4734e-04,\n",
      "         1.3697e-04,  1.2301e-04, -1.0265e-03,  3.4441e-04,  2.3896e-04,\n",
      "         3.5807e-04,  6.5223e-04, -2.3053e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.2041e-06, 1.4422e-06, 1.3079e-06, 1.8899e-06, 8.8611e-06, 1.6454e-06,\n",
      "        1.2727e-06, 1.4348e-06, 2.4028e-06, 2.0781e-06, 1.0499e-06, 2.4603e-06,\n",
      "        3.1012e-06, 1.8823e-06, 2.4216e-06, 1.7268e-06, 1.9851e-06, 2.3521e-06,\n",
      "        4.6305e-06, 6.3490e-06, 1.2864e-17, 3.4264e-06, 6.3211e-06, 2.6066e-06,\n",
      "        3.4416e-06, 3.5931e-06, 1.6039e-06, 9.6054e-07, 1.5983e-06, 1.6335e-06,\n",
      "        1.1789e-06, 2.2806e-06, 1.5858e-06, 1.5490e-06, 2.9185e-06, 2.7731e-06,\n",
      "        1.5423e-06, 2.2896e-06, 3.8669e-06, 1.2813e-06, 1.1918e-06, 1.0995e-06,\n",
      "        2.3140e-06, 1.9452e-06, 1.9695e-06, 1.4023e-06, 1.2752e-06, 2.4828e-06,\n",
      "        4.7759e-06, 1.2880e-06, 1.7757e-06, 2.2607e-06, 1.6401e-06, 2.4310e-06,\n",
      "        3.5852e-06, 3.5877e-06, 1.4714e-06, 2.9269e-06, 4.1699e-06, 1.3370e-06,\n",
      "        1.1038e-06, 1.0518e-06, 1.1249e-06, 2.0961e-06, 2.4998e-06, 1.6823e-06,\n",
      "        1.0024e-06, 2.4011e-06, 1.2094e-06, 3.2699e-06, 1.3724e-06, 2.5708e-06,\n",
      "        1.6833e-06, 9.7534e-07, 2.1489e-06, 1.5618e-06, 1.9549e-06, 2.3346e-06,\n",
      "        2.3119e-06, 3.5569e-06, 3.6427e-06, 1.7746e-06, 4.3958e-06, 1.0422e-06,\n",
      "        1.5793e-06, 2.1172e-06, 1.6310e-06, 4.2246e-06, 1.7704e-06, 2.6521e-06,\n",
      "        1.9011e-06, 2.3334e-06, 1.2448e-06, 1.9247e-06, 3.2394e-06, 1.0438e-06,\n",
      "        1.4512e-06, 1.4776e-06, 1.8722e-06, 1.5804e-06, 2.3271e-06, 1.1307e-06,\n",
      "        2.8525e-06, 4.1264e-06, 1.3411e-06, 1.6849e-06, 1.7647e-06, 2.6214e-06,\n",
      "        1.5900e-06, 1.2750e-06, 2.3376e-06, 3.0994e-06, 1.8376e-06, 2.2201e-06,\n",
      "        3.2822e-06, 2.0146e-06, 2.1892e-06, 2.4616e-06, 1.9937e-06, 2.0163e-06,\n",
      "        1.3511e-06, 1.3876e-06, 4.3092e-06, 3.8361e-06, 3.3972e-06, 2.6652e-06,\n",
      "        3.6942e-06, 1.5333e-06], device='cuda:0')}, 140402548533144: {'step': 23620, 'exp_avg': tensor([-1.2032e-03,  6.6812e-04, -9.3716e-04, -5.0698e-04,  6.6986e-04,\n",
      "        -4.9862e-04,  1.0608e-03,  1.1084e-03, -5.4677e-04,  1.8826e-03,\n",
      "        -1.5086e-04, -1.2136e-03,  1.0057e-03,  5.4242e-04, -6.8503e-04,\n",
      "        -6.1554e-04,  9.2421e-04, -7.8504e-04,  1.8282e-04, -1.4277e-03,\n",
      "         5.6052e-45, -8.5843e-04, -4.2391e-04, -4.5299e-04, -2.0293e-04,\n",
      "        -2.9520e-04, -2.0369e-04,  3.9450e-04,  5.8824e-04,  7.6772e-04,\n",
      "         2.4613e-04,  1.8766e-04,  1.5539e-03,  1.4427e-03,  2.1084e-03,\n",
      "        -5.4312e-05,  8.1893e-04, -1.9718e-04, -3.0431e-04,  6.2493e-04,\n",
      "         5.3890e-04, -1.6314e-04,  1.8144e-04,  1.8544e-04,  1.0622e-03,\n",
      "         1.0915e-03,  1.6597e-03, -6.8702e-04,  3.6159e-04,  5.4634e-04,\n",
      "         1.3100e-03, -2.2289e-04, -8.5431e-04, -1.9944e-03, -1.8221e-03,\n",
      "        -9.9605e-05, -4.0754e-04, -7.3517e-04,  2.2616e-04,  2.2994e-05,\n",
      "         1.6593e-03,  1.8600e-03, -1.7367e-04,  8.9755e-04, -7.5826e-04,\n",
      "         4.3574e-04, -4.6978e-04, -1.4171e-04,  1.2594e-03,  9.2171e-04,\n",
      "         9.2754e-04,  8.9756e-04, -1.2129e-04, -1.8115e-04, -3.5272e-04,\n",
      "        -9.0976e-04, -4.2089e-04, -7.0482e-04,  1.0125e-03, -4.9627e-04,\n",
      "        -8.5966e-04,  3.4587e-04, -7.3139e-04,  1.3596e-04,  5.7236e-05,\n",
      "        -1.5693e-04,  2.8818e-04, -6.1876e-04, -2.0988e-05, -1.1999e-03,\n",
      "        -5.4034e-04, -6.3558e-04,  5.1936e-04, -8.0457e-04,  6.1889e-04,\n",
      "         6.5371e-05,  4.8584e-04,  7.3992e-06,  9.9371e-04, -7.9975e-05,\n",
      "        -1.2918e-03, -9.6279e-04, -8.1427e-04, -4.9573e-04,  1.0760e-04,\n",
      "         1.6892e-03, -2.3835e-04, -4.7179e-04, -1.6923e-04,  5.5078e-04,\n",
      "         8.4129e-06,  6.3398e-04, -7.0178e-04,  1.5758e-03,  1.2852e-03,\n",
      "         1.0574e-04,  2.7382e-04,  3.7960e-04, -6.8881e-04, -1.8955e-03,\n",
      "         5.8711e-04,  5.0115e-04, -2.5434e-03,  1.5766e-04,  6.0449e-04,\n",
      "         1.1447e-03,  2.0123e-03, -8.2864e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.4927e-05, 7.0300e-06, 1.0060e-05, 1.4694e-05, 2.5601e-05, 7.9305e-06,\n",
      "        5.2860e-06, 8.4062e-06, 1.2033e-05, 1.2405e-05, 6.9335e-06, 1.4979e-05,\n",
      "        1.6895e-05, 8.0374e-06, 1.5248e-05, 1.2275e-05, 1.3612e-05, 1.4849e-05,\n",
      "        1.5949e-05, 2.1444e-05, 1.1532e-17, 1.5325e-05, 2.5020e-05, 9.7163e-06,\n",
      "        1.3803e-05, 1.6283e-05, 6.5773e-06, 6.6848e-06, 1.6099e-05, 1.1352e-05,\n",
      "        6.3647e-06, 9.6794e-06, 9.9923e-06, 6.5063e-06, 1.9704e-05, 9.1416e-06,\n",
      "        9.5011e-06, 8.9753e-06, 1.7848e-05, 8.0158e-06, 6.7861e-06, 7.5767e-06,\n",
      "        1.5598e-05, 1.7048e-05, 1.3555e-05, 1.0954e-05, 7.9800e-06, 1.3529e-05,\n",
      "        1.7437e-05, 8.1826e-06, 1.7126e-05, 8.4071e-06, 9.1858e-06, 1.3901e-05,\n",
      "        1.6841e-05, 1.6715e-05, 8.4299e-06, 1.6255e-05, 1.3608e-05, 1.1675e-05,\n",
      "        7.3332e-06, 9.6532e-06, 7.5325e-06, 1.1704e-05, 1.7733e-05, 9.4953e-06,\n",
      "        7.7784e-06, 2.1019e-05, 7.9703e-06, 1.2874e-05, 6.8758e-06, 1.5049e-05,\n",
      "        1.1196e-05, 6.4212e-06, 1.2474e-05, 8.5159e-06, 1.0229e-05, 1.2789e-05,\n",
      "        1.0865e-05, 1.9070e-05, 1.8502e-05, 8.1097e-06, 1.8992e-05, 7.8503e-06,\n",
      "        7.7605e-06, 8.8714e-06, 8.3539e-06, 1.9163e-05, 8.1465e-06, 1.3702e-05,\n",
      "        7.3652e-06, 1.4956e-05, 8.9317e-06, 9.5857e-06, 1.8061e-05, 7.5677e-06,\n",
      "        8.5801e-06, 1.0015e-05, 1.2237e-05, 1.0803e-05, 1.6728e-05, 7.2201e-06,\n",
      "        1.3492e-05, 1.3743e-05, 7.7074e-06, 1.4417e-05, 7.9362e-06, 1.4903e-05,\n",
      "        8.5038e-06, 6.1519e-06, 1.3428e-05, 1.3962e-05, 6.4458e-06, 8.2352e-06,\n",
      "        1.3216e-05, 8.8514e-06, 1.3865e-05, 1.7399e-05, 1.2522e-05, 1.2202e-05,\n",
      "        8.3308e-06, 8.9751e-06, 1.9423e-05, 2.1920e-05, 1.8669e-05, 1.0916e-05,\n",
      "        1.8562e-05, 7.8056e-06], device='cuda:0')}, 140402548534512: {'step': 23620, 'exp_avg': tensor([[-6.8726e-04, -7.2333e-05, -5.4795e-04,  ..., -1.4012e-06,\n",
      "         -2.3203e-04,  6.0409e-04],\n",
      "        [-2.9104e-04, -3.6834e-04, -1.3279e-04,  ..., -6.6369e-05,\n",
      "         -1.6335e-04, -1.6427e-04],\n",
      "        [ 2.8647e-04,  2.1822e-04,  5.1138e-04,  ..., -1.6389e-03,\n",
      "          2.2285e-04,  3.5646e-04],\n",
      "        ...,\n",
      "        [ 3.0231e-04, -9.0172e-05,  5.4753e-05,  ...,  1.6019e-03,\n",
      "          1.5491e-04,  6.3179e-04],\n",
      "        [-7.9908e-04, -8.7745e-05,  9.7083e-05,  ..., -8.0767e-04,\n",
      "         -2.7969e-04,  6.7762e-05],\n",
      "        [ 1.7790e-03,  3.5995e-05,  1.2271e-04,  ...,  1.4289e-03,\n",
      "          7.8338e-04, -8.4667e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[8.4166e-06, 2.3179e-06, 8.2482e-06,  ..., 9.7920e-07, 5.1839e-06,\n",
      "         9.2134e-06],\n",
      "        [1.5133e-05, 2.0086e-05, 1.2637e-05,  ..., 6.2435e-06, 1.0224e-06,\n",
      "         1.7802e-05],\n",
      "        [1.4210e-06, 3.1470e-06, 1.4496e-06,  ..., 1.3873e-05, 1.3927e-06,\n",
      "         2.0897e-06],\n",
      "        ...,\n",
      "        [2.9463e-06, 1.7312e-05, 2.3219e-06,  ..., 1.3532e-05, 3.8055e-07,\n",
      "         3.9603e-06],\n",
      "        [3.6291e-06, 1.9645e-06, 2.0044e-06,  ..., 5.2410e-06, 2.1804e-06,\n",
      "         2.0544e-06],\n",
      "        [7.2265e-06, 7.5013e-06, 1.2031e-06,  ..., 5.9252e-06, 4.3263e-06,\n",
      "         1.8858e-06]], device='cuda:0')}, 140402548534440: {'step': 23620, 'exp_avg': tensor([-9.0609e-05, -3.8639e-04,  9.5039e-04, -1.9988e-03, -2.3812e-05,\n",
      "        -1.0687e-04,  3.9555e-04,  1.1120e-03, -1.5673e-03,  1.7158e-03],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([1.5488e-05, 3.5508e-05, 2.0996e-05, 2.4701e-05, 1.9262e-05, 1.7673e-05,\n",
      "        1.7702e-05, 1.9299e-05, 1.6771e-05, 1.5091e-05], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [140402548532784, 140402548531416, 140402548531344, 140402548534152, 140402548533720, 140402548533648, 140402548532712, 140402548531704, 140402548532568, 140402548532208, 140402548531848, 140402548531992, 140402548531488, 140402548534080, 140402548535232, 140402548535160, 140402548532064, 140402548533072, 140402548535016, 140402548533144, 140402548534512, 140402548534440]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Epoch :  4 [ 56016,  60000] loss: 0.051 TrnAcc: 0.940\n",
    "Test | Size :  10000  | ValAcc: 0.987\n",
    "\n",
    "Train Epoch :  8 [ 56016,  60000] loss: 0.059 TrnAcc: 0.940\n",
    "Test | Size :  10000  | ValAcc: 0.988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refs\n",
    "https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist\n",
    "\n",
    "https://nextjournal.com/gkoehler/pytorch-mnist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
