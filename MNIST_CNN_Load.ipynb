{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading PyTorch CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : Fully Connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3) # 28x28 -> 26x26\n",
    "        self.b1    = nn.BatchNorm2d(64)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)  # 26x26 -> 13x13\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)  # 13x13 -> 11x11\n",
    "        self.b2    = nn.BatchNorm2d(128)\n",
    "        #self.pool                          # 11x11 -> 5x5\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3) # 5x5 -> 3x3\n",
    "        self.b3    = nn.BatchNorm2d(128)\n",
    "        #self.pool                          # 3x3 -> 1x1 \n",
    "        \n",
    "        # FC Layers\n",
    "        self.fc1 = nn.Linear(128 * 1 * 1, 512)\n",
    "        self.bf1 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bf2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.pool(F.relu(self.b1(self.conv1(x))))\n",
    "        #print(self.num_flat_features(x))\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.pool(F.relu(self.b2(self.conv2(x))))\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.pool(F.relu(self.b3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten tensors\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        # FC Layer 1\n",
    "        x = F.relu(self.bf1(self.fc1(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # FC Layer 2\n",
    "        x = F.relu(self.bf2(self.fc2(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # FC Layer 3\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (b1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (b2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (b3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "  (bf1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bf2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 1 : Load on GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('./results/model.pth'))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Case 2 : Load on CPU\n",
    "#device = torch.device('cpu')\n",
    "#model.load_state_dict(torch.load(PATH, map_location=device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | Size :  10000  | ValAcc: 0.987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Calculate Validation Accuracy\n",
    "total_eval = 0\n",
    "correct_eval = 0.0\n",
    "with torch.no_grad():\n",
    "    for images_eval, labels_eval in testloader:\n",
    "        images_eval, labels_eval = images_eval.to(device), labels_eval.to(device)\n",
    "        outputs_eval = model(images_eval)\n",
    "        _, predicted_eval = torch.max(outputs_eval.data, 1)\n",
    "        total_eval += labels_eval.size(0)\n",
    "        correct_eval += (predicted_eval == labels_eval).sum().item() \n",
    "val_acc = correct_eval / total_eval\n",
    "print('Test | Size : %6d  | ValAcc: %.3f\\n' %\n",
    "      (len(testloader.dataset), val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1.weight\n",
      "1 conv1.bias\n",
      "2 b1.weight\n",
      "3 b1.bias\n",
      "4 b1.running_mean\n",
      "5 b1.running_var\n",
      "6 b1.num_batches_tracked\n",
      "7 conv2.weight\n",
      "8 conv2.bias\n",
      "9 b2.weight\n",
      "10 b2.bias\n",
      "11 b2.running_mean\n",
      "12 b2.running_var\n",
      "13 b2.num_batches_tracked\n",
      "14 conv3.weight\n",
      "15 conv3.bias\n",
      "16 b3.weight\n",
      "17 b3.bias\n",
      "18 b3.running_mean\n",
      "19 b3.running_var\n",
      "20 b3.num_batches_tracked\n",
      "21 fc1.weight\n",
      "22 fc1.bias\n",
      "23 bf1.weight\n",
      "24 bf1.bias\n",
      "25 bf1.running_mean\n",
      "26 bf1.running_var\n",
      "27 bf1.num_batches_tracked\n",
      "28 fc2.weight\n",
      "29 fc2.bias\n",
      "30 bf2.weight\n",
      "31 bf2.bias\n",
      "32 bf2.running_mean\n",
      "33 bf2.running_var\n",
      "34 bf2.num_batches_tracked\n",
      "35 fc3.weight\n",
      "36 fc3.bias\n",
      "21\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "another_dict = {}\n",
    "for i, (k, v) in enumerate(model.state_dict().items()):\n",
    "    print(i, k)\n",
    "    if i <= 20:\n",
    "        another_dict[k] = v\n",
    "        #print(k)\n",
    "print(len(another_dict))\n",
    "\n",
    "# update & load\n",
    "cur_dict = model.state_dict()\n",
    "cur_dict.update(another_dict)\n",
    "model.load_state_dict(cur_dict)\n",
    "model.to(device)\n",
    "\n",
    "print(len(model.state_dict()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('conv1.weight', tensor([[[[-2.5679e-02,  1.2768e-01, -1.7729e-01],\n",
      "          [-2.0581e-01, -2.5305e-01, -1.9026e-01],\n",
      "          [-1.3796e-01, -1.5476e-02, -1.6153e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0971e-01,  1.5258e-01, -3.2308e-01],\n",
      "          [ 2.6326e-01,  1.5560e-01,  1.9040e-01],\n",
      "          [-7.5650e-02, -3.3277e-01, -9.2336e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0863e-01, -5.6459e-02, -1.0615e-01],\n",
      "          [ 8.5192e-02,  1.4713e-02, -2.2124e-01],\n",
      "          [ 2.0818e-01, -1.5482e-01, -2.1861e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.0022e-02, -2.3761e-01, -1.8780e-01],\n",
      "          [-1.9244e-01, -9.7412e-02, -1.0576e-01],\n",
      "          [-4.5556e-02, -1.4751e-02, -2.1402e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9394e-02, -1.5709e-01, -1.3093e-01],\n",
      "          [ 3.1017e-01,  1.1941e-02,  4.4425e-02],\n",
      "          [-8.2639e-02,  1.3259e-02,  2.9113e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2636e-01,  1.3066e-04,  2.9539e-01],\n",
      "          [ 3.1197e-02,  5.2154e-02,  1.0690e-01],\n",
      "          [ 1.9844e-01, -2.4458e-01, -3.1848e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9453e-01,  6.5610e-02,  4.1411e-02],\n",
      "          [-1.6834e-01,  1.1530e-01,  2.5624e-03],\n",
      "          [-3.6630e-01,  1.7176e-01, -3.2749e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7245e-01,  2.6258e-01,  1.4926e-01],\n",
      "          [-9.4021e-02, -2.0836e-02,  5.7688e-03],\n",
      "          [ 5.6565e-02, -2.5875e-01, -3.6104e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5281e-01,  1.9000e-01,  2.1709e-01],\n",
      "          [-9.8776e-02, -5.6555e-02,  1.3584e-01],\n",
      "          [ 1.8010e-01,  3.0201e-01,  2.9883e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2758e-01,  3.0394e-01,  2.5404e-01],\n",
      "          [ 2.8572e-01,  2.8123e-01, -1.2729e-01],\n",
      "          [ 2.5892e-01,  9.5801e-02,  2.6089e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8670e-01, -1.0042e-01, -1.2060e-01],\n",
      "          [ 3.3803e-01, -2.8190e-01, -2.5783e-01],\n",
      "          [ 2.9055e-01,  1.7968e-01, -3.1429e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6474e-01, -2.2497e-01,  1.2383e-01],\n",
      "          [-8.1040e-03, -1.8269e-01,  2.0892e-01],\n",
      "          [ 3.0139e-01,  3.3944e-01, -2.1579e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3882e-01, -3.1098e-01, -7.7502e-02],\n",
      "          [ 2.1377e-01, -1.8918e-01,  2.9954e-01],\n",
      "          [ 2.8011e-02,  3.2892e-01,  3.2683e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.9470e-01,  1.8936e-01,  2.9208e-01],\n",
      "          [ 4.5918e-02, -9.1301e-02, -1.1095e-01],\n",
      "          [-7.4450e-02, -2.5883e-01, -2.4447e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1710e-01, -6.5600e-02,  2.3342e-01],\n",
      "          [-3.0357e-01,  4.5444e-01, -3.0060e-01],\n",
      "          [ 2.5458e-02,  2.7280e-01, -3.4943e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0521e-01, -2.9735e-01, -2.9890e-01],\n",
      "          [ 2.9246e-01,  1.9087e-03, -2.8401e-01],\n",
      "          [ 2.8442e-01,  2.5105e-01, -9.5132e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.7244e-01, -5.6599e-03,  2.5121e-01],\n",
      "          [-3.0525e-01, -1.1175e-01,  3.8451e-01],\n",
      "          [-2.1926e-01, -2.4055e-01,  2.6854e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2426e-01, -1.6824e-01,  1.5691e-01],\n",
      "          [ 2.2958e-01, -2.9600e-03, -2.6524e-01],\n",
      "          [-3.1738e-01,  2.3385e-02, -1.5314e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8651e-01,  2.7914e-01, -1.8524e-01],\n",
      "          [-1.7302e-01,  2.3646e-01, -2.7457e-01],\n",
      "          [ 1.5282e-02,  2.4322e-01, -4.3701e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3318e-01,  2.5399e-01,  5.1124e-02],\n",
      "          [-8.4144e-02, -1.9426e-04,  1.1923e-01],\n",
      "          [-8.4743e-02, -5.3814e-02,  1.0057e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0528e-03,  1.0018e-01, -2.5059e-01],\n",
      "          [ 3.4520e-01, -2.8689e-01,  1.9827e-01],\n",
      "          [-9.0396e-02,  1.9078e-01,  2.3356e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1068e-02, -4.5056e-02, -9.8187e-02],\n",
      "          [ 1.9299e-01, -2.7439e-01,  6.6746e-02],\n",
      "          [-2.2651e-01, -1.1165e-01,  1.3399e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7841e-02, -1.8518e-01,  2.5340e-01],\n",
      "          [-2.0848e-01, -2.6245e-01,  3.8864e-02],\n",
      "          [ 3.2549e-01, -2.3442e-01, -1.9309e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7463e-01,  1.6986e-01, -1.0649e-01],\n",
      "          [-7.7806e-02, -8.1070e-03,  3.5612e-01],\n",
      "          [ 2.0628e-01,  1.0523e-01,  1.1200e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1632e-02, -2.0707e-02,  3.3042e-02],\n",
      "          [ 2.7730e-01, -2.4184e-01,  1.7869e-01],\n",
      "          [-3.3193e-01,  4.4874e-02,  2.8622e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8055e-01, -7.0929e-02, -1.2944e-01],\n",
      "          [ 1.8302e-01, -4.2172e-01,  1.7652e-01],\n",
      "          [ 1.1071e-01, -2.8480e-01,  2.0007e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7763e-02,  1.2381e-02,  1.9643e-01],\n",
      "          [ 2.9978e-01,  3.3315e-01, -1.3756e-01],\n",
      "          [ 6.0162e-02,  1.3617e-01,  2.1981e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3799e-01, -5.8249e-02, -1.2970e-01],\n",
      "          [ 9.2531e-02,  1.1546e-01,  7.2158e-02],\n",
      "          [ 2.3069e-01, -1.5980e-01, -1.1600e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.4294e-03,  2.4308e-01,  1.8042e-01],\n",
      "          [-1.3049e-01, -1.6231e-01,  2.3917e-01],\n",
      "          [-5.1325e-02, -2.9170e-01,  2.8951e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2317e-01,  5.7886e-02,  3.2812e-02],\n",
      "          [-3.6583e-01, -2.9948e-01, -2.4923e-01],\n",
      "          [ 3.0831e-01, -1.9598e-02,  1.2463e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2632e-01,  5.0563e-02,  9.9109e-02],\n",
      "          [-1.5567e-01,  2.8438e-01, -2.5147e-01],\n",
      "          [-1.5079e-02, -2.2173e-01, -9.9589e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4250e-01, -1.4982e-01, -2.6355e-02],\n",
      "          [ 2.2743e-01,  3.0363e-01,  1.6864e-01],\n",
      "          [-1.1152e-01, -3.0373e-01,  7.2225e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1643e-01, -1.0233e-01, -2.5557e-01],\n",
      "          [-2.8831e-01, -2.2796e-01,  2.0770e-01],\n",
      "          [-2.0851e-01,  3.1394e-01,  1.5571e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4151e-01,  2.9484e-01,  3.2752e-03],\n",
      "          [-1.4733e-01, -2.1693e-01,  2.7488e-01],\n",
      "          [ 5.6408e-02, -2.3574e-02, -3.3608e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5098e-01, -2.8813e-01,  8.2767e-03],\n",
      "          [ 3.4340e-02, -2.2535e-01,  6.1174e-02],\n",
      "          [-2.2589e-01, -3.5872e-02,  6.9706e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5212e-02,  2.1445e-01,  8.3293e-02],\n",
      "          [-3.4877e-01, -3.4778e-02, -1.7416e-01],\n",
      "          [ 1.2954e-02, -2.2949e-01, -8.9741e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3476e-01,  2.0981e-01, -1.0956e-02],\n",
      "          [-2.2910e-01, -2.4090e-01, -1.3444e-01],\n",
      "          [-1.5585e-01, -1.5823e-02, -1.2982e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0983e-03, -3.2645e-02, -1.6210e-02],\n",
      "          [-2.4754e-01,  2.1821e-01, -1.7581e-01],\n",
      "          [ 6.9621e-03, -3.9698e-02,  4.7169e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4454e-01,  3.1946e-01,  2.4352e-01],\n",
      "          [-2.6240e-01,  3.1719e-01,  2.2840e-01],\n",
      "          [-5.2859e-02,  1.0832e-01,  1.6350e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1522e-01,  2.6435e-01, -2.3206e-01],\n",
      "          [-2.6260e-01,  1.6434e-01,  4.0258e-01],\n",
      "          [-1.5674e-01, -2.7312e-01, -2.2681e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3309e-02, -2.0277e-01, -1.0969e-01],\n",
      "          [-1.1625e-01, -5.7564e-02,  1.4025e-01],\n",
      "          [ 8.9633e-02,  2.7088e-01,  1.3773e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4595e-01, -1.0168e-02, -2.3248e-01],\n",
      "          [ 1.3960e-01, -1.9753e-01,  9.3493e-02],\n",
      "          [ 1.0204e-01,  1.6210e-01,  1.0870e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0206e-01,  1.1061e-01, -3.0535e-01],\n",
      "          [ 2.0583e-01, -2.6714e-01, -1.2588e-01],\n",
      "          [-2.5209e-01, -2.2769e-01, -8.9312e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5868e-01, -2.0933e-02, -2.6642e-01],\n",
      "          [ 1.4495e-01, -3.1575e-01,  1.7666e-01],\n",
      "          [-2.5933e-01,  1.9575e-01,  3.0461e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8210e-01,  1.8571e-01,  1.0870e-01],\n",
      "          [ 1.8490e-01,  1.0627e-01,  9.0966e-02],\n",
      "          [ 1.1473e-01,  1.7571e-01,  7.8623e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8966e-02,  1.9055e-02,  9.3893e-02],\n",
      "          [-2.1303e-01, -3.1699e-01, -9.9559e-03],\n",
      "          [-2.7342e-01,  1.9009e-01, -3.0217e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2181e-01,  1.9770e-01, -2.4879e-01],\n",
      "          [ 6.4858e-02, -3.2187e-01, -4.4067e-02],\n",
      "          [-2.1349e-01,  4.6027e-02,  1.6091e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1114e-01,  1.4611e-01,  1.3988e-02],\n",
      "          [ 3.1791e-01,  8.4199e-02,  4.8420e-02],\n",
      "          [ 3.9685e-02, -2.0996e-02, -2.8145e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7627e-01,  2.5054e-01,  1.6756e-02],\n",
      "          [ 1.2254e-01, -2.5483e-01,  1.9350e-01],\n",
      "          [-2.8939e-01, -1.6333e-02,  2.2399e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9374e-01, -3.2268e-01, -3.7574e-01],\n",
      "          [-1.2840e-02, -1.5421e-01,  2.5077e-01],\n",
      "          [ 2.6316e-01,  2.4432e-01, -3.2445e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3519e-02,  5.8731e-02,  2.3932e-01],\n",
      "          [-1.5130e-01,  1.7753e-01,  5.9081e-02],\n",
      "          [-3.3194e-01, -3.5110e-01, -3.0661e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6810e-01,  6.3583e-02,  3.0066e-01],\n",
      "          [-4.2910e-02,  2.8473e-02, -2.0805e-01],\n",
      "          [-2.9736e-01, -5.5262e-02, -6.7538e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3512e-01, -2.2363e-01, -1.2302e-01],\n",
      "          [ 1.0729e-01,  2.9638e-01, -2.7169e-01],\n",
      "          [ 2.0909e-01, -1.1152e-01,  3.2113e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3258e-01, -2.6124e-01, -6.6180e-02],\n",
      "          [ 2.6341e-01,  1.5820e-01, -4.7630e-02],\n",
      "          [ 1.9694e-01, -2.2496e-01, -3.1189e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0482e-02, -2.2765e-01,  2.7410e-01],\n",
      "          [-2.7254e-01,  1.5736e-01,  2.6873e-01],\n",
      "          [-2.9481e-01, -4.8034e-02, -2.1183e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3678e-01,  2.0500e-01,  2.1026e-01],\n",
      "          [-2.2088e-01, -2.9114e-01, -2.9580e-01],\n",
      "          [ 2.1719e-02, -1.5971e-02,  2.1776e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.0618e-01,  3.2039e-01,  2.9622e-01],\n",
      "          [ 2.1702e-01, -1.2768e-01, -1.1913e-01],\n",
      "          [ 2.9015e-01,  1.4861e-01,  5.1933e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4800e-01,  3.1706e-01, -1.2890e-01],\n",
      "          [-2.0320e-01,  7.7096e-02,  2.5972e-02],\n",
      "          [ 1.9646e-01,  1.7737e-01,  7.7242e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9174e-01,  1.6469e-01, -2.5400e-01],\n",
      "          [ 1.8042e-01, -7.3677e-02, -2.4337e-01],\n",
      "          [-8.3793e-02,  5.6665e-02, -8.1307e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4183e-02, -1.5226e-01, -2.6991e-02],\n",
      "          [ 6.2660e-02,  1.1336e-01, -3.6185e-01],\n",
      "          [-1.6578e-01,  2.0690e-01,  2.4879e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0380e-01,  5.3613e-02,  2.0494e-01],\n",
      "          [ 2.7488e-01,  2.3278e-01, -4.0829e-02],\n",
      "          [-1.3998e-01, -1.7959e-01, -3.0033e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9723e-01,  4.7401e-02,  1.8214e-01],\n",
      "          [ 7.0934e-02, -2.1474e-01, -3.6252e-01],\n",
      "          [-3.3585e-01,  2.3394e-03,  2.8296e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2889e-01,  2.2025e-01,  2.9515e-01],\n",
      "          [-2.8722e-01, -1.5873e-01, -1.6054e-01],\n",
      "          [-8.3655e-02,  2.4607e-01, -9.6752e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3855e-01,  8.0927e-02,  6.5361e-02],\n",
      "          [-1.9714e-01,  1.8772e-01,  2.4548e-03],\n",
      "          [-2.4168e-01, -2.5272e-01, -2.4201e-01]]]], device='cuda:0')), ('conv1.bias', tensor([-0.1814, -0.1537, -0.0198,  0.2508, -0.2218, -0.2037, -0.1924, -0.0097,\n",
      "        -0.2331,  0.0481, -0.2745,  0.0190,  0.0918, -0.0697,  0.1042, -0.3164,\n",
      "        -0.0262, -0.0570, -0.2417, -0.2953, -0.2387, -0.2201, -0.2582,  0.1680,\n",
      "        -0.2161, -0.3039, -0.1380,  0.2728, -0.0582,  0.1535,  0.0149,  0.1940,\n",
      "         0.0216,  0.1264, -0.0355, -0.3092,  0.2271,  0.0509, -0.2876,  0.1126,\n",
      "        -0.1569, -0.2671, -0.0850, -0.1888,  0.0488,  0.0810,  0.0311,  0.1960,\n",
      "        -0.2446, -0.0209, -0.1228,  0.0882, -0.2598, -0.2915, -0.0188,  0.3237,\n",
      "        -0.0122,  0.2628, -0.0720,  0.2728, -0.2334, -0.2299, -0.2036,  0.3055],\n",
      "       device='cuda:0')), ('b1.weight', tensor([0.2759, 0.0674, 0.7542, 0.4343, 0.2123, 0.2169, 0.4160, 0.8241, 0.7218,\n",
      "        0.7360, 0.6998, 0.6088, 0.0213, 0.5342, 0.7064, 0.9502, 0.6238, 0.1537,\n",
      "        0.7534, 0.3775, 0.4704, 0.9971, 0.7100, 0.6264, 0.0436, 0.7122, 0.0265,\n",
      "        0.0749, 0.7303, 0.7255, 0.3494, 0.5421, 0.1942, 0.6143, 0.2838, 1.0356,\n",
      "        0.5469, 0.0779, 0.0809, 0.5250, 0.5064, 0.3184, 0.8032, 0.9410, 0.4323,\n",
      "        0.2960, 0.2731, 0.1389, 0.4751, 0.5762, 1.0270, 0.6643, 0.3104, 0.4960,\n",
      "        0.0190, 0.6862, 0.1300, 0.3465, 0.7976, 0.5515, 0.8585, 0.7043, 0.6831,\n",
      "        0.7208], device='cuda:0')), ('b1.bias', tensor([ 0.0118, -0.0134, -0.0172,  0.0161,  0.0032, -0.0010, -0.0272, -0.0441,\n",
      "        -0.0331, -0.0609, -0.0206, -0.0160,  0.0137, -0.0296, -0.0880, -0.0589,\n",
      "        -0.0098, -0.0123, -0.0619, -0.0192, -0.0248,  0.0099, -0.0237, -0.0449,\n",
      "         0.0012, -0.0207, -0.0058, -0.0211, -0.0758, -0.0128, -0.0169, -0.0303,\n",
      "         0.0096, -0.0245,  0.0046, -0.0101, -0.0065, -0.0079, -0.0190, -0.0266,\n",
      "        -0.0127,  0.0094,  0.0341, -0.0596, -0.0217, -0.0076,  0.0094, -0.0099,\n",
      "         0.0042, -0.0047, -0.0249, -0.0026, -0.0512, -0.0420,  0.0126, -0.0060,\n",
      "        -0.0213, -0.0417, -0.0730, -0.0488, -0.0641, -0.0129, -0.0235, -0.0015],\n",
      "       device='cuda:0')), ('b1.running_mean', tensor([ 0.5679,  0.1145,  0.1564,  0.9380, -0.4733, -0.2012, -0.2096, -0.0164,\n",
      "        -0.9654, -1.1823,  0.0544,  0.0313, -0.4545,  0.3266,  0.2727, -0.3459,\n",
      "         0.1536,  0.2115, -0.4472, -0.6829, -0.5532,  0.0035, -0.1011, -0.2513,\n",
      "        -0.3271, -0.2695, -0.9586,  0.4104, -0.0803,  0.2910,  0.3298,  0.1693,\n",
      "         0.1576,  0.3763,  0.2899,  0.1158,  0.4876,  0.2263, -0.8793,  0.2584,\n",
      "        -0.1781, -0.2812,  0.4542,  0.0970, -0.8366,  0.6169,  0.4502,  0.0247,\n",
      "        -0.2216, -0.0591,  0.3023,  0.4849, -0.5045, -0.1732,  0.0702,  0.8435,\n",
      "        -0.5683, -0.2318,  0.0312,  0.3249, -0.2356, -0.1325, -0.0869,  0.6404],\n",
      "       device='cuda:0')), ('b1.running_var', tensor([0.3019, 0.0477, 0.1130, 0.2590, 0.0551, 0.0474, 0.0341, 0.1383, 0.3359,\n",
      "        0.8413, 0.1733, 0.0999, 0.2173, 0.1285, 0.0605, 0.1688, 0.2455, 0.0737,\n",
      "        0.0693, 0.0957, 0.0722, 0.0537, 0.0466, 0.1377, 0.0485, 0.0458, 0.3625,\n",
      "        0.0288, 0.0631, 0.0569, 0.0585, 0.0251, 0.0832, 0.0534, 0.0898, 0.1268,\n",
      "        0.0873, 0.0187, 0.3310, 0.0672, 0.0399, 0.0391, 0.2562, 0.1554, 0.3983,\n",
      "        0.1773, 0.1122, 0.0687, 0.0594, 0.0924, 0.1984, 0.1146, 0.0739, 0.1019,\n",
      "        0.1041, 0.1763, 0.1907, 0.1347, 0.0838, 0.0289, 0.0700, 0.0575, 0.0532,\n",
      "        0.1189], device='cuda:0')), ('b1.num_batches_tracked', tensor(18750, device='cuda:0')), ('conv2.weight', tensor([[[[ 0.0313, -0.0158,  0.0125],\n",
      "          [ 0.0328, -0.0309, -0.0114],\n",
      "          [ 0.0098, -0.0466,  0.0070]],\n",
      "\n",
      "         [[-0.0143,  0.0303, -0.0018],\n",
      "          [ 0.0340,  0.0282,  0.0100],\n",
      "          [-0.0189, -0.0060, -0.0002]],\n",
      "\n",
      "         [[ 0.0320, -0.0330, -0.0637],\n",
      "          [-0.0183, -0.0566, -0.0658],\n",
      "          [-0.0585, -0.0315, -0.0988]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0639,  0.0087,  0.0631],\n",
      "          [-0.0274,  0.0237,  0.0878],\n",
      "          [-0.0362,  0.0068,  0.0233]],\n",
      "\n",
      "         [[-0.0357, -0.0337, -0.0105],\n",
      "          [-0.0385, -0.0349,  0.0156],\n",
      "          [-0.0145,  0.0245, -0.0022]],\n",
      "\n",
      "         [[-0.0207, -0.0112,  0.0027],\n",
      "          [-0.0490, -0.0671, -0.0547],\n",
      "          [-0.0365,  0.0208,  0.0303]]],\n",
      "\n",
      "\n",
      "        [[[-0.0374, -0.0149,  0.0106],\n",
      "          [-0.0121,  0.0028,  0.0260],\n",
      "          [-0.0173, -0.0096,  0.0064]],\n",
      "\n",
      "         [[ 0.0027, -0.0205,  0.0364],\n",
      "          [-0.0221, -0.0346,  0.0404],\n",
      "          [-0.0404,  0.0162,  0.0091]],\n",
      "\n",
      "         [[-0.0035,  0.0541,  0.0301],\n",
      "          [ 0.0127, -0.0626, -0.0141],\n",
      "          [ 0.0073, -0.0453, -0.0395]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0158, -0.0171, -0.0004],\n",
      "          [-0.0405, -0.0741, -0.0423],\n",
      "          [-0.0125, -0.0076, -0.0082]],\n",
      "\n",
      "         [[-0.0215,  0.0415, -0.0033],\n",
      "          [-0.0121,  0.0240, -0.0411],\n",
      "          [-0.0264,  0.0120,  0.0564]],\n",
      "\n",
      "         [[-0.0411, -0.0309, -0.0364],\n",
      "          [-0.0178, -0.0488, -0.0683],\n",
      "          [-0.0500,  0.0099, -0.0182]]],\n",
      "\n",
      "\n",
      "        [[[-0.0264,  0.0356,  0.0011],\n",
      "          [ 0.0171,  0.0244,  0.0253],\n",
      "          [-0.0281,  0.0033, -0.0157]],\n",
      "\n",
      "         [[-0.0068,  0.0202, -0.0258],\n",
      "          [-0.0014,  0.0126, -0.0321],\n",
      "          [ 0.0326,  0.0108,  0.0288]],\n",
      "\n",
      "         [[ 0.0108,  0.0375, -0.0278],\n",
      "          [-0.0427,  0.0075, -0.0469],\n",
      "          [ 0.0018, -0.0455, -0.0628]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0441, -0.0088, -0.0200],\n",
      "          [ 0.0624, -0.0343, -0.0819],\n",
      "          [ 0.0046,  0.0431,  0.0399]],\n",
      "\n",
      "         [[ 0.0027, -0.0016,  0.0123],\n",
      "          [ 0.0067,  0.0126, -0.0393],\n",
      "          [-0.0353, -0.0175, -0.0293]],\n",
      "\n",
      "         [[ 0.0401,  0.0305,  0.0026],\n",
      "          [-0.0162,  0.0380,  0.0194],\n",
      "          [-0.0157, -0.0282,  0.0715]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0062,  0.0101, -0.0236],\n",
      "          [-0.0008,  0.0163, -0.0343],\n",
      "          [ 0.0048,  0.0056,  0.0366]],\n",
      "\n",
      "         [[-0.0189,  0.0169, -0.0106],\n",
      "          [ 0.0013,  0.0327, -0.0396],\n",
      "          [-0.0072, -0.0316, -0.0300]],\n",
      "\n",
      "         [[-0.0017,  0.0250, -0.0258],\n",
      "          [-0.0044, -0.0122,  0.0315],\n",
      "          [-0.0253,  0.0131, -0.0032]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0076,  0.0069,  0.0328],\n",
      "          [ 0.0115,  0.0222,  0.0736],\n",
      "          [ 0.0500, -0.0198,  0.0022]],\n",
      "\n",
      "         [[ 0.0445,  0.0395,  0.0297],\n",
      "          [-0.0291, -0.0283, -0.0145],\n",
      "          [ 0.0250,  0.0280, -0.0453]],\n",
      "\n",
      "         [[ 0.0117, -0.0083,  0.0205],\n",
      "          [ 0.0043,  0.0575, -0.0164],\n",
      "          [ 0.0160, -0.0040,  0.0091]]],\n",
      "\n",
      "\n",
      "        [[[-0.0287,  0.0175, -0.0089],\n",
      "          [-0.0223, -0.0138,  0.0007],\n",
      "          [ 0.0202,  0.0367,  0.0257]],\n",
      "\n",
      "         [[-0.0376,  0.0148,  0.0346],\n",
      "          [ 0.0313, -0.0276,  0.0228],\n",
      "          [ 0.0401, -0.0313,  0.0203]],\n",
      "\n",
      "         [[-0.0228, -0.0057,  0.0598],\n",
      "          [-0.0074, -0.0127, -0.0238],\n",
      "          [-0.0154,  0.0095,  0.0582]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0386,  0.0054,  0.0381],\n",
      "          [ 0.0219,  0.0497, -0.0035],\n",
      "          [-0.0045,  0.0158, -0.0245]],\n",
      "\n",
      "         [[ 0.0186, -0.0036,  0.0424],\n",
      "          [ 0.0077, -0.0368,  0.0053],\n",
      "          [-0.0077, -0.0260, -0.0176]],\n",
      "\n",
      "         [[-0.0179, -0.0226, -0.0044],\n",
      "          [-0.0441,  0.0261,  0.0240],\n",
      "          [ 0.0128, -0.0159,  0.0182]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0088, -0.0253,  0.0272],\n",
      "          [ 0.0066,  0.0145, -0.0323],\n",
      "          [ 0.0072,  0.0082,  0.0271]],\n",
      "\n",
      "         [[ 0.0399, -0.0364, -0.0260],\n",
      "          [-0.0259, -0.0310,  0.0259],\n",
      "          [ 0.0292,  0.0187, -0.0417]],\n",
      "\n",
      "         [[ 0.0348,  0.0497,  0.0221],\n",
      "          [ 0.0167,  0.0465, -0.0077],\n",
      "          [ 0.0785,  0.0232,  0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0137, -0.0602, -0.0368],\n",
      "          [ 0.0117, -0.0328, -0.0149],\n",
      "          [-0.0151, -0.0269, -0.0395]],\n",
      "\n",
      "         [[-0.0257,  0.0244, -0.0029],\n",
      "          [-0.0412, -0.0235, -0.0289],\n",
      "          [ 0.0113, -0.0086, -0.0104]],\n",
      "\n",
      "         [[ 0.0243,  0.0303, -0.0128],\n",
      "          [-0.0441,  0.0220,  0.0128],\n",
      "          [-0.0153,  0.0195,  0.0231]]]], device='cuda:0')), ('conv2.bias', tensor([ 0.0157, -0.0049, -0.0388, -0.0037,  0.0098, -0.0102,  0.0135,  0.0110,\n",
      "        -0.0255,  0.0354, -0.0063,  0.0204, -0.0138, -0.0036,  0.0197,  0.0339,\n",
      "         0.0285, -0.0387,  0.0306,  0.0129,  0.0150, -0.0036,  0.0178, -0.0395,\n",
      "        -0.0381, -0.0093, -0.0290,  0.0388, -0.0180,  0.0376, -0.0367, -0.0312,\n",
      "         0.0193,  0.0365, -0.0112,  0.0292,  0.0349,  0.0411, -0.0331,  0.0308,\n",
      "        -0.0409, -0.0039,  0.0104, -0.0094,  0.0169, -0.0338,  0.0270,  0.0384,\n",
      "        -0.0237,  0.0115,  0.0284, -0.0187,  0.0129,  0.0057,  0.0172, -0.0015,\n",
      "        -0.0405,  0.0398,  0.0120,  0.0108, -0.0134, -0.0183,  0.0071, -0.0355,\n",
      "        -0.0352, -0.0264,  0.0008,  0.0019, -0.0014,  0.0034,  0.0102,  0.0096,\n",
      "         0.0324,  0.0211,  0.0355, -0.0409,  0.0224, -0.0196, -0.0355, -0.0332,\n",
      "        -0.0352,  0.0245,  0.0131,  0.0086, -0.0346, -0.0212, -0.0274,  0.0037,\n",
      "        -0.0060, -0.0234, -0.0232,  0.0167,  0.0204,  0.0211, -0.0228,  0.0036,\n",
      "         0.0160,  0.0362,  0.0209, -0.0371, -0.0405,  0.0087, -0.0317, -0.0135,\n",
      "         0.0406, -0.0209, -0.0334, -0.0265,  0.0060, -0.0307,  0.0348, -0.0325,\n",
      "         0.0364, -0.0226,  0.0255,  0.0320, -0.0075, -0.0334,  0.0053, -0.0022,\n",
      "        -0.0100,  0.0094,  0.0337,  0.0080, -0.0099, -0.0356,  0.0029,  0.0412],\n",
      "       device='cuda:0')), ('b2.weight', tensor([ 7.5577e-01,  8.5796e-01,  9.9645e-01,  2.8136e-01,  6.4158e-01,\n",
      "         8.1524e-01,  7.9966e-01,  6.5797e-01,  7.1160e-01,  3.0948e-01,\n",
      "         5.7729e-01,  3.9353e-01,  7.3227e-01,  5.3736e-01,  7.4148e-01,\n",
      "         1.2327e-01,  5.1848e-01,  8.6211e-01,  1.3677e-01,  9.5423e-01,\n",
      "         1.8201e-01,  8.3891e-01,  3.2775e-01,  9.0983e-01,  3.8095e-01,\n",
      "         9.2306e-01,  5.2289e-02,  5.6450e-01,  8.6749e-01,  6.7419e-01,\n",
      "         7.8722e-01,  4.0837e-01,  3.8237e-01,  3.9452e-01,  4.1846e-01,\n",
      "         8.6723e-01,  4.0759e-01,  1.0090e+00,  6.3917e-04,  9.7861e-01,\n",
      "         7.6840e-01,  7.8753e-01,  4.1535e-01,  8.0051e-01,  3.1893e-01,\n",
      "         6.1028e-01,  2.2008e-01,  5.2307e-02,  7.3856e-01,  9.7235e-01,\n",
      "         4.2926e-01,  8.1351e-01,  8.0240e-01,  2.4198e-01,  1.8274e-01,\n",
      "         8.2847e-01,  1.1614e-01,  5.3366e-01,  5.2219e-02,  7.6372e-01,\n",
      "         5.7874e-01,  4.6372e-01,  7.3702e-01,  3.2513e-01,  3.8813e-01,\n",
      "         6.1832e-02,  1.1935e-01,  3.9015e-01, -1.8158e-02,  6.3352e-04,\n",
      "         8.5254e-02,  8.8387e-01,  2.1252e-01,  4.0264e-01,  2.0234e-01,\n",
      "         6.7735e-01,  6.7588e-01,  6.9834e-01,  1.7470e-01,  2.5519e-01,\n",
      "         6.5812e-01,  5.5336e-01,  8.0442e-01,  2.9345e-01,  6.2291e-01,\n",
      "         1.4436e-04,  6.7239e-01,  3.4136e-01,  4.9555e-01,  5.1998e-01,\n",
      "         6.2954e-01,  7.6029e-01,  3.5641e-02,  5.2080e-01,  1.0930e-01,\n",
      "         3.9096e-01,  2.2958e-01,  5.3513e-01,  1.9920e-01,  6.2385e-01,\n",
      "         9.5464e-01,  1.7551e-01,  1.6483e-01,  5.4225e-01,  5.3081e-01,\n",
      "         3.8638e-01,  8.7807e-02,  7.6302e-01,  8.0343e-01,  2.8898e-01,\n",
      "         3.5261e-01,  7.4518e-01,  5.3877e-02,  7.7125e-01,  6.9612e-01,\n",
      "         2.7919e-01,  2.4582e-01,  6.4440e-01,  1.5393e-01,  9.4414e-01,\n",
      "         7.1260e-01,  2.8854e-02,  8.0439e-01,  3.1044e-01,  3.0662e-01,\n",
      "         5.7579e-01,  6.9156e-01,  9.1732e-01], device='cuda:0')), ('b2.bias', tensor([-0.0249, -0.0524, -0.0106, -0.0142,  0.0071, -0.0163, -0.0261, -0.0452,\n",
      "        -0.0500, -0.0318, -0.0103,  0.0032, -0.0694, -0.0104, -0.0053, -0.0089,\n",
      "        -0.0052, -0.0179, -0.0147, -0.0770, -0.0187, -0.0630, -0.0047, -0.1173,\n",
      "        -0.0152, -0.0261,  0.0055, -0.0190, -0.0445, -0.0260, -0.0689, -0.0278,\n",
      "        -0.0075,  0.0068, -0.0186, -0.0334, -0.0220, -0.0388, -0.0046, -0.0073,\n",
      "        -0.0308, -0.0393,  0.0032, -0.0221, -0.0206, -0.0065, -0.0164, -0.0063,\n",
      "         0.0012, -0.0216,  0.0089, -0.0234, -0.0450, -0.0088, -0.0016, -0.0668,\n",
      "        -0.0125, -0.0222, -0.0024, -0.0434, -0.0185, -0.0652, -0.0718, -0.0278,\n",
      "        -0.0128,  0.0187,  0.0154, -0.0132,  0.0018, -0.0033,  0.0058, -0.0405,\n",
      "         0.0025, -0.0124, -0.0024, -0.0207, -0.0237, -0.0549, -0.0223, -0.0234,\n",
      "        -0.0552, -0.0151, -0.0616, -0.0111, -0.0428, -0.0017,  0.0051,  0.0047,\n",
      "        -0.0222, -0.0488, -0.0154, -0.0524, -0.0040,  0.0017, -0.0344,  0.0106,\n",
      "        -0.0335, -0.0215, -0.0099, -0.0390, -0.0771, -0.0193, -0.0159, -0.0268,\n",
      "        -0.0237, -0.0061,  0.0104, -0.0293, -0.0753, -0.0185, -0.0201, -0.0548,\n",
      "         0.0033, -0.0430, -0.0326, -0.0247, -0.0174, -0.0505, -0.0140, -0.0585,\n",
      "        -0.0390,  0.0020, -0.0402, -0.0153, -0.0255, -0.0191, -0.0354, -0.0600],\n",
      "       device='cuda:0')), ('b2.running_mean', tensor([-0.5960, -0.6825, -0.8178, -0.5843, -0.4676, -1.3779,  0.8782, -0.2739,\n",
      "         0.8183,  0.2211, -0.5836,  0.1143,  0.0388,  0.0605, -0.0221, -0.2376,\n",
      "        -0.6945, -1.0386,  0.1774, -0.2454, -0.5536, -0.5917,  0.0366, -0.0526,\n",
      "        -0.3835, -0.8202, -0.0523, -0.4780, -0.9882, -0.2922,  0.2725,  0.0203,\n",
      "        -0.3477, -0.3093, -0.4155, -0.7467, -0.0493, -0.3817,  0.2222,  0.3291,\n",
      "        -0.2215,  0.7100,  0.3028, -0.0386, -0.2718, -0.1024, -0.5558,  0.1064,\n",
      "        -0.2112, -0.2525,  0.1068,  0.0829, -0.8886,  0.1497, -0.1012, -0.6392,\n",
      "        -0.1832, -0.5358, -0.0858,  0.0417,  0.6549, -0.2076,  0.0457, -0.0225,\n",
      "         0.1821, -0.0994,  0.2303, -0.1678, -0.0860, -0.2098,  0.0623, -0.6762,\n",
      "        -0.1011,  0.2028,  0.2824,  0.6700,  0.2575, -0.6657, -0.3157, -0.1215,\n",
      "         0.6101, -0.2070,  1.1644, -0.0440, -0.7053, -0.0014, -0.2570,  0.0086,\n",
      "        -0.1712,  0.3366, -0.4172,  0.0140, -0.1787,  0.0416, -0.2472,  0.0262,\n",
      "         0.0909, -0.3830, -0.1338, -0.5398,  0.3387,  0.0020,  0.2013, -0.4696,\n",
      "        -0.3228,  0.6684, -0.1215, -0.7000, -0.0144, -0.2842,  0.0330, -0.8215,\n",
      "         0.1956,  0.3548, -0.5291, -0.0246,  0.3741, -1.0605,  0.1180, -0.1068,\n",
      "        -0.4462, -0.0507, -0.1589, -0.2035,  0.2329,  0.1727,  0.4123, -0.1662],\n",
      "       device='cuda:0')), ('b2.running_var', tensor([0.5041, 0.6690, 1.2578, 0.2226, 0.3813, 0.9319, 1.2215, 0.4783, 0.7206,\n",
      "        0.1799, 0.3894, 0.2094, 0.6033, 0.2817, 0.5402, 0.0557, 0.3854, 0.7036,\n",
      "        0.0653, 1.1483, 0.2781, 0.8373, 0.2028, 0.9552, 0.3952, 0.5294, 0.0762,\n",
      "        0.4705, 0.7045, 0.5737, 0.8167, 0.1753, 0.2385, 0.2497, 0.2837, 0.8658,\n",
      "        0.1637, 0.9995, 0.0619, 0.7756, 0.5223, 1.0167, 0.2066, 0.6469, 0.1091,\n",
      "        0.4384, 0.2102, 0.0824, 0.7260, 0.6423, 0.3279, 0.8016, 0.5428, 0.0890,\n",
      "        0.1242, 0.6132, 0.1378, 0.3757, 0.0777, 0.3410, 0.7555, 0.3374, 0.7052,\n",
      "        0.1861, 0.1921, 0.0449, 0.0759, 0.2237, 0.0572, 0.0443, 0.1219, 0.6154,\n",
      "        0.1600, 0.3610, 0.1347, 0.5904, 0.5484, 0.5839, 0.1960, 0.1295, 1.0571,\n",
      "        0.3703, 1.3075, 0.1511, 0.3354, 0.0336, 0.6905, 0.1310, 0.2436, 0.4147,\n",
      "        0.3898, 0.4925, 0.0435, 0.3458, 0.1667, 0.2426, 0.2131, 0.3128, 0.0716,\n",
      "        0.4603, 0.5371, 0.0900, 0.1164, 0.3765, 0.3149, 0.3361, 0.0807, 0.6963,\n",
      "        0.7375, 0.1610, 0.2896, 0.5862, 0.0700, 0.7925, 0.6927, 0.1999, 0.1909,\n",
      "        0.7722, 0.0937, 0.7189, 0.7199, 0.0634, 0.4760, 0.1402, 0.1234, 0.4831,\n",
      "        0.5414, 1.2588], device='cuda:0')), ('b2.num_batches_tracked', tensor(18750, device='cuda:0')), ('conv3.weight', tensor([[[[-5.2266e-02, -1.8509e-02, -3.8446e-02],\n",
      "          [-4.6101e-02,  5.8073e-02,  7.7740e-03],\n",
      "          [ 2.3379e-02,  2.7094e-02, -2.9552e-04]],\n",
      "\n",
      "         [[-1.4823e-02,  8.8763e-03,  3.7236e-02],\n",
      "          [-4.5120e-02,  7.9950e-03,  2.7970e-02],\n",
      "          [ 8.8114e-02,  3.6039e-02,  4.1711e-02]],\n",
      "\n",
      "         [[-2.6335e-02,  4.1592e-02,  4.9015e-02],\n",
      "          [ 2.6017e-02,  7.3340e-03, -2.8167e-02],\n",
      "          [-8.8724e-03, -8.6512e-03, -1.5586e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.6535e-03, -3.5998e-02, -2.5421e-02],\n",
      "          [-3.9683e-02, -4.8190e-02,  1.3211e-02],\n",
      "          [-4.3896e-02,  1.1658e-02, -3.3638e-02]],\n",
      "\n",
      "         [[-1.0733e-02,  2.5154e-03,  3.8258e-02],\n",
      "          [-2.6509e-02,  2.9727e-02,  2.4332e-02],\n",
      "          [-1.9320e-02, -3.1223e-02,  5.2076e-02]],\n",
      "\n",
      "         [[-1.2087e-02,  9.9760e-03, -2.3323e-02],\n",
      "          [-3.9479e-02,  1.0173e-02,  4.4081e-02],\n",
      "          [-2.2857e-02, -1.9021e-02, -3.0930e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1729e-02, -4.3243e-02, -4.4451e-03],\n",
      "          [ 5.5098e-02,  1.0637e-02,  4.1193e-03],\n",
      "          [-7.5705e-02, -6.2157e-02, -1.9844e-02]],\n",
      "\n",
      "         [[ 1.8692e-02, -5.8210e-03,  4.6378e-03],\n",
      "          [-2.1444e-03, -8.5672e-02, -3.3157e-02],\n",
      "          [-4.2525e-02, -6.0215e-03, -2.9544e-02]],\n",
      "\n",
      "         [[ 2.8268e-02,  4.1298e-02,  4.3264e-02],\n",
      "          [ 4.0685e-02,  2.3832e-02,  2.5511e-02],\n",
      "          [-1.7396e-02, -5.5606e-02, -3.0450e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.5714e-03, -3.4120e-02, -2.3877e-02],\n",
      "          [ 2.7907e-02,  1.3360e-02, -3.6019e-03],\n",
      "          [ 1.6280e-02,  1.1487e-02, -1.0016e-02]],\n",
      "\n",
      "         [[-5.7091e-02,  3.2805e-02,  2.0168e-02],\n",
      "          [ 1.3280e-02,  4.7790e-02,  1.3940e-02],\n",
      "          [ 2.6396e-02,  2.7657e-02, -6.9917e-04]],\n",
      "\n",
      "         [[ 3.1140e-02,  2.2013e-02,  6.8697e-02],\n",
      "          [-3.4125e-02,  5.4106e-02, -2.3888e-03],\n",
      "          [-5.9558e-02,  4.7627e-02,  4.8835e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1951e-02, -6.0460e-02, -3.7713e-02],\n",
      "          [-4.8644e-02, -5.3363e-02, -8.2546e-02],\n",
      "          [-4.9055e-02,  1.8743e-02,  1.4051e-03]],\n",
      "\n",
      "         [[-1.7468e-02, -2.7744e-02, -4.3919e-02],\n",
      "          [-6.3819e-02, -2.4870e-02, -3.4923e-02],\n",
      "          [-2.3398e-02,  3.8004e-03, -2.9316e-02]],\n",
      "\n",
      "         [[ 1.3350e-03, -9.7285e-03, -5.6362e-02],\n",
      "          [-3.4409e-03,  6.0977e-02, -5.1445e-02],\n",
      "          [ 6.9133e-02,  2.2641e-02, -3.7450e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.4498e-03,  1.6666e-02,  9.1414e-03],\n",
      "          [ 2.8662e-02, -3.0668e-02, -4.2098e-03],\n",
      "          [-2.5950e-02,  1.8460e-03, -2.8994e-02]],\n",
      "\n",
      "         [[-1.3213e-02,  1.0285e-02, -9.7736e-03],\n",
      "          [-3.4923e-02, -2.4082e-03,  1.0303e-02],\n",
      "          [-2.6622e-02, -2.5124e-02,  1.0973e-02]],\n",
      "\n",
      "         [[-4.7552e-03,  7.1841e-04, -2.7365e-02],\n",
      "          [ 2.9721e-03,  1.3013e-02,  3.3551e-02],\n",
      "          [-2.1413e-02, -2.3026e-02,  2.7295e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5424e-02, -3.4580e-02, -4.4420e-02],\n",
      "          [ 1.4634e-02, -4.0864e-02, -2.8693e-02],\n",
      "          [ 4.9067e-04,  3.4462e-03,  2.7649e-02]],\n",
      "\n",
      "         [[-3.6335e-02, -1.2460e-02,  8.1232e-03],\n",
      "          [-7.5428e-02,  2.3759e-02,  1.0276e-01],\n",
      "          [-2.5921e-02,  1.2042e-02,  3.1105e-02]],\n",
      "\n",
      "         [[-1.4204e-04,  4.2345e-02, -4.9747e-02],\n",
      "          [ 2.0266e-02, -1.9098e-02, -7.3686e-02],\n",
      "          [ 9.0104e-02,  4.6365e-02,  2.3356e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0300e-03,  2.5066e-02,  4.8193e-02],\n",
      "          [-1.2385e-02,  5.0668e-03, -2.2890e-02],\n",
      "          [ 1.0426e-02, -4.6390e-02, -1.4543e-02]],\n",
      "\n",
      "         [[ 1.3487e-02, -1.1239e-02,  5.5266e-02],\n",
      "          [-4.6576e-02,  1.1905e-02, -3.3666e-02],\n",
      "          [ 8.6690e-03, -1.4105e-02, -2.9606e-02]],\n",
      "\n",
      "         [[ 1.7454e-03, -4.6143e-03, -2.2594e-02],\n",
      "          [-4.4582e-02,  9.8588e-03,  5.7510e-03],\n",
      "          [-5.4185e-02, -2.2390e-02,  6.0997e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3212e-02,  3.8011e-03, -6.2486e-02],\n",
      "          [ 2.7058e-02, -5.8572e-02, -8.1577e-02],\n",
      "          [-3.5315e-02,  8.2428e-03,  2.0975e-04]],\n",
      "\n",
      "         [[ 7.3127e-02, -5.1941e-02, -1.0522e-02],\n",
      "          [ 2.2227e-02, -2.8647e-02,  1.9941e-02],\n",
      "          [-4.7618e-02,  6.5512e-02,  1.0691e-01]],\n",
      "\n",
      "         [[-2.2230e-03,  2.8113e-02, -3.3486e-05],\n",
      "          [ 1.5584e-02,  2.2514e-02, -3.6282e-02],\n",
      "          [ 4.1294e-02,  1.3408e-04, -5.5597e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2095e-02,  5.3749e-03, -3.6435e-02],\n",
      "          [ 7.5320e-03,  4.2487e-02, -2.9423e-02],\n",
      "          [ 1.4184e-03,  4.2688e-02, -3.8021e-02]],\n",
      "\n",
      "         [[ 9.0204e-03, -2.5637e-02, -4.5278e-02],\n",
      "          [ 2.2389e-04, -2.1474e-03, -1.8955e-03],\n",
      "          [ 1.7268e-02, -1.2649e-02,  2.0181e-02]],\n",
      "\n",
      "         [[ 1.9677e-03, -1.1750e-02, -2.7466e-02],\n",
      "          [-2.6531e-02,  2.6555e-02,  7.4198e-03],\n",
      "          [ 4.5420e-02, -2.7687e-03, -6.0085e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7461e-02,  1.8038e-04,  1.7446e-04],\n",
      "          [-2.0628e-02, -3.0192e-02, -3.3121e-03],\n",
      "          [-3.3279e-02,  9.1916e-04, -1.0856e-03]],\n",
      "\n",
      "         [[ 2.6506e-03,  1.1906e-02, -3.4388e-03],\n",
      "          [-2.7873e-03,  2.9481e-02, -2.8888e-02],\n",
      "          [-4.3076e-02, -1.3758e-02, -4.0167e-02]],\n",
      "\n",
      "         [[-3.8933e-03, -7.7198e-04,  1.3075e-02],\n",
      "          [ 1.4504e-02, -9.9448e-03, -1.6243e-02],\n",
      "          [-2.0393e-02, -2.6663e-02, -2.6356e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2065e-02,  1.0190e-02, -3.0461e-02],\n",
      "          [-1.9075e-02, -1.1679e-02, -2.0677e-03],\n",
      "          [-7.5551e-03,  2.7004e-02,  1.6078e-02]],\n",
      "\n",
      "         [[-2.0167e-02,  1.4318e-02, -5.1798e-03],\n",
      "          [-2.6052e-02, -2.8826e-03, -2.3864e-02],\n",
      "          [ 3.7749e-03, -9.7269e-03, -8.0934e-03]],\n",
      "\n",
      "         [[-1.1158e-02,  7.5139e-03,  1.1529e-03],\n",
      "          [ 1.2725e-02,  1.1878e-02,  4.1939e-02],\n",
      "          [-4.7729e-03, -9.2897e-03,  2.3151e-02]]]], device='cuda:0')), ('conv3.bias', tensor([-0.0146, -0.0152,  0.0096,  0.0167, -0.0241,  0.0021,  0.0059, -0.0189,\n",
      "         0.0046,  0.0229, -0.0093, -0.0020, -0.0279,  0.0132, -0.0097,  0.0221,\n",
      "         0.0085,  0.0276,  0.0105,  0.0240, -0.0096, -0.0189, -0.0001,  0.0233,\n",
      "         0.0239,  0.0266,  0.0070, -0.0250,  0.0109,  0.0016, -0.0138,  0.0071,\n",
      "         0.0288,  0.0163,  0.0259,  0.0140, -0.0292, -0.0283, -0.0175,  0.0056,\n",
      "        -0.0006, -0.0147,  0.0193,  0.0281, -0.0192, -0.0160,  0.0117,  0.0061,\n",
      "         0.0118,  0.0252,  0.0038,  0.0257,  0.0229,  0.0179, -0.0054, -0.0224,\n",
      "         0.0210, -0.0235,  0.0126, -0.0030,  0.0253,  0.0008,  0.0261, -0.0285,\n",
      "         0.0119,  0.0224,  0.0055, -0.0080, -0.0185,  0.0198, -0.0064,  0.0110,\n",
      "         0.0161,  0.0054, -0.0184,  0.0024,  0.0151, -0.0098,  0.0105, -0.0227,\n",
      "        -0.0268, -0.0268, -0.0084, -0.0074, -0.0033,  0.0186,  0.0161,  0.0058,\n",
      "        -0.0006,  0.0230,  0.0035,  0.0058, -0.0049,  0.0048,  0.0276, -0.0114,\n",
      "        -0.0207, -0.0156, -0.0285, -0.0290,  0.0120, -0.0110,  0.0261,  0.0042,\n",
      "        -0.0025, -0.0208,  0.0060, -0.0088,  0.0020,  0.0102, -0.0020,  0.0230,\n",
      "        -0.0265,  0.0152, -0.0022,  0.0163,  0.0163,  0.0077,  0.0027,  0.0119,\n",
      "        -0.0252, -0.0205,  0.0006, -0.0272,  0.0154,  0.0158,  0.0016, -0.0288],\n",
      "       device='cuda:0')), ('b3.weight', tensor([ 0.8173,  0.9310,  0.9210,  0.0505,  1.0114,  0.8022,  0.3363,  0.7109,\n",
      "         0.6605,  0.0805,  0.5923,  1.0466,  0.5416,  0.8967,  0.5860,  0.6264,\n",
      "         0.5002,  0.9775,  0.8877,  0.1677,  0.6283,  0.4667,  0.8944,  0.2802,\n",
      "         0.4776,  0.4064,  0.1246,  0.1585,  0.8127,  0.7598,  0.6463,  0.3864,\n",
      "         0.1622,  0.7990,  0.1871,  0.8432,  0.7864,  0.4320,  0.6350,  0.0382,\n",
      "         0.3688,  0.7811,  0.2941,  0.2961,  0.4915,  0.3936,  0.8512,  0.0450,\n",
      "         0.5841,  0.7740,  0.9531,  0.9681,  0.4457,  0.8106,  0.7107,  0.5466,\n",
      "         0.3905,  0.6680,  0.4557,  0.1490,  0.1516,  0.5310,  0.6918,  0.2283,\n",
      "         0.4801,  0.2257,  0.2402,  0.7230,  0.8090,  0.6151,  0.2707, -0.0024,\n",
      "         0.0305,  0.4607,  0.6052,  0.4619,  0.3246,  0.5162,  0.2266,  0.8901,\n",
      "         0.7237,  0.6164,  0.6679,  0.3458,  0.4603,  0.0664,  0.4680,  0.6779,\n",
      "         0.4015,  0.8655,  0.6987,  0.1121,  0.6641,  0.4970,  0.2345,  0.2783,\n",
      "         0.3371,  0.3535,  0.0702,  0.7575,  0.1624,  0.7657,  0.8473,  0.3312,\n",
      "         0.8594,  0.3337,  0.2217,  0.3942,  0.8980,  0.4206,  0.4386,  0.5661,\n",
      "         0.2157,  0.1090,  0.6825,  0.5686,  0.5176,  0.3590,  0.9263,  0.5544,\n",
      "         0.3597,  0.8024,  0.2515,  0.4411,  0.7100,  0.9033,  0.8280,  0.1570],\n",
      "       device='cuda:0')), ('b3.bias', tensor([-5.4458e-03,  1.7953e-02, -5.8225e-02, -2.0411e-03,  1.2003e-02,\n",
      "         1.0227e-02, -2.1282e-02, -1.4682e-02,  1.5888e-02,  4.2609e-03,\n",
      "        -3.7711e-03, -1.4875e-01, -3.5714e-02,  5.9034e-03, -3.6082e-02,\n",
      "         9.8552e-03, -4.3018e-03, -4.7412e-02, -3.0308e-02,  1.2018e-02,\n",
      "         2.0121e-02,  4.4628e-03, -4.9132e-02, -1.9624e-02, -1.2089e-04,\n",
      "         1.5646e-02,  2.2014e-03,  9.7418e-03, -9.8523e-03, -2.0825e-03,\n",
      "        -4.2082e-02, -1.8912e-02,  2.4528e-02,  5.2440e-03, -1.5930e-03,\n",
      "         8.4780e-03,  1.2143e-02, -3.4221e-02, -2.0972e-02, -6.0301e-03,\n",
      "        -1.1173e-02, -5.9443e-02,  4.1518e-02,  1.7594e-02,  7.0410e-03,\n",
      "         7.4571e-03,  3.7304e-03,  1.6120e-02,  1.7321e-02, -1.4405e-02,\n",
      "        -1.9102e-02, -3.0980e-02,  1.6068e-02,  2.7649e-02,  6.6560e-02,\n",
      "        -3.2383e-03, -1.6030e-02, -2.4839e-02,  2.0982e-02, -1.5896e-03,\n",
      "        -6.5916e-03, -1.4253e-02,  1.5415e-02,  1.6546e-02,  1.5772e-02,\n",
      "         2.6134e-03, -1.7721e-02, -3.5379e-03, -2.3357e-02,  2.8145e-02,\n",
      "         2.6148e-02,  7.4542e-03,  8.6967e-03, -8.8598e-03, -7.5240e-03,\n",
      "         3.9100e-02, -1.6962e-02, -2.2886e-02,  1.8933e-02, -5.3992e-02,\n",
      "         6.1368e-03, -1.8689e-02, -3.9481e-02, -6.5399e-04,  1.9395e-02,\n",
      "         7.5115e-03, -5.8749e-02,  5.6259e-02,  1.7981e-02,  2.1283e-02,\n",
      "        -6.0906e-02, -6.5968e-03,  6.0616e-02,  4.1754e-03,  8.5183e-03,\n",
      "        -1.2080e-02,  2.2279e-02,  9.9210e-03,  9.0301e-03, -3.8007e-03,\n",
      "        -1.5252e-02,  2.3327e-02, -7.1731e-02,  1.9421e-02,  6.2752e-03,\n",
      "        -9.0315e-04, -1.5514e-02, -5.5135e-03, -2.9183e-02, -4.6700e-03,\n",
      "         1.7537e-02, -5.6236e-02, -7.5301e-03,  8.7516e-03,  1.4362e-02,\n",
      "        -2.4172e-02,  6.4992e-03,  2.8642e-02, -2.4321e-02,  5.0440e-03,\n",
      "        -2.3450e-02,  1.8137e-02, -7.3615e-03,  2.1230e-02, -2.2998e-02,\n",
      "        -3.0007e-02, -3.7106e-03, -3.5397e-02], device='cuda:0')), ('b3.running_mean', tensor([-0.1087,  0.5477, -2.3129, -0.1664,  2.1825,  1.8384, -0.4645,  1.8136,\n",
      "         2.0896,  0.5536,  1.2784, -1.8033,  0.1561,  0.4977,  1.9838,  1.9419,\n",
      "        -0.7985, -0.3743, -0.6919,  0.5382, -0.6989,  0.9546, -2.3168,  0.4931,\n",
      "        -1.2210, -0.0540, -0.5520,  0.3474, -2.0155, -0.3935, -0.8156,  0.1682,\n",
      "        -0.3674,  1.3993, -0.4931,  0.4782,  0.4699,  0.1742,  1.0527,  0.2935,\n",
      "        -0.0375, -1.2677,  0.5851,  1.1960,  0.3729, -0.6226,  1.1145,  0.3531,\n",
      "         0.5944,  0.0562, -1.5782,  1.8590,  0.7128,  0.7511,  0.2882, -0.9712,\n",
      "         0.9071, -0.8146, -0.2161, -0.3527, -0.0214,  1.1005, -0.1194,  0.3270,\n",
      "         0.9166, -0.7327,  1.1083, -0.3172, -1.2381, -1.3257,  0.2261,  0.0303,\n",
      "        -0.1184,  0.7342,  1.3983,  2.0224,  0.1670,  1.5027,  0.7232,  0.2971,\n",
      "         0.3129, -0.1576, -0.0647, -0.4772,  0.2762,  0.4071, -0.4792,  1.9765,\n",
      "        -0.1717,  2.2712, -1.0502, -0.2601,  0.4949,  2.0042,  1.0772,  0.0319,\n",
      "         0.1963,  0.6321,  0.4338,  0.8534, -0.3120, -0.3224,  0.8403, -0.2998,\n",
      "         0.0160, -0.5509, -0.8515,  1.1009,  1.1781,  0.8551, -0.5199,  1.0420,\n",
      "         1.5427,  0.7124,  0.7485,  0.2156, -0.1084,  0.1039,  2.1502, -0.3396,\n",
      "         1.4630, -0.6560,  0.8188,  0.3802,  0.6032, -0.2364, -0.2164, -0.0898],\n",
      "       device='cuda:0')), ('b3.running_var', tensor([2.0287, 1.5772, 2.1413, 0.0786, 3.7740, 1.8360, 0.5576, 1.0975, 1.4277,\n",
      "        0.1370, 1.0758, 1.9572, 1.1062, 1.9781, 1.1860, 1.3453, 1.1015, 2.0122,\n",
      "        2.2608, 0.2692, 1.4804, 0.9800, 1.9561, 0.6521, 1.0384, 0.7332, 0.2994,\n",
      "        0.3106, 2.0320, 2.1322, 1.4759, 0.6640, 0.3282, 2.1699, 0.3425, 2.1358,\n",
      "        1.5136, 0.5737, 1.4767, 0.0761, 0.6573, 1.2565, 0.5205, 0.5316, 0.9329,\n",
      "        0.9206, 1.7906, 0.1213, 1.7321, 1.4154, 2.6199, 2.1389, 0.7246, 1.9736,\n",
      "        1.8068, 1.7821, 0.5024, 1.4931, 1.0718, 0.2879, 0.3709, 1.2254, 1.8741,\n",
      "        0.5237, 0.6754, 0.2671, 0.6298, 2.0119, 1.8279, 1.7080, 0.6846, 0.0652,\n",
      "        0.1098, 0.6782, 1.0819, 0.7270, 0.6923, 1.0659, 0.4246, 2.5701, 1.3830,\n",
      "        1.7128, 1.2292, 0.5278, 0.8950, 0.1154, 0.7456, 1.9265, 0.6978, 1.5205,\n",
      "        1.2903, 0.1820, 1.5974, 1.3708, 0.4171, 0.5068, 0.5134, 0.7043, 0.1893,\n",
      "        1.5938, 0.2160, 1.5874, 1.8625, 0.7626, 2.4267, 0.5210, 0.6153, 0.9485,\n",
      "        2.2563, 0.9218, 0.8419, 1.2149, 0.4629, 0.2316, 1.5219, 1.1530, 1.2405,\n",
      "        0.6481, 2.0680, 0.9300, 0.7856, 1.7272, 0.4399, 1.0514, 1.0328, 1.7332,\n",
      "        1.6252, 0.4084], device='cuda:0')), ('b3.num_batches_tracked', tensor(18750, device='cuda:0')), ('fc1.weight', tensor([[-6.4832e-02, -3.2065e-02, -5.1221e-02,  ...,  6.9056e-02,\n",
      "          5.4010e-02,  6.7763e-02],\n",
      "        [-4.5099e-02, -1.0264e-01,  5.4930e-02,  ..., -6.8385e-02,\n",
      "         -1.7093e-02,  5.4475e-02],\n",
      "        [-8.0643e-02, -8.9734e-02, -3.8540e-05,  ...,  3.5168e-02,\n",
      "          6.7903e-04,  7.9593e-02],\n",
      "        ...,\n",
      "        [ 9.3776e-02,  6.3368e-02,  3.6093e-02,  ...,  3.1957e-02,\n",
      "          5.2200e-02, -8.1881e-02],\n",
      "        [-1.3554e-03, -2.4016e-02,  1.7756e-03,  ..., -2.2674e-02,\n",
      "         -4.5567e-02, -5.3593e-03],\n",
      "        [-6.1275e-02, -3.9263e-02,  1.1189e-01,  ..., -6.0787e-02,\n",
      "         -4.5223e-02, -3.4759e-02]], device='cuda:0')), ('fc1.bias', tensor([ 1.8751e-02,  3.2181e-03,  3.3781e-02,  7.8886e-02,  5.9838e-02,\n",
      "         3.0431e-02,  7.6063e-02,  7.0337e-02,  4.8070e-02,  3.7446e-02,\n",
      "        -3.2104e-02,  6.2619e-02,  3.3157e-02, -1.6556e-02,  2.6493e-02,\n",
      "         1.1558e-02, -8.2914e-02, -4.5693e-02,  1.9791e-02, -2.7786e-02,\n",
      "         2.3921e-02, -6.5912e-02,  1.7928e-02, -4.0785e-02,  6.9454e-02,\n",
      "        -8.4741e-02,  6.2764e-02, -5.9617e-02, -5.5236e-02,  2.7980e-02,\n",
      "         5.0274e-02,  2.5818e-02,  7.8805e-02, -8.7342e-02, -1.4684e-02,\n",
      "        -6.7023e-02,  1.4969e-03,  1.6110e-02,  6.1945e-02,  3.8281e-02,\n",
      "         7.7491e-03, -3.4674e-02, -3.1402e-02, -2.4600e-02,  5.5445e-02,\n",
      "        -3.2703e-02,  8.5629e-02,  6.6057e-02, -4.1608e-02, -5.5974e-02,\n",
      "         5.3411e-02,  3.6055e-02, -5.6557e-02, -6.7594e-02, -6.6651e-02,\n",
      "        -2.4380e-02, -7.9149e-03, -8.8093e-02,  5.8677e-02, -6.5251e-02,\n",
      "        -1.9822e-03,  3.0592e-02, -6.9891e-02, -8.0361e-02,  7.5044e-02,\n",
      "         1.8856e-02, -6.1137e-02,  8.4699e-02,  2.5438e-02,  1.2120e-02,\n",
      "         1.2930e-02,  1.1134e-02,  1.8091e-02, -7.1113e-03, -1.5770e-03,\n",
      "         5.1384e-02, -2.9375e-02, -7.0966e-03, -1.8458e-02, -2.9100e-02,\n",
      "        -5.3772e-02, -2.2720e-02, -6.7624e-02, -4.2758e-02,  8.0363e-02,\n",
      "        -3.6194e-02, -8.3059e-02,  6.3044e-02, -2.8976e-02,  7.1573e-02,\n",
      "         3.9818e-02, -7.9914e-03,  7.6873e-02,  6.1389e-02, -8.0487e-02,\n",
      "        -1.9871e-02,  8.2226e-02, -8.4172e-03,  5.0337e-02,  8.1881e-02,\n",
      "         3.0377e-02, -7.1420e-02, -8.0727e-02,  4.5187e-02,  1.1727e-02,\n",
      "         2.1962e-02, -2.3104e-03,  1.6354e-02,  3.3712e-02,  7.2292e-02,\n",
      "         8.5595e-02,  3.7311e-02,  4.2152e-02, -7.4762e-02,  4.9060e-02,\n",
      "        -8.1553e-02, -3.6651e-02,  2.1189e-02, -6.5967e-03, -4.6904e-02,\n",
      "        -5.8326e-02,  8.5575e-02, -5.9880e-02, -8.3737e-02, -6.7473e-02,\n",
      "         1.1772e-02, -6.5902e-02, -5.6021e-02,  8.3009e-02,  3.3914e-02,\n",
      "         8.3983e-02, -7.8763e-03, -4.7341e-02,  7.5563e-02,  8.5066e-02,\n",
      "        -8.5757e-02, -6.2962e-02,  1.2162e-02, -8.3590e-02, -7.5134e-02,\n",
      "        -5.8206e-02, -5.6636e-02,  7.3088e-02,  5.1991e-02,  7.4288e-02,\n",
      "        -8.0516e-02, -2.0542e-02,  8.8291e-02,  1.7653e-03, -4.6568e-02,\n",
      "        -8.4583e-03,  8.6826e-03,  8.7853e-02,  1.6861e-02, -3.3575e-02,\n",
      "         5.4912e-02, -5.6399e-02, -3.6247e-03,  4.4227e-02,  5.3585e-02,\n",
      "        -1.1777e-02, -3.2239e-02,  1.3611e-02,  8.0502e-02, -3.2887e-02,\n",
      "         2.2722e-02, -7.4575e-02, -4.8835e-02, -3.9391e-04,  3.7938e-03,\n",
      "         1.8920e-03, -5.6728e-02,  4.5883e-04, -2.2502e-02, -7.5766e-02,\n",
      "        -3.1326e-02,  1.2317e-02, -7.9665e-02,  3.9172e-02, -3.1575e-02,\n",
      "         2.6496e-02,  1.0612e-02,  7.7898e-02,  7.5468e-02, -6.9904e-02,\n",
      "        -3.4144e-02, -1.3110e-02, -5.3113e-02,  6.9771e-02,  3.5913e-02,\n",
      "        -5.5229e-02, -2.5989e-02, -6.6653e-02, -1.1327e-02,  2.3655e-02,\n",
      "         4.7319e-02,  4.9994e-02,  2.3318e-02, -4.3682e-02, -8.6661e-02,\n",
      "        -3.1717e-02, -8.2700e-02,  7.4824e-02, -8.7512e-02, -7.1367e-02,\n",
      "        -5.4304e-02,  4.4492e-02, -3.2706e-03, -1.1675e-02, -3.1590e-02,\n",
      "         4.8073e-02, -2.3290e-02,  2.2608e-02, -8.8415e-03,  3.2823e-02,\n",
      "         4.6561e-02,  1.7946e-02, -7.1859e-02, -3.4712e-03, -1.2134e-02,\n",
      "        -1.4240e-02,  5.9712e-02, -5.9251e-02,  8.1958e-02,  8.6608e-02,\n",
      "        -7.4069e-02, -1.1974e-02, -3.0233e-02, -8.6611e-02, -1.7453e-02,\n",
      "         3.2311e-02, -5.6358e-02,  2.0909e-02,  8.1978e-02, -5.3185e-02,\n",
      "        -5.4213e-02, -5.1688e-02, -4.1299e-02, -6.9286e-02, -4.3954e-02,\n",
      "        -3.5624e-02, -8.1442e-02,  2.5209e-02,  6.9122e-02, -8.7271e-02,\n",
      "        -1.5409e-02, -2.7718e-02,  7.0966e-02, -3.6899e-02,  2.9759e-02,\n",
      "         6.8123e-02,  4.4823e-02, -8.8252e-02,  3.0908e-02,  8.0003e-02,\n",
      "        -1.8162e-02,  2.8486e-02,  2.6996e-02, -3.4538e-02,  2.2234e-02,\n",
      "         5.6842e-02, -5.3387e-02,  5.0041e-02,  8.4636e-02, -3.9653e-02,\n",
      "         3.5623e-02, -5.3875e-02,  6.1648e-02, -5.8265e-02, -3.2775e-02,\n",
      "        -3.8998e-03,  3.7973e-02, -2.9738e-02,  5.0315e-02, -2.1581e-02,\n",
      "         3.0919e-02,  2.4261e-03,  7.0032e-02,  5.3263e-02,  7.7332e-02,\n",
      "         6.5451e-02, -8.6553e-02, -4.5950e-02,  8.2990e-02,  5.0603e-02,\n",
      "         8.5225e-02, -8.4820e-02, -8.8371e-02,  7.4654e-02, -2.3977e-03,\n",
      "         3.4495e-02,  5.4914e-02, -5.4048e-02,  8.6512e-02, -8.6328e-02,\n",
      "         4.1554e-02,  5.3590e-02, -4.6190e-03, -3.0240e-02,  6.2852e-02,\n",
      "        -1.3630e-02, -1.9880e-02,  2.5940e-02, -7.2534e-03, -3.6628e-02,\n",
      "         8.3071e-03, -7.4895e-02, -1.0144e-02,  6.6038e-02, -4.3055e-02,\n",
      "         1.6958e-02,  5.0279e-02, -4.2139e-04,  6.1322e-02,  5.8386e-02,\n",
      "         3.4828e-02,  6.7755e-02,  2.7722e-02, -6.4369e-02, -1.5193e-02,\n",
      "         2.0124e-02,  1.5204e-02, -5.1037e-02, -3.1600e-02, -3.6975e-02,\n",
      "        -5.6480e-02,  1.8511e-02,  1.1770e-03, -1.0242e-03,  3.0187e-02,\n",
      "         3.8957e-02,  2.1974e-03, -8.0925e-02, -1.0052e-02,  1.1764e-02,\n",
      "         2.5357e-02, -8.6983e-02,  3.6397e-02, -7.6143e-04, -8.7619e-02,\n",
      "         3.0337e-02,  6.8525e-02, -6.3566e-02,  1.7105e-02,  3.1395e-02,\n",
      "         6.4809e-02,  2.5499e-02, -7.4515e-02, -2.6754e-02,  5.3985e-02,\n",
      "        -4.2885e-02, -5.8800e-02,  1.5861e-02, -2.7759e-02,  2.1171e-02,\n",
      "         1.2683e-02,  4.1339e-02,  4.8998e-02,  4.5561e-02, -1.6305e-02,\n",
      "         7.4131e-02,  6.5088e-02, -7.9244e-02,  2.2170e-02,  6.0057e-02,\n",
      "        -5.5355e-02,  7.6922e-02, -1.7085e-02,  8.1046e-02,  4.5051e-02,\n",
      "         2.9486e-03,  8.5335e-02, -2.0386e-02, -9.0511e-04, -7.0604e-02,\n",
      "        -5.9074e-02,  6.4328e-02, -8.8079e-02, -1.9387e-02, -7.2201e-02,\n",
      "        -8.0800e-02,  8.1648e-02,  1.7976e-02, -1.5069e-02,  2.4513e-02,\n",
      "         7.3788e-03,  4.7364e-02,  6.0623e-02, -1.4661e-02, -1.8560e-03,\n",
      "         5.7925e-02,  2.5800e-02,  2.4200e-02, -7.9747e-02, -5.8532e-02,\n",
      "         6.2036e-03, -7.2075e-02,  3.8228e-02, -4.2618e-02, -6.4292e-02,\n",
      "         6.6151e-02, -4.7811e-02,  5.0623e-02,  1.2589e-02,  2.5246e-02,\n",
      "         2.8051e-03, -5.7918e-02, -3.5610e-02, -1.5124e-02,  6.3956e-02,\n",
      "        -5.6488e-02, -3.6706e-02,  6.2516e-02,  6.6789e-02, -1.0827e-02,\n",
      "        -3.5469e-02, -5.7437e-02, -1.6737e-02, -5.2986e-02,  7.5672e-02,\n",
      "        -3.4593e-02,  6.6279e-02, -3.4409e-02, -6.8191e-02,  7.0851e-02,\n",
      "        -8.0827e-03, -4.4166e-02, -6.8393e-02, -1.5530e-02, -6.8742e-03,\n",
      "         8.1781e-02,  8.1674e-02,  4.0565e-02, -4.3159e-02,  4.7299e-03,\n",
      "        -1.3992e-02,  1.8354e-02,  3.1973e-02, -7.2709e-02,  5.2200e-02,\n",
      "        -7.0642e-03,  4.3284e-02, -7.5781e-02, -2.6155e-02, -5.8122e-02,\n",
      "        -2.6257e-02, -6.0041e-02, -1.9773e-02, -5.8998e-02, -2.3081e-02,\n",
      "        -7.5455e-02,  2.7658e-02,  3.9796e-02,  7.6623e-02,  4.1656e-02,\n",
      "        -2.4733e-05, -3.1729e-02, -1.3563e-02,  5.2084e-02,  4.1958e-02,\n",
      "        -1.7385e-03, -2.7617e-02, -1.0436e-02,  6.4611e-02, -3.6323e-02,\n",
      "         2.7979e-03, -6.0933e-02, -4.8956e-02,  5.0712e-02, -5.8478e-02,\n",
      "         2.1701e-02,  3.3804e-02,  7.1505e-02, -7.1484e-02, -6.4234e-02,\n",
      "         2.7795e-03,  6.3035e-02, -6.1900e-02, -4.6656e-02,  6.4057e-04,\n",
      "        -8.3212e-03,  2.4853e-02, -2.2637e-02, -7.0824e-02, -1.2318e-02,\n",
      "        -9.3660e-03,  3.3341e-02,  1.5633e-02,  6.3157e-02, -1.3156e-02,\n",
      "        -7.6030e-02,  5.3651e-03,  3.0503e-02, -5.5378e-02,  3.1252e-02,\n",
      "         6.7988e-02,  4.3808e-02,  5.1661e-02, -2.9879e-02, -8.7956e-02,\n",
      "         1.9171e-02, -7.9145e-02,  8.7184e-02,  2.4787e-02,  9.2707e-03,\n",
      "         6.7021e-02,  4.9994e-02, -7.4223e-02,  4.8543e-03,  7.4330e-02,\n",
      "         3.0967e-02, -2.7559e-02], device='cuda:0')), ('bf1.weight', tensor([4.1993e-01, 5.6772e-01, 4.1757e-01, 1.7534e-01, 7.5159e-01, 8.1251e-01,\n",
      "        9.7352e-01, 2.7449e-01, 1.6971e-01, 5.4240e-02, 4.3954e-02, 8.8987e-01,\n",
      "        9.6155e-01, 6.5615e-01, 6.5939e-01, 9.1116e-01, 5.8754e-02, 6.4968e-01,\n",
      "        1.5878e-01, 2.9842e-01, 5.4580e-01, 4.7026e-01, 3.0583e-02, 5.2783e-01,\n",
      "        7.8363e-01, 5.7532e-02, 3.3756e-01, 6.8096e-01, 2.3688e-01, 4.2426e-01,\n",
      "        9.4810e-01, 1.2765e-01, 4.8557e-01, 3.6589e-03, 9.2831e-01, 2.9842e-01,\n",
      "        1.4761e-01, 9.1331e-02, 5.5245e-01, 6.6879e-01, 3.6913e-01, 7.4200e-01,\n",
      "        2.2311e-01, 1.7384e-01, 8.5456e-01, 8.6649e-01, 1.0812e-01, 5.3139e-01,\n",
      "        5.0337e-01, 6.1841e-01, 1.7665e-01, 9.1423e-01, 5.7003e-01, 8.6370e-01,\n",
      "        9.5596e-01, 9.2082e-02, 8.6364e-01, 3.0917e-01, 4.7306e-01, 1.6531e-01,\n",
      "        5.1386e-01, 5.6442e-01, 9.6619e-01, 5.1102e-01, 4.3700e-01, 8.7816e-01,\n",
      "        9.0953e-01, 5.7824e-01, 6.5657e-01, 2.1354e-01, 3.3017e-01, 7.5176e-01,\n",
      "        8.3391e-01, 6.6424e-01, 8.0878e-02, 8.4909e-01, 1.4462e-01, 6.0625e-01,\n",
      "        5.9537e-01, 6.2219e-01, 5.1577e-01, 9.3824e-01, 6.7436e-01, 5.9058e-01,\n",
      "        4.5892e-01, 6.0959e-01, 1.5853e-01, 2.8359e-01, 3.4014e-01, 6.7508e-01,\n",
      "        3.1090e-01, 3.7169e-01, 1.4030e-01, 4.2497e-01, 8.8888e-01, 9.1954e-01,\n",
      "        2.6487e-01, 5.9244e-01, 6.3608e-01, 7.3426e-02, 2.9522e-01, 2.1326e-01,\n",
      "        5.7809e-01, 5.0881e-01, 4.3496e-02, 6.3955e-01, 5.6478e-02, 6.7630e-01,\n",
      "        6.0029e-01, 2.9926e-01, 2.5673e-01, 8.2757e-01, 1.3058e-01, 7.0207e-01,\n",
      "        3.9640e-01, 6.5365e-02, 4.6481e-01, 2.4681e-01, 6.4128e-01, 3.7662e-01,\n",
      "        3.0546e-01, 3.3072e-01, 6.1875e-01, 4.2870e-01, 6.0596e-01, 4.7010e-03,\n",
      "        5.3378e-01, 2.5671e-01, 1.0391e-01, 8.0925e-01, 8.3863e-01, 6.0222e-01,\n",
      "        5.2879e-01, 8.3232e-01, 8.1869e-01, 6.4196e-01, 2.5376e-01, 8.1810e-01,\n",
      "        4.2334e-01, 3.4098e-01, 6.1093e-01, 6.2948e-01, 5.1029e-01, 2.2345e-01,\n",
      "        8.9943e-01, 8.2252e-01, 2.9739e-01, 3.8462e-01, 8.7677e-01, 5.2550e-01,\n",
      "        7.8393e-01, 1.5770e-02, 5.7564e-01, 3.5039e-01, 8.3290e-01, 1.1923e-01,\n",
      "        3.1783e-01, 1.7994e-01, 8.2309e-02, 6.7150e-01, 1.4626e-01, 7.0839e-01,\n",
      "        7.7889e-01, 7.8257e-01, 5.7769e-01, 5.1857e-01, 2.2161e-01, 1.5314e-01,\n",
      "        7.7276e-01, 9.0376e-01, 1.3107e-01, 2.7349e-02, 4.1279e-01, 7.2072e-01,\n",
      "        1.3828e-01, 8.0083e-02, 8.7765e-01, 5.4524e-01, 2.1216e-01, 8.5645e-01,\n",
      "        5.1007e-01, 5.7753e-01, 6.7110e-01, 6.1311e-01, 1.1117e-01, 2.9442e-01,\n",
      "        6.2456e-01, 6.1843e-01, 4.1599e-01, 5.0294e-02, 3.5976e-01, 2.4532e-01,\n",
      "        8.1654e-01, 7.1924e-01, 8.0662e-03, 3.8388e-01, 4.3917e-01, 6.2410e-01,\n",
      "        3.0994e-02, 8.2849e-01, 9.4611e-01, 4.3843e-01, 8.2598e-01, 6.8374e-01,\n",
      "        8.2583e-01, 7.0151e-01, 9.5662e-01, 5.8629e-01, 4.0997e-01, 4.6495e-01,\n",
      "        4.6925e-01, 8.3652e-02, 3.7124e-01, 1.3607e-01, 5.9713e-01, 5.4233e-01,\n",
      "        3.8010e-01, 1.3857e-01, 6.7318e-02, 3.8330e-01, 1.7297e-01, 4.5541e-01,\n",
      "        4.1400e-01, 4.8645e-01, 7.6937e-02, 8.1656e-01, 3.5272e-01, 1.9903e-01,\n",
      "        6.9061e-03, 3.8785e-01, 7.3057e-01, 1.1341e-01, 9.4961e-01, 7.4688e-01,\n",
      "        6.5233e-01, 2.6044e-01, 9.2494e-01, 5.3374e-01, 6.4026e-01, 9.5717e-01,\n",
      "        7.3467e-01, 9.3251e-02, 8.0590e-01, 4.4986e-01, 2.7744e-01, 3.9973e-02,\n",
      "        8.0312e-01, 2.7227e-01, 2.6729e-01, 6.1706e-02, 6.8362e-01, 2.7126e-01,\n",
      "        9.6401e-01, 4.8995e-01, 4.4635e-02, 2.8819e-01, 5.1549e-01, 5.6446e-01,\n",
      "        9.4189e-01, 8.5482e-01, 6.3308e-01, 8.3062e-01, 4.6401e-01, 6.3563e-01,\n",
      "        1.8562e-01, 3.8788e-01, 1.9629e-02, 5.9357e-01, 5.7356e-01, 4.3527e-01,\n",
      "        2.3163e-01, 4.5126e-01, 3.9319e-01, 7.2874e-01, 9.2550e-01, 7.9387e-01,\n",
      "        1.9944e-02, 1.6803e-01, 8.8085e-01, 5.2175e-01, 6.5842e-02, 7.8859e-01,\n",
      "        3.9914e-01, 6.5218e-01, 7.9117e-01, 8.2352e-01, 8.1561e-01, 4.2950e-01,\n",
      "        7.6899e-01, 9.5431e-01, 6.4165e-01, 7.3010e-01, 6.8985e-01, 2.7031e-01,\n",
      "        2.1123e-01, 5.3853e-01, 8.2216e-01, 2.2325e-01, 3.2219e-01, 9.2969e-01,\n",
      "        1.7965e-01, 8.4097e-02, 8.6896e-01, 1.0552e-01, 7.9795e-01, 7.8165e-01,\n",
      "        8.0241e-01, 6.2600e-01, 5.9030e-01, 7.2654e-01, 1.9047e-01, 8.6605e-01,\n",
      "        4.8974e-01, 9.5685e-01, 3.2215e-01, 2.5315e-01, 4.6391e-01, 6.0702e-01,\n",
      "        1.9437e-01, 4.9007e-01, 2.6088e-01, 8.7386e-01, 8.0756e-01, 2.1428e-01,\n",
      "        5.3546e-01, 5.1387e-01, 7.4422e-01, 7.1294e-01, 8.2455e-01, 6.8109e-01,\n",
      "        7.6619e-01, 1.3490e-01, 9.1488e-01, 6.3948e-01, 4.0654e-01, 7.6133e-01,\n",
      "        1.0357e-01, 8.8291e-01, 8.4032e-02, 5.6507e-01, 3.3156e-01, 2.1363e-01,\n",
      "        9.5356e-01, 5.3332e-01, 1.0913e-01, 7.1559e-01, 8.7222e-01, 4.3170e-01,\n",
      "        8.5356e-01, 7.4262e-01, 6.4989e-01, 1.9069e-01, 1.0956e-01, 8.7542e-01,\n",
      "        4.1183e-01, 4.4104e-02, 4.1322e-01, 2.7277e-01, 1.1867e-01, 3.2739e-01,\n",
      "        3.5948e-01, 8.4648e-01, 4.5911e-01, 8.1725e-01, 8.4323e-01, 6.8177e-03,\n",
      "        2.2066e-01, 1.2143e-01, 7.0456e-01, 1.8934e-01, 2.0080e-02, 7.2877e-01,\n",
      "        2.6435e-01, 4.4968e-01, 6.2892e-01, 7.0199e-01, 4.9889e-01, 7.1823e-01,\n",
      "        3.4272e-01, 1.1476e-01, 3.3207e-01, 6.4604e-01, 3.8290e-01, 7.6851e-02,\n",
      "        2.5386e-01, 1.7334e-01, 9.6628e-01, 1.2678e-01, 6.3831e-02, 4.1377e-01,\n",
      "        3.9432e-01, 2.6550e-01, 2.1158e-01, 3.5501e-01, 5.6716e-01, 3.3515e-01,\n",
      "        3.9670e-03, 4.7626e-01, 1.0955e-01, 4.9483e-01, 9.1130e-02, 5.1234e-01,\n",
      "        6.4021e-01, 2.1639e-01, 5.9595e-01, 2.2392e-01, 1.4526e-02, 8.1580e-01,\n",
      "        7.6906e-01, 5.6005e-01, 3.8116e-01, 8.3151e-01, 3.2002e-01, 2.6148e-01,\n",
      "        8.6342e-01, 6.2797e-01, 7.8855e-01, 4.7833e-01, 3.1595e-04, 8.7806e-01,\n",
      "        8.4561e-01, 5.1568e-01, 8.5551e-01, 5.3996e-01, 2.7315e-01, 2.1826e-01,\n",
      "        1.7097e-01, 9.2678e-01, 8.8227e-01, 7.0307e-01, 8.9503e-02, 3.3972e-02,\n",
      "        2.1329e-01, 6.5355e-01, 9.4872e-01, 8.9945e-01, 8.9363e-01, 2.5366e-01,\n",
      "        7.6709e-01, 7.5026e-01, 7.2146e-01, 7.6218e-01, 1.9438e-03, 2.2826e-01,\n",
      "        3.7694e-01, 4.9593e-01, 2.6914e-01, 5.6292e-02, 7.3659e-01, 9.3421e-01,\n",
      "        3.2926e-01, 2.5883e-01, 1.3813e-01, 8.6316e-01, 3.6194e-01, 6.3417e-01,\n",
      "        2.9550e-01, 6.5991e-01, 6.6440e-01, 3.0103e-01, 4.3816e-01, 3.2055e-01,\n",
      "        5.7777e-01, 2.6208e-01, 5.0402e-01, 7.4199e-01, 7.4678e-01, 7.1187e-01,\n",
      "        4.9693e-01, 6.6384e-01, 2.6645e-01, 1.5542e-01, 4.7032e-01, 6.6005e-03,\n",
      "        6.0378e-01, 1.5487e-01, 6.6468e-01, 7.9335e-01, 1.8638e-01, 6.6061e-04,\n",
      "        4.2683e-01, 8.3163e-01, 1.3485e-01, 9.2889e-01, 1.9659e-01, 4.3894e-01,\n",
      "        5.7132e-01, 6.5249e-01, 5.9404e-02, 6.4500e-01, 2.4539e-01, 8.0609e-01,\n",
      "        8.1342e-02, 3.3591e-01, 2.2265e-01, 5.2515e-01, 6.7468e-01, 1.6572e-01,\n",
      "        3.1983e-01, 1.7989e-01, 6.6433e-01, 8.5311e-02, 5.5263e-01, 5.4861e-01,\n",
      "        6.6330e-01, 9.2653e-01, 4.8887e-01, 8.0565e-01, 7.9598e-01, 9.6001e-01,\n",
      "        7.8011e-01, 6.5141e-01], device='cuda:0')), ('bf1.bias', tensor([ 2.4553e-02,  1.8534e-02, -7.1514e-03,  2.5686e-02, -4.2870e-03,\n",
      "        -1.7263e-02, -4.7661e-03,  2.5104e-02,  2.6368e-02,  3.4744e-03,\n",
      "         1.9345e-02, -1.8827e-02, -2.6905e-02,  1.0444e-02, -1.6221e-02,\n",
      "        -3.9648e-02, -1.4393e-02,  9.6983e-03,  2.1112e-02,  2.9315e-02,\n",
      "         5.2425e-02,  2.1558e-02,  1.6131e-02,  1.9601e-02, -2.1630e-02,\n",
      "         1.7002e-02,  2.3997e-02, -1.2329e-02,  2.6776e-02,  2.5079e-02,\n",
      "        -7.2273e-03,  1.5444e-02,  8.3601e-03, -6.7001e-03, -6.1505e-03,\n",
      "         2.3142e-02, -1.3020e-02,  2.9796e-02,  1.3448e-02,  3.6143e-02,\n",
      "         2.5928e-02,  6.2236e-03,  3.5517e-02,  3.4818e-02, -7.7071e-03,\n",
      "        -1.2024e-02,  1.0656e-02,  1.4003e-02,  1.3945e-03,  1.5187e-02,\n",
      "         2.5362e-02, -2.4295e-02,  2.3143e-02,  4.9551e-03, -1.3779e-02,\n",
      "         3.0171e-02, -4.7561e-03,  4.5901e-02,  1.8655e-02,  1.5634e-02,\n",
      "         1.7987e-02, -3.1360e-03, -1.6191e-03,  7.7270e-03,  8.6560e-03,\n",
      "        -2.3505e-02, -1.4378e-02,  1.0164e-02,  3.8330e-03,  2.7674e-02,\n",
      "         5.6324e-02,  8.1602e-03, -8.4422e-03,  3.2431e-02,  2.5338e-02,\n",
      "        -2.2689e-04,  6.5250e-03,  1.4767e-02,  6.9217e-04, -1.9487e-02,\n",
      "         1.6703e-02, -1.1643e-02,  1.5342e-04,  1.7370e-02, -5.9843e-04,\n",
      "        -4.8236e-04,  1.6105e-02,  2.7894e-02,  1.9759e-02, -1.1948e-02,\n",
      "         3.6745e-02,  2.1426e-02,  2.1869e-02,  4.2070e-02, -2.5031e-02,\n",
      "        -2.5515e-02,  2.9566e-02,  3.7559e-02,  2.5555e-02,  2.2303e-02,\n",
      "        -9.3782e-04,  1.7579e-02, -1.0623e-02,  2.8972e-02, -1.6111e-03,\n",
      "         4.1913e-03,  8.9147e-04,  1.7095e-04, -7.4009e-03,  2.9802e-02,\n",
      "         3.0831e-02,  3.5447e-02, -1.1173e-02,  6.8987e-03,  3.8365e-02,\n",
      "         4.7009e-03,  5.3778e-02,  3.1169e-02,  2.3512e-02,  2.5860e-02,\n",
      "         5.0588e-02,  3.3542e-02,  1.8650e-02,  1.0882e-02,  2.9383e-03,\n",
      "        -8.2274e-03,  4.8458e-02,  1.3123e-02, -9.3802e-03, -3.7969e-02,\n",
      "        -2.5893e-02,  2.6501e-02,  1.4169e-02,  1.2767e-04, -1.6024e-03,\n",
      "         4.3746e-02,  1.6827e-02, -1.2309e-02,  9.7520e-03,  2.2743e-02,\n",
      "        -9.9688e-03,  9.3307e-03, -4.4191e-03,  1.9125e-02, -1.7024e-02,\n",
      "        -5.5173e-03,  1.8380e-02,  3.2362e-03, -2.6477e-02,  1.2101e-02,\n",
      "         1.4725e-03,  2.2364e-03,  1.8446e-02,  2.9346e-02, -1.9527e-02,\n",
      "        -6.6060e-03,  2.1187e-02,  3.3433e-02,  1.6535e-02, -4.9234e-03,\n",
      "         2.5879e-02,  6.1431e-03, -5.4637e-03, -2.3224e-02,  8.0974e-03,\n",
      "         1.3767e-02,  3.0852e-02, -5.0863e-03,  1.1974e-02, -1.1013e-02,\n",
      "         2.5293e-02, -1.7023e-02,  2.2188e-02,  5.8216e-03, -6.0541e-03,\n",
      "        -9.9684e-03, -2.9548e-02,  2.7364e-02,  2.2767e-02,  6.1462e-03,\n",
      "         2.2050e-02,  5.3827e-03,  5.1388e-03,  4.0079e-04,  7.6296e-03,\n",
      "         2.7868e-02,  1.8731e-03,  1.6585e-02,  2.8906e-02,  4.8421e-03,\n",
      "         4.0914e-02,  2.7186e-02, -2.0524e-02, -1.8812e-03, -1.4240e-02,\n",
      "         5.1192e-02, -3.0854e-03,  4.2958e-02,  5.7483e-04, -1.5744e-02,\n",
      "        -2.0864e-02,  1.1287e-02,  1.3038e-02,  1.7275e-03, -2.2249e-02,\n",
      "         8.4433e-04, -2.9713e-02,  2.0747e-02,  1.4947e-02,  1.4541e-02,\n",
      "         2.6874e-02,  1.4190e-02,  4.6918e-02, -4.4424e-04,  1.3450e-03,\n",
      "         3.0089e-02,  3.5733e-02,  2.0980e-02,  1.9618e-03,  4.2359e-02,\n",
      "         1.8027e-02,  2.0645e-03,  3.6167e-02,  1.5938e-02,  1.6279e-02,\n",
      "        -3.2741e-03,  5.1385e-02, -1.0784e-02, -1.2489e-02,  3.5746e-02,\n",
      "        -1.0719e-02, -1.1499e-02, -5.4438e-03, -4.6513e-02, -8.7537e-03,\n",
      "         3.1072e-02, -1.1467e-02,  6.9751e-03,  3.8577e-02, -3.9096e-02,\n",
      "         1.0034e-03,  1.7599e-02, -1.6794e-02,  9.4555e-03,  1.7904e-02,\n",
      "         7.7002e-03, -3.6731e-03,  8.8719e-03,  1.2484e-02,  1.5373e-02,\n",
      "         4.2945e-03,  3.4419e-02, -2.4575e-03,  1.6764e-02, -1.7844e-03,\n",
      "         1.8519e-02,  7.4140e-03,  1.1856e-02, -2.0416e-02, -2.0011e-02,\n",
      "         6.7146e-03, -2.5861e-02,  2.0046e-02,  7.7583e-04,  2.3434e-02,\n",
      "         1.7422e-02,  2.1583e-02,  2.6973e-03,  5.8768e-03,  2.5606e-02,\n",
      "         4.2161e-02,  2.5274e-02,  2.5861e-02,  6.6474e-03, -8.6089e-03,\n",
      "        -5.4839e-03,  4.0782e-03,  3.9668e-02, -3.6491e-02,  3.4305e-02,\n",
      "         1.1826e-02, -3.1440e-02,  2.5381e-02,  4.4486e-02,  3.8035e-03,\n",
      "        -8.4643e-03,  9.3145e-04,  2.3694e-02, -1.2466e-02, -2.3760e-02,\n",
      "         2.7396e-02,  6.9303e-03,  1.3116e-03,  6.6815e-02,  2.8560e-02,\n",
      "         2.0875e-02, -1.8485e-02,  3.0432e-02,  1.7373e-02, -1.6284e-02,\n",
      "         2.9065e-02,  1.0339e-02, -2.7438e-02, -9.1819e-03,  5.2126e-03,\n",
      "        -1.2511e-02, -1.4047e-02,  1.5607e-02,  4.8330e-02,  4.1318e-03,\n",
      "         3.7100e-02, -3.2011e-02, -3.4173e-03, -3.8116e-02,  3.5804e-02,\n",
      "         2.0574e-02,  1.5275e-02,  2.1782e-02,  3.5417e-02,  3.5849e-02,\n",
      "         1.6190e-02, -2.2791e-02, -1.5672e-02,  2.2193e-02,  2.2056e-02,\n",
      "         3.0340e-02, -1.5187e-02,  1.1625e-02, -1.7948e-02, -1.3080e-02,\n",
      "        -2.1110e-02,  1.2935e-02, -3.0173e-02,  9.7390e-03,  5.0188e-02,\n",
      "         1.0673e-02,  1.1261e-02, -3.4995e-02,  2.6644e-02,  1.9704e-02,\n",
      "         3.6477e-02, -7.3977e-03, -1.5914e-02, -1.1863e-03,  3.9622e-02,\n",
      "         7.1157e-03, -3.9677e-02,  1.5260e-02, -1.2170e-02,  1.1577e-02,\n",
      "         3.0810e-02,  1.6045e-03,  1.2539e-02, -9.4493e-03,  1.8317e-02,\n",
      "         2.8515e-02,  3.3130e-02,  5.3566e-03, -5.8682e-04,  2.7222e-02,\n",
      "         3.2138e-02, -2.1563e-02,  2.7590e-02, -2.2530e-02,  1.4955e-02,\n",
      "        -1.1846e-02,  3.0932e-02,  2.2799e-02,  3.4084e-02, -1.6118e-03,\n",
      "         2.3097e-03, -1.0175e-02,  1.5409e-02,  2.5577e-02,  8.3248e-03,\n",
      "         2.6762e-03,  9.1022e-03, -1.1903e-02,  3.0596e-02,  8.9237e-03,\n",
      "         4.7648e-02,  3.4469e-03,  3.9782e-02,  1.0964e-02,  3.5550e-02,\n",
      "         1.1807e-02, -2.6930e-02,  2.2924e-02,  1.1566e-02,  1.6132e-02,\n",
      "         3.0358e-02,  2.9704e-02,  6.0607e-03,  2.7694e-02,  2.3509e-02,\n",
      "         4.4120e-02, -7.1458e-03,  1.6138e-03,  4.2464e-03,  4.3137e-02,\n",
      "        -7.4996e-04,  3.1220e-02,  6.8379e-04,  1.7755e-02,  1.8068e-05,\n",
      "         2.4281e-02, -6.8047e-03, -1.0387e-02, -5.4977e-03,  3.0646e-02,\n",
      "        -1.4613e-03, -4.6050e-03, -5.6374e-03,  2.8361e-02, -8.2707e-03,\n",
      "        -2.0257e-03, -2.6583e-02,  2.2361e-02, -1.1937e-03, -1.1297e-02,\n",
      "        -4.4757e-03, -8.7370e-03, -7.7758e-03,  7.9929e-03,  9.3391e-03,\n",
      "        -6.5332e-03,  2.1972e-02, -2.3690e-02, -3.4087e-02,  1.1621e-02,\n",
      "         2.1522e-02,  2.9050e-03,  1.8019e-02,  1.0816e-02, -2.4498e-02,\n",
      "        -4.4674e-03, -1.1636e-02,  1.2041e-02, -3.6136e-02, -2.2907e-02,\n",
      "         8.2074e-03,  4.7770e-03, -3.4536e-03,  1.2160e-03,  1.2237e-02,\n",
      "         2.0546e-02,  3.6647e-02,  2.1044e-03,  1.0353e-02, -2.0700e-02,\n",
      "         1.2324e-02,  5.8412e-02,  9.4494e-03, -2.9163e-02,  9.6316e-03,\n",
      "         4.7554e-03,  1.9682e-02,  6.5039e-03, -1.2569e-02, -9.5277e-03,\n",
      "         2.7217e-02,  2.7285e-02,  2.1004e-02,  5.6761e-03,  2.1890e-02,\n",
      "         7.0823e-04,  2.7649e-02, -1.6082e-02,  1.7679e-02,  3.0017e-02,\n",
      "         5.1780e-02,  2.5465e-02,  2.2679e-02, -1.1557e-02,  7.3113e-03,\n",
      "         1.8733e-02,  1.5765e-02, -8.4367e-03, -6.0036e-03, -2.0262e-03,\n",
      "         5.8925e-02, -2.1016e-02,  9.3223e-03, -3.1488e-02,  5.4637e-02,\n",
      "         1.4318e-02,  7.5343e-03, -1.5827e-02,  1.1816e-02,  7.2386e-05,\n",
      "         3.0238e-02, -2.2108e-02,  3.1917e-03,  2.3469e-02,  6.0651e-02,\n",
      "         5.2206e-02,  6.9504e-03,  2.2914e-02,  2.7053e-02,  1.6612e-02,\n",
      "        -3.8735e-03,  1.3220e-02,  3.0670e-02,  3.0410e-02, -3.2704e-03,\n",
      "        -3.1692e-02,  6.7705e-03, -1.6187e-02, -2.0355e-02, -8.6352e-03,\n",
      "        -1.5999e-02,  1.0676e-02], device='cuda:0')), ('bf1.running_mean', tensor([ 3.9533e-01, -2.0579e-01,  4.7812e-01,  1.6216e-02,  5.3907e-02,\n",
      "         1.2818e-01,  8.2055e-01,  1.0443e-01,  6.2522e-02, -6.9685e-03,\n",
      "         3.4385e-02,  1.0542e-01, -9.4962e-03,  3.0913e-02, -3.0995e-01,\n",
      "         1.9692e-01, -3.4933e-02, -1.4512e-01, -2.6474e-01, -8.4412e-02,\n",
      "         8.4201e-02, -1.5108e-01, -4.4786e-01, -4.4050e-01, -4.0456e-01,\n",
      "        -3.7088e-01, -3.0643e-01, -1.5570e-01,  1.6373e-01, -4.7436e-01,\n",
      "        -4.0934e-01, -1.0196e-01, -4.7284e-01, -2.7958e-01,  4.5308e-01,\n",
      "        -1.0381e-01,  1.4153e-01,  2.5393e-01, -2.2768e-01,  1.2768e+00,\n",
      "        -1.8809e-01, -3.0657e-01,  1.5707e-01,  5.1177e-01, -2.2440e-01,\n",
      "         1.1763e-01,  1.3982e-01,  1.4159e-01, -4.1616e-01,  4.5090e-01,\n",
      "         4.4876e-01, -1.1482e-01, -3.7596e-01,  3.0832e-02, -7.5683e-02,\n",
      "        -1.5622e-01, -7.9306e-01,  9.6396e-02,  6.3966e-02, -5.4248e-01,\n",
      "        -5.8244e-01, -1.1667e-01, -1.0263e-01, -6.5566e-02,  3.1163e-01,\n",
      "         7.2273e-02,  7.3124e-01, -6.5926e-03, -3.3765e-01,  8.3172e-03,\n",
      "         7.0480e-01,  1.5151e-01, -5.9312e-01,  7.3204e-01, -7.2997e-01,\n",
      "        -2.5745e-01, -1.2193e-02,  2.3216e-01, -7.9925e-01, -8.1041e-01,\n",
      "        -4.5521e-02, -2.1543e-01,  9.2027e-02,  6.4251e-02,  4.6738e-01,\n",
      "        -5.4195e-01, -1.4515e-01,  5.3872e-01, -1.1657e-02,  3.8316e-01,\n",
      "         5.9740e-01,  3.9743e-01, -2.4024e-01,  3.9291e-02, -2.1858e-01,\n",
      "        -8.2043e-01, -9.6235e-02, -4.5503e-01,  4.6100e-01, -6.9819e-02,\n",
      "        -5.3416e-02, -4.1731e-01, -2.2312e-01,  5.8288e-01, -1.0383e-01,\n",
      "         1.6308e-01, -1.9348e-01, -3.4763e-01, -3.6229e-01, -2.3511e-01,\n",
      "         3.3498e-01, -4.0004e-01,  4.4229e-01,  5.7437e-01,  2.0731e-01,\n",
      "        -1.7538e-01,  4.3270e-02,  4.7271e-01, -4.5664e-01, -2.7891e-01,\n",
      "        -3.5757e-01,  1.2613e-01, -7.2811e-01,  2.3387e-01,  2.8367e-01,\n",
      "         1.0727e-01,  4.4353e-01,  2.4625e-01,  8.2745e-02, -1.7168e-01,\n",
      "        -1.5346e-01,  1.2605e-01, -1.7777e-01, -8.0743e-02,  1.4545e-01,\n",
      "        -1.5474e-01,  5.8511e-02, -2.8913e-01,  1.3425e-02,  3.1855e-01,\n",
      "        -3.5224e-02,  6.5065e-01,  6.7983e-01, -2.2224e-02, -8.9811e-01,\n",
      "         1.0098e-01,  3.4297e-03, -2.4205e-01, -7.9561e-02,  4.6861e-01,\n",
      "         4.6776e-01,  1.0937e-01,  5.5437e-01, -1.6976e-01,  3.6758e-01,\n",
      "        -1.8560e-02, -8.3331e-01,  2.4021e-01,  8.3076e-02,  7.9553e-01,\n",
      "        -2.8859e-01,  6.9079e-02, -8.3462e-02, -6.2322e-01,  1.6248e-01,\n",
      "        -8.9652e-02, -5.6880e-02, -2.3077e-01, -7.3015e-01,  4.8852e-01,\n",
      "         1.4410e-01, -2.1233e-01, -1.3193e-01,  2.6345e-01, -2.6532e-01,\n",
      "         1.3758e-01, -3.5081e-01,  3.4485e-01, -9.3013e-03,  4.0381e-02,\n",
      "         2.2169e-01,  6.7355e-01,  6.9072e-02, -6.3936e-01, -6.8748e-01,\n",
      "        -8.1991e-02, -2.9816e-04,  6.9963e-02,  4.4813e-01,  6.3280e-02,\n",
      "         9.2227e-02, -2.6191e-01, -3.6971e-01,  4.1669e-01, -6.7322e-02,\n",
      "        -3.8261e-01,  7.9469e-01, -5.3335e-02, -4.8536e-01, -5.8486e-02,\n",
      "        -1.0307e-01, -3.3516e-01,  4.7688e-02,  1.5578e-01, -5.7144e-01,\n",
      "        -1.6118e-01, -6.7007e-01, -1.2330e-01,  6.6516e-02,  2.8228e-01,\n",
      "        -2.2898e-01,  2.9533e-02, -3.9044e-01,  5.4182e-01, -2.5866e-02,\n",
      "         1.0885e+00, -8.5878e-04, -5.9547e-01,  3.4010e-02,  2.6642e-01,\n",
      "        -3.8703e-02,  1.0657e-01, -4.9555e-01, -5.3231e-01,  6.3363e-01,\n",
      "        -5.7651e-02,  2.0291e-01, -5.0221e-01, -5.2892e-02,  1.1667e-01,\n",
      "        -4.9508e-02, -2.4870e-01, -6.5140e-01,  5.1823e-01, -2.6808e-01,\n",
      "        -5.0060e-01,  3.7983e-01, -5.3156e-01,  9.9260e-02, -1.1823e+00,\n",
      "         6.0506e-01, -3.7264e-01,  1.2316e-01,  7.0522e-02, -8.0183e-01,\n",
      "        -1.2045e-01,  7.5645e-01, -2.9801e-02,  6.5062e-01,  1.7480e-01,\n",
      "         2.8192e-02,  1.5947e-01, -1.3799e-01,  1.9476e-02,  1.2660e-02,\n",
      "         7.5206e-02, -4.4271e-01, -6.3735e-01,  2.2280e-01, -2.1986e-02,\n",
      "         3.7086e-01, -1.5397e-01,  2.3873e-01,  3.3321e-02,  3.9460e-01,\n",
      "        -1.0243e-01,  8.6862e-02, -1.2873e-01, -3.5493e-01, -1.4918e-01,\n",
      "         4.2331e-01, -1.1168e-01,  2.5002e-01, -4.7903e-01, -4.4584e-01,\n",
      "        -2.7481e-01,  1.2055e-01, -3.9781e-02,  5.9323e-01, -4.3912e-01,\n",
      "         1.9961e-01, -3.8951e-01, -2.5906e-01, -5.4101e-01,  2.0357e-01,\n",
      "        -2.5242e-01, -6.1132e-01, -7.5558e-01, -4.1014e-01,  6.8315e-02,\n",
      "         3.1322e-01,  5.5731e-01, -1.3611e-01,  4.3715e-01,  1.0805e-01,\n",
      "         4.3742e-02,  4.0311e-03, -2.1020e-01, -1.2367e-01,  1.9426e-01,\n",
      "        -1.1605e-02, -2.5922e-02,  2.5153e-01,  8.2492e-01,  1.0029e-01,\n",
      "         8.7968e-02, -1.5309e-01, -1.6365e-01,  1.1243e-01, -1.7740e-01,\n",
      "         1.2188e-01, -4.8069e-01, -7.1944e-03, -2.1099e-01, -3.6203e-01,\n",
      "         3.5038e-01,  3.9478e-01,  3.6302e-01, -1.2158e-01, -4.4250e-01,\n",
      "        -2.8968e-01,  2.0885e-01,  9.5754e-02,  2.8025e-01,  2.0436e-01,\n",
      "        -1.8796e-02, -4.1509e-01, -1.0959e-01,  3.7367e-01, -9.2771e-01,\n",
      "        -3.9657e-01,  3.9886e-01,  8.9981e-02,  3.0061e-01,  1.7995e-02,\n",
      "         7.2989e-03, -7.5769e-01,  9.2444e-02, -2.8642e-01, -9.3045e-02,\n",
      "         1.8838e-01,  6.0713e-01, -1.0062e-01,  5.1134e-01,  9.8269e-02,\n",
      "         4.3307e-01, -2.4723e-01, -3.8685e-02, -6.7544e-02,  3.9557e-01,\n",
      "        -6.3562e-01, -5.5250e-01,  2.1547e-01, -7.4803e-02,  1.7348e-01,\n",
      "         3.1395e-01, -5.2666e-01, -3.7302e-01, -1.8875e-01,  2.5428e-02,\n",
      "         4.0721e-02,  5.1062e-01,  2.3214e-01,  5.6337e-02,  2.0855e-01,\n",
      "        -4.4534e-01,  4.2526e-02,  1.1783e-02, -4.3269e-02, -1.6046e-01,\n",
      "         2.4169e-01,  3.6557e-01, -4.5603e-01, -6.1394e-01, -2.6768e-01,\n",
      "        -5.7059e-02, -9.3486e-02, -6.5189e-02, -5.4782e-01,  1.1087e-01,\n",
      "        -5.9445e-01, -5.9166e-02,  2.7818e-01, -1.5030e-01,  3.8557e-01,\n",
      "         2.3130e-01, -4.6649e-01, -3.0007e-02, -2.3071e-01, -9.5542e-02,\n",
      "         9.3756e-01,  8.9414e-02, -3.3026e-01, -5.5838e-01, -1.0851e-03,\n",
      "        -2.3963e-01,  3.5212e-01,  8.8189e-01,  9.3898e-02, -6.3126e-01,\n",
      "         3.5599e-01, -1.2271e-01, -4.8862e-01,  3.8687e-02, -5.1888e-02,\n",
      "        -4.5496e-01, -5.7258e-01,  8.7214e-02, -5.2838e-01, -1.1846e-01,\n",
      "         2.5859e-04, -2.2482e-01,  2.2596e-01, -7.8633e-02, -6.7647e-01,\n",
      "         8.5829e-02,  3.9507e-01, -3.6724e-01,  4.9305e-01, -3.0907e-01,\n",
      "        -6.6837e-01, -1.6725e-01, -3.1166e-01,  1.2732e-01,  2.4709e-01,\n",
      "        -3.3846e-01, -4.5080e-01, -2.1635e-01,  3.0807e-01, -9.0332e-01,\n",
      "        -2.3821e-01,  3.8379e-01,  2.7409e-01, -7.0466e-02, -3.5311e-01,\n",
      "        -3.9885e-01, -2.3656e-01,  3.5814e-01, -4.4220e-01,  8.5579e-02,\n",
      "        -1.2308e-01, -6.8238e-01, -3.4567e-02,  9.3336e-02, -8.2288e-02,\n",
      "         1.2132e-01, -2.0082e-01,  1.9702e-01,  2.2051e-01,  9.0490e-01,\n",
      "        -4.2317e-01,  3.2775e-02, -5.5090e-02, -8.2334e-01,  1.7267e-01,\n",
      "        -5.6644e-01, -1.3561e-01,  3.7723e-01, -6.1688e-03, -4.3134e-01,\n",
      "         3.0632e-01, -2.6447e-01,  1.3296e-01, -1.0352e-01, -4.9806e-01,\n",
      "        -1.3339e-01,  5.6124e-01, -6.3295e-01,  4.0328e-01,  2.7466e-01,\n",
      "        -5.4317e-01, -4.7269e-01, -1.8382e-01,  1.4985e-01, -5.7755e-01,\n",
      "         1.7187e-01, -2.0889e-01,  1.0284e-01, -3.9327e-01,  4.6295e-01,\n",
      "        -2.2109e-01,  2.9038e-01,  1.0908e-01, -2.4271e-01,  3.0636e-02,\n",
      "         5.4965e-02, -1.7982e-01, -3.7332e-01, -5.7530e-01, -2.4376e-01,\n",
      "         3.1100e-01, -3.8400e-02, -3.0960e-01, -6.1627e-01, -1.1478e-01,\n",
      "         1.8683e-01,  5.8138e-01,  2.8950e-01, -5.7400e-01,  4.2625e-01,\n",
      "         4.3647e-01,  2.4638e-01,  2.3160e-01, -1.5781e-01, -6.0230e-01,\n",
      "         7.8799e-02, -1.8603e-01, -8.1260e-01,  5.2166e-03,  2.9175e-01,\n",
      "        -2.3685e-02, -1.9968e-01], device='cuda:0')), ('bf1.running_var', tensor([0.1110, 0.0790, 0.1364, 0.0442, 0.1418, 0.1471, 0.1329, 0.0641, 0.0565,\n",
      "        0.0598, 0.0547, 0.2106, 0.1453, 0.1455, 0.0597, 0.2122, 0.0431, 0.0955,\n",
      "        0.0774, 0.0436, 0.0769, 0.0876, 0.0404, 0.1110, 0.1281, 0.0787, 0.0576,\n",
      "        0.1067, 0.0915, 0.0880, 0.1033, 0.0580, 0.1007, 0.0835, 0.1064, 0.0850,\n",
      "        0.0370, 0.0542, 0.0787, 0.1078, 0.0575, 0.1243, 0.0578, 0.0543, 0.1157,\n",
      "        0.1386, 0.0365, 0.0722, 0.1046, 0.0656, 0.0553, 0.2134, 0.0944, 0.0885,\n",
      "        0.1738, 0.0591, 0.1639, 0.0344, 0.0908, 0.0712, 0.0977, 0.0710, 0.1500,\n",
      "        0.0671, 0.0593, 0.0752, 0.0793, 0.0874, 0.0763, 0.0428, 0.0678, 0.0828,\n",
      "        0.1468, 0.0638, 0.0516, 0.0930, 0.0655, 0.0967, 0.1177, 0.0950, 0.0778,\n",
      "        0.0760, 0.1069, 0.0994, 0.0629, 0.0515, 0.0444, 0.0527, 0.0458, 0.1261,\n",
      "        0.0883, 0.0479, 0.0787, 0.0809, 0.1035, 0.1450, 0.0727, 0.0837, 0.1124,\n",
      "        0.0482, 0.0598, 0.0499, 0.1391, 0.1054, 0.0645, 0.1507, 0.0351, 0.1180,\n",
      "        0.0897, 0.0407, 0.0829, 0.1348, 0.0733, 0.0854, 0.0855, 0.0226, 0.0692,\n",
      "        0.0339, 0.1096, 0.0521, 0.0429, 0.0817, 0.1260, 0.0466, 0.1119, 0.0462,\n",
      "        0.0962, 0.0575, 0.0201, 0.1052, 0.0779, 0.1212, 0.0832, 0.0911, 0.0846,\n",
      "        0.1720, 0.0507, 0.0843, 0.0794, 0.0495, 0.0828, 0.0866, 0.0910, 0.0727,\n",
      "        0.1689, 0.0681, 0.0608, 0.0640, 0.1256, 0.0578, 0.1299, 0.0443, 0.1002,\n",
      "        0.0426, 0.1570, 0.0442, 0.1154, 0.0765, 0.0349, 0.1575, 0.0445, 0.0865,\n",
      "        0.1345, 0.1553, 0.0706, 0.0646, 0.0616, 0.0287, 0.1185, 0.1168, 0.0352,\n",
      "        0.0677, 0.0495, 0.1061, 0.0495, 0.0653, 0.1377, 0.0869, 0.0524, 0.0942,\n",
      "        0.0914, 0.0606, 0.1031, 0.0617, 0.0984, 0.0330, 0.1333, 0.1135, 0.0642,\n",
      "        0.0455, 0.0427, 0.0769, 0.1290, 0.0974, 0.0457, 0.0552, 0.0801, 0.0744,\n",
      "        0.0510, 0.0932, 0.1601, 0.1451, 0.1067, 0.0957, 0.1624, 0.0730, 0.1431,\n",
      "        0.0852, 0.0817, 0.0751, 0.0730, 0.0515, 0.0575, 0.0439, 0.0551, 0.0996,\n",
      "        0.0772, 0.0517, 0.0469, 0.0624, 0.0655, 0.0504, 0.1119, 0.1057, 0.0370,\n",
      "        0.1483, 0.0594, 0.0586, 0.0411, 0.1139, 0.0868, 0.0255, 0.1959, 0.1205,\n",
      "        0.0651, 0.0519, 0.1117, 0.0448, 0.1065, 0.1335, 0.1592, 0.0284, 0.0881,\n",
      "        0.0517, 0.0386, 0.0251, 0.1136, 0.0539, 0.0946, 0.0225, 0.0688, 0.0557,\n",
      "        0.1346, 0.0786, 0.0511, 0.1232, 0.0469, 0.0888, 0.0972, 0.1213, 0.1070,\n",
      "        0.1607, 0.0645, 0.0947, 0.0673, 0.1003, 0.0234, 0.1057, 0.1037, 0.1165,\n",
      "        0.0602, 0.0856, 0.0737, 0.0893, 0.1416, 0.0699, 0.0550, 0.0549, 0.1140,\n",
      "        0.1196, 0.0811, 0.1702, 0.0721, 0.1250, 0.0621, 0.1056, 0.1193, 0.0855,\n",
      "        0.1445, 0.1092, 0.0685, 0.1368, 0.1059, 0.0553, 0.0546, 0.1247, 0.1262,\n",
      "        0.0346, 0.0949, 0.1182, 0.0506, 0.0277, 0.1035, 0.0552, 0.1064, 0.0725,\n",
      "        0.1084, 0.1000, 0.0775, 0.0901, 0.0535, 0.1406, 0.0603, 0.1484, 0.0914,\n",
      "        0.0431, 0.0845, 0.0715, 0.0684, 0.1239, 0.0638, 0.1216, 0.1110, 0.0516,\n",
      "        0.1012, 0.0763, 0.1524, 0.0875, 0.1385, 0.0979, 0.0950, 0.0451, 0.1601,\n",
      "        0.0661, 0.0541, 0.1318, 0.0216, 0.1481, 0.0774, 0.0996, 0.0671, 0.0706,\n",
      "        0.1218, 0.0626, 0.0678, 0.1104, 0.0951, 0.0915, 0.1570, 0.1192, 0.0820,\n",
      "        0.0693, 0.0471, 0.1118, 0.0965, 0.0506, 0.0585, 0.0412, 0.0323, 0.0623,\n",
      "        0.0787, 0.1527, 0.0570, 0.0881, 0.1013, 0.0465, 0.0510, 0.1154, 0.1082,\n",
      "        0.0969, 0.0560, 0.0758, 0.0761, 0.1253, 0.0797, 0.1086, 0.0577, 0.1006,\n",
      "        0.0682, 0.0433, 0.0789, 0.0839, 0.0631, 0.0361, 0.0777, 0.0479, 0.1787,\n",
      "        0.0382, 0.1335, 0.0709, 0.0603, 0.0432, 0.0459, 0.0720, 0.1165, 0.0564,\n",
      "        0.0400, 0.0830, 0.0582, 0.0625, 0.0444, 0.0840, 0.0908, 0.0564, 0.1126,\n",
      "        0.0426, 0.0533, 0.1192, 0.1085, 0.0807, 0.0449, 0.1177, 0.0883, 0.0622,\n",
      "        0.1462, 0.1248, 0.1371, 0.0889, 0.0553, 0.0988, 0.1075, 0.0482, 0.1264,\n",
      "        0.0861, 0.0808, 0.0578, 0.0808, 0.1433, 0.1218, 0.0972, 0.0301, 0.0703,\n",
      "        0.0347, 0.0920, 0.1601, 0.1444, 0.2053, 0.0343, 0.1666, 0.1206, 0.1035,\n",
      "        0.1511, 0.0545, 0.1095, 0.0488, 0.1023, 0.0737, 0.0364, 0.0984, 0.1258,\n",
      "        0.0851, 0.0466, 0.0722, 0.1696, 0.0541, 0.1878, 0.0601, 0.1077, 0.1545,\n",
      "        0.1192, 0.0977, 0.0430, 0.0597, 0.0488, 0.0876, 0.0998, 0.0797, 0.0932,\n",
      "        0.0653, 0.1330, 0.0340, 0.0885, 0.1178, 0.0544, 0.1280, 0.0287, 0.1108,\n",
      "        0.1196, 0.0377, 0.0461, 0.0714, 0.1180, 0.0292, 0.2093, 0.0574, 0.1147,\n",
      "        0.0829, 0.1044, 0.0634, 0.0619, 0.0519, 0.1440, 0.0426, 0.0657, 0.0578,\n",
      "        0.0739, 0.0782, 0.0676, 0.0522, 0.0617, 0.1328, 0.0558, 0.1406, 0.0982,\n",
      "        0.1459, 0.1228, 0.0646, 0.1095, 0.1421, 0.1505, 0.1524, 0.0839],\n",
      "       device='cuda:0')), ('bf1.num_batches_tracked', tensor(18750, device='cuda:0')), ('fc2.weight', tensor([[-0.0100, -0.0014,  0.0098,  ...,  0.0298,  0.0652,  0.0124],\n",
      "        [ 0.0509,  0.0347,  0.0381,  ..., -0.0680, -0.0179, -0.0133],\n",
      "        [-0.0258,  0.0606,  0.0029,  ...,  0.0346, -0.0452,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0607, -0.0283, -0.0322,  ...,  0.0766,  0.0323, -0.0055],\n",
      "        [ 0.0382, -0.0166, -0.0126,  ..., -0.0342,  0.0442,  0.0103],\n",
      "        [ 0.0005,  0.0385,  0.0381,  ...,  0.0194, -0.0191,  0.0307]],\n",
      "       device='cuda:0')), ('fc2.bias', tensor([ 0.0403,  0.0442,  0.0233,  0.0234,  0.0025,  0.0107, -0.0389, -0.0211,\n",
      "        -0.0224,  0.0227, -0.0042,  0.0188,  0.0397,  0.0301,  0.0418,  0.0421,\n",
      "        -0.0066, -0.0125, -0.0227,  0.0028,  0.0051,  0.0269, -0.0306,  0.0166,\n",
      "         0.0096,  0.0437, -0.0231, -0.0106, -0.0250,  0.0127, -0.0010,  0.0390,\n",
      "         0.0019,  0.0440, -0.0037, -0.0237,  0.0088,  0.0430, -0.0069, -0.0397,\n",
      "        -0.0418,  0.0337, -0.0171, -0.0047,  0.0205, -0.0229, -0.0233, -0.0165,\n",
      "         0.0157, -0.0425,  0.0194, -0.0082, -0.0373, -0.0381, -0.0325, -0.0173,\n",
      "        -0.0267, -0.0387, -0.0092,  0.0035,  0.0036,  0.0432,  0.0185, -0.0255,\n",
      "        -0.0397, -0.0012,  0.0008,  0.0285, -0.0418,  0.0040, -0.0061,  0.0045,\n",
      "        -0.0127,  0.0159,  0.0037, -0.0167, -0.0110,  0.0231, -0.0092, -0.0187,\n",
      "         0.0218,  0.0118,  0.0051,  0.0198,  0.0350, -0.0300, -0.0242, -0.0408,\n",
      "         0.0151,  0.0027,  0.0081, -0.0287, -0.0337,  0.0221,  0.0266,  0.0340,\n",
      "        -0.0352, -0.0310,  0.0245,  0.0288, -0.0338,  0.0163,  0.0391,  0.0181,\n",
      "         0.0327,  0.0164, -0.0280,  0.0245,  0.0428, -0.0231, -0.0073, -0.0285,\n",
      "         0.0298, -0.0434, -0.0152,  0.0432,  0.0076, -0.0034, -0.0247, -0.0296,\n",
      "         0.0048,  0.0068,  0.0353, -0.0095,  0.0194,  0.0392, -0.0016, -0.0288,\n",
      "        -0.0431,  0.0066,  0.0258,  0.0356,  0.0289,  0.0328,  0.0147,  0.0118,\n",
      "         0.0306,  0.0186, -0.0255,  0.0250, -0.0432, -0.0101,  0.0170,  0.0362,\n",
      "        -0.0370, -0.0162, -0.0394,  0.0287, -0.0128,  0.0033,  0.0355,  0.0389,\n",
      "        -0.0198, -0.0130, -0.0139,  0.0267, -0.0212, -0.0411, -0.0024,  0.0425,\n",
      "        -0.0324,  0.0198,  0.0348, -0.0212, -0.0290,  0.0290,  0.0043,  0.0392,\n",
      "        -0.0358, -0.0404,  0.0382, -0.0181, -0.0107,  0.0288,  0.0281, -0.0265,\n",
      "        -0.0140,  0.0417,  0.0391,  0.0350, -0.0207, -0.0357, -0.0324,  0.0025,\n",
      "         0.0029,  0.0406, -0.0158, -0.0230, -0.0222,  0.0014, -0.0150,  0.0308,\n",
      "        -0.0181, -0.0076,  0.0009, -0.0282, -0.0241, -0.0355, -0.0262,  0.0409,\n",
      "        -0.0269, -0.0398, -0.0282, -0.0392, -0.0349,  0.0148, -0.0290,  0.0205,\n",
      "        -0.0315,  0.0227, -0.0219,  0.0021, -0.0347,  0.0142,  0.0435, -0.0336,\n",
      "        -0.0362, -0.0016, -0.0100,  0.0058, -0.0190, -0.0221,  0.0082,  0.0279,\n",
      "        -0.0374,  0.0276, -0.0222, -0.0265, -0.0214,  0.0223, -0.0055,  0.0430,\n",
      "         0.0222,  0.0274, -0.0249, -0.0419, -0.0009,  0.0057, -0.0293, -0.0020,\n",
      "         0.0413, -0.0216, -0.0354, -0.0381, -0.0309,  0.0154,  0.0257,  0.0272,\n",
      "        -0.0265,  0.0307,  0.0110,  0.0372,  0.0293, -0.0436, -0.0093, -0.0378],\n",
      "       device='cuda:0')), ('bf2.weight', tensor([ 1.0566e+00,  1.0376e+00,  8.3313e-01,  4.7183e-01,  5.7695e-01,\n",
      "         7.5341e-01,  3.9467e-01,  1.0137e+00,  7.0131e-01,  3.2852e-01,\n",
      "         8.2635e-01,  9.7334e-01,  8.5244e-01,  5.4988e-01,  4.7842e-01,\n",
      "         2.0282e-01,  7.9008e-01,  1.0079e+00,  9.8387e-01,  3.0861e-01,\n",
      "         9.9082e-01,  9.3256e-01,  1.7694e-02,  1.9592e-01,  9.1289e-01,\n",
      "         5.1637e-01,  3.4690e-01,  9.9215e-01,  5.7480e-01,  3.8665e-01,\n",
      "         3.6601e-01,  1.4990e-01,  5.4340e-01,  3.0590e-01,  7.4008e-01,\n",
      "         7.3851e-01,  6.4666e-04,  6.4349e-01,  1.0305e+00,  4.3259e-01,\n",
      "         1.7404e-01,  5.7876e-01,  8.1924e-01,  5.8761e-01,  1.0202e+00,\n",
      "         7.4055e-01,  9.5160e-01,  3.8670e-01,  6.7153e-01,  8.5424e-01,\n",
      "         9.5773e-01,  1.0278e+00,  1.7954e-01,  6.4132e-01,  7.6540e-01,\n",
      "         2.5827e-01,  6.6553e-01,  1.0716e+00,  2.9294e-01,  8.4733e-01,\n",
      "         2.3298e-01,  9.0524e-01,  7.5466e-01,  9.2428e-01,  6.3164e-01,\n",
      "         4.8924e-01,  1.0010e+00,  3.6498e-01,  9.7500e-01,  2.3757e-01,\n",
      "         1.0254e+00,  6.1644e-01,  7.0819e-01,  1.0794e+00,  7.6162e-01,\n",
      "         6.7401e-02,  4.9217e-01,  9.1779e-01,  7.0096e-01,  2.4764e-01,\n",
      "         1.2610e-04,  3.9150e-01,  1.0510e+00,  6.7167e-01,  3.8719e-01,\n",
      "         9.4991e-01,  4.0621e-01,  4.9860e-01,  9.9123e-01,  4.7317e-01,\n",
      "         8.6740e-01,  7.6851e-02,  6.2312e-01,  2.2490e-01,  1.0826e-01,\n",
      "         8.2008e-01,  5.8138e-02,  8.0898e-01,  5.9144e-01,  8.0218e-01,\n",
      "         7.5287e-01,  3.7508e-01,  2.4654e-01,  2.7186e-01,  3.3381e-01,\n",
      "         1.1463e-01,  6.5738e-01,  8.0047e-01,  3.9181e-01,  4.6567e-01,\n",
      "         1.0277e+00,  7.6198e-01,  2.8416e-02,  5.6556e-01,  7.5252e-01,\n",
      "         1.0493e+00,  8.3193e-01,  5.7445e-01,  9.0891e-01,  4.5009e-01,\n",
      "         9.7366e-01,  1.4110e-01,  4.8095e-01,  5.5885e-01,  7.8238e-01,\n",
      "         2.9329e-01,  1.7640e-01,  8.8137e-01,  9.5302e-01,  7.0261e-01,\n",
      "         9.7879e-04,  1.9857e-01,  2.8706e-01,  8.6796e-01,  4.5544e-01,\n",
      "         4.2418e-01,  5.1034e-02,  5.6710e-01,  6.9376e-01,  3.8261e-01,\n",
      "         5.4682e-01,  7.9749e-01,  9.2507e-01,  1.0310e+00,  4.6083e-01,\n",
      "         1.0278e+00,  7.7429e-01,  7.3760e-01,  8.2240e-01,  7.5036e-01,\n",
      "         1.0178e+00,  2.9745e-01,  7.1912e-01,  1.2895e-01,  6.9369e-01,\n",
      "         4.6533e-02,  1.0182e+00,  7.5154e-01,  9.6655e-01,  4.7476e-01,\n",
      "         9.2568e-01,  4.8362e-01,  4.7487e-01,  8.5218e-01,  2.5115e-01,\n",
      "         6.6514e-01,  4.8876e-01,  4.4257e-01,  1.0060e+00,  7.4559e-01,\n",
      "         5.4887e-01,  4.4690e-01,  9.8524e-01,  8.2196e-01,  5.4224e-01,\n",
      "         6.5997e-01,  9.1186e-01,  7.5239e-01,  3.1672e-01,  6.2939e-01,\n",
      "         8.9187e-01,  7.4647e-01,  1.3452e-02,  9.3368e-01,  9.1586e-01,\n",
      "         6.1679e-01,  9.7979e-01,  3.4371e-01,  7.2730e-01,  6.8413e-01,\n",
      "         4.4073e-01,  2.6179e-01,  6.6575e-01,  5.5961e-01,  8.1691e-01,\n",
      "         6.3223e-01,  4.9035e-01,  9.3922e-01,  3.6349e-01,  2.9491e-01,\n",
      "         1.0594e+00,  5.0662e-01,  1.6083e-01,  9.7380e-01,  1.0266e+00,\n",
      "         8.3770e-01,  5.0210e-01,  5.9143e-01,  8.4549e-01,  6.0773e-01,\n",
      "         3.2597e-01,  1.0411e+00,  2.5090e-01,  8.3499e-01, -1.9449e-02,\n",
      "         3.0733e-01,  4.8606e-01,  4.9084e-01,  6.0403e-01,  7.0375e-01,\n",
      "         7.5535e-01,  4.8469e-01,  6.7321e-01,  2.8372e-01,  1.3582e-01,\n",
      "         4.5049e-01,  7.1755e-01,  3.9945e-01,  9.4306e-01,  3.8963e-01,\n",
      "         3.5064e-01,  1.0671e+00,  2.3789e-01,  6.7220e-01,  1.7488e-01,\n",
      "         8.6828e-01,  1.0176e+00,  4.7405e-01,  7.6715e-01,  2.7201e-01,\n",
      "         1.9401e-01,  8.0907e-01,  9.8073e-01,  4.1101e-02,  9.3158e-01,\n",
      "         6.1356e-01,  7.2833e-01,  9.0717e-01,  5.0498e-01,  7.4459e-01,\n",
      "         9.5100e-01,  1.0077e+00,  4.4408e-01,  8.3064e-01,  9.0811e-01,\n",
      "         4.5244e-03], device='cuda:0')), ('bf2.bias', tensor([ 0.1395,  0.1574,  0.1720,  0.1104,  0.1646,  0.1465,  0.1032,  0.1547,\n",
      "         0.1582,  0.0875,  0.1536,  0.1407,  0.1962,  0.1479,  0.1729,  0.0821,\n",
      "         0.1465,  0.1172,  0.1413,  0.1216,  0.1238,  0.1560, -0.0185,  0.0769,\n",
      "         0.1284,  0.1472,  0.1263,  0.1596,  0.1358,  0.1121,  0.1245,  0.0368,\n",
      "         0.1443,  0.0818,  0.1163,  0.1632, -0.0014,  0.1314,  0.1289,  0.0982,\n",
      "         0.0753,  0.1133,  0.1685,  0.1583,  0.1452,  0.1726,  0.1476,  0.0931,\n",
      "         0.1344,  0.1690,  0.1049,  0.1447,  0.0551,  0.1456,  0.1438,  0.0814,\n",
      "         0.1532,  0.1578,  0.0604,  0.1680,  0.0781,  0.1228,  0.1451,  0.1558,\n",
      "         0.1725,  0.1186,  0.1261,  0.1122,  0.1422,  0.0678,  0.1332,  0.1298,\n",
      "         0.1262,  0.1348,  0.1448, -0.0106,  0.1330,  0.1675,  0.1759,  0.1062,\n",
      "        -0.0009,  0.1163,  0.1208,  0.1443,  0.1288,  0.1431,  0.1652,  0.1479,\n",
      "         0.1153,  0.1400,  0.1323,  0.0113,  0.1807,  0.0519,  0.0416,  0.1358,\n",
      "         0.0243,  0.1322,  0.1894,  0.1293,  0.1399,  0.1388,  0.0920,  0.0678,\n",
      "         0.1184,  0.0353,  0.1794,  0.1371,  0.1128,  0.1294,  0.1472,  0.1740,\n",
      "         0.0136,  0.1566,  0.1330,  0.1512,  0.1807,  0.1484,  0.1873,  0.1698,\n",
      "         0.1423,  0.0208,  0.1394,  0.1253,  0.1432,  0.1271,  0.0661,  0.1665,\n",
      "         0.1229,  0.1600, -0.0021,  0.0911,  0.1104,  0.1343,  0.1443,  0.1453,\n",
      "         0.0331,  0.1450,  0.1552,  0.1307,  0.1125,  0.1215,  0.1477,  0.1429,\n",
      "         0.1490,  0.1226,  0.1655,  0.1861,  0.1662,  0.1647,  0.1346,  0.0793,\n",
      "         0.1608,  0.0543,  0.1482,  0.0383,  0.1258,  0.1226,  0.1346,  0.1172,\n",
      "         0.1263,  0.1108,  0.1475,  0.1374,  0.1110,  0.1815,  0.1511,  0.1342,\n",
      "         0.1254,  0.1153,  0.1620,  0.1616,  0.1429,  0.1346,  0.1509,  0.1587,\n",
      "         0.1688,  0.1515,  0.0589,  0.1198,  0.1701,  0.1567,  0.0050,  0.1624,\n",
      "         0.1465,  0.1657,  0.1434,  0.1009,  0.1992,  0.1331,  0.1254,  0.1026,\n",
      "         0.1516,  0.1163,  0.1764,  0.1478,  0.1017,  0.1409,  0.1077,  0.0861,\n",
      "         0.1519,  0.1213,  0.0679,  0.1326,  0.1515,  0.1551,  0.1283,  0.1383,\n",
      "         0.1566,  0.1715,  0.1208,  0.1469,  0.0881,  0.1452,  0.0107,  0.0573,\n",
      "         0.1460,  0.0929,  0.1759,  0.1252,  0.1489,  0.1342,  0.1640,  0.0716,\n",
      "         0.0311,  0.1502,  0.1437,  0.1099,  0.1553,  0.1096,  0.1131,  0.1644,\n",
      "         0.0599,  0.1599,  0.0358,  0.1636,  0.1678,  0.1721,  0.1595,  0.0810,\n",
      "         0.0732,  0.1720,  0.1490,  0.0070,  0.1281,  0.1433,  0.1301,  0.1230,\n",
      "         0.1600,  0.1305,  0.1531,  0.1924,  0.0938,  0.1669,  0.1529, -0.0079],\n",
      "       device='cuda:0')), ('bf2.running_mean', tensor([ 0.4901,  0.6069,  0.1877,  0.2204,  0.3010,  0.8532, -0.1238,  0.5795,\n",
      "         0.7554,  0.2456,  0.2888,  0.4761,  0.4953,  0.4330,  0.2784,  0.0237,\n",
      "         0.7976,  0.6041,  0.7438,  0.2272,  0.7126,  0.4000, -0.0238,  0.1050,\n",
      "         1.0175,  0.3235,  0.0944,  0.5541,  0.5844, -0.0446,  0.3011,  0.0789,\n",
      "         0.3603,  0.0944,  0.5902,  0.3187,  0.0763,  0.5772,  0.9254,  0.2739,\n",
      "         0.0469,  0.4359,  0.3247,  0.2856,  0.7057,  0.3094,  0.6442,  0.3412,\n",
      "         0.5374,  0.2700,  0.9024,  0.6352,  0.0558,  0.4345,  0.7180,  0.0417,\n",
      "         0.1776,  0.0271,  0.1118,  0.1871,  0.0745,  0.8602,  0.5651,  0.3944,\n",
      "         0.8422,  0.3447,  0.6762,  0.2466,  0.1968,  0.1426,  0.9171,  0.4219,\n",
      "         0.4566,  0.7737,  0.5457,  0.1823,  0.4373,  0.5536,  0.7276, -0.0997,\n",
      "         0.2681,  0.3328,  0.4930,  0.4270,  0.0651,  0.4591,  0.0058,  0.5490,\n",
      "         0.6252,  0.2255,  0.7201, -0.0699,  0.2838,  0.2733,  0.1764,  0.7192,\n",
      "         0.0377,  0.1704,  0.4664,  0.8006,  0.2510,  0.0731, -0.0748,  0.1409,\n",
      "        -0.0446, -0.0011,  0.1465,  1.0964, -0.0907,  0.2512,  0.4694,  0.7043,\n",
      "         0.0796,  0.0957,  0.4959,  0.4610,  0.0295,  0.4758,  0.3598,  0.3986,\n",
      "         0.3104,  0.0593,  0.3810,  0.1393,  0.5613, -0.0986,  0.1578,  0.4618,\n",
      "         0.2770,  0.8763,  0.1774,  0.2116,  0.2272,  0.7335,  0.1706,  0.3094,\n",
      "         0.0054,  0.3761,  0.3053,  0.2916,  0.2810,  0.9443,  0.5074,  0.5607,\n",
      "         0.1654,  0.3501,  0.4683,  0.6533,  0.3867,  0.4390,  0.6170,  0.3226,\n",
      "         0.4065,  0.2880,  0.5922, -0.0702,  0.8424,  0.6130,  0.6681,  0.4010,\n",
      "         0.6293,  0.1586,  0.4272,  0.7247, -0.0121,  0.4658,  0.2722,  0.1304,\n",
      "         0.3558,  0.5893,  0.2787,  0.3376,  0.3886,  0.3421,  0.1924,  0.3764,\n",
      "         0.1012,  0.6291,  0.3344,  0.4634,  0.4288,  0.5407, -0.1750,  0.7031,\n",
      "         0.4449,  0.6211,  0.7767,  0.2781,  0.3209,  0.8921,  0.4289,  0.1513,\n",
      "         0.2176, -0.0477,  0.3931,  0.3509,  0.5383,  0.8468, -0.0283,  0.3585,\n",
      "         0.4008,  0.5218, -0.1752,  0.7571,  0.3600,  0.4504, -0.1444,  0.7658,\n",
      "         0.5918,  0.0734,  0.2083,  1.0288,  0.1325,  0.5486,  0.1738, -0.1285,\n",
      "         0.3275,  0.4431,  0.4798,  0.7801,  0.1873,  0.3614,  0.5201,  0.0905,\n",
      "        -0.1754,  0.1366,  0.1180,  0.4416,  0.5170,  0.4032,  0.4159,  0.4510,\n",
      "         0.3857,  0.3673,  0.0694,  0.3037,  0.5956,  0.4229,  0.4802, -0.1535,\n",
      "         0.1639,  0.4763,  0.3265,  0.3842,  0.4440,  0.5908,  0.3801,  0.4477,\n",
      "         0.3270,  0.9020,  0.4901,  0.5981,  0.5190,  0.1458,  0.1812,  0.0542],\n",
      "       device='cuda:0')), ('bf2.running_var', tensor([0.6338, 0.6167, 0.4859, 0.2779, 0.4779, 0.5375, 0.2479, 0.5992, 0.5227,\n",
      "        0.1406, 0.4547, 0.5598, 0.5337, 0.4321, 0.2602, 0.2095, 0.4970, 0.5706,\n",
      "        0.6330, 0.2352, 0.8852, 0.6670, 0.1594, 0.1154, 0.4246, 0.4102, 0.1915,\n",
      "        0.4896, 0.3356, 0.2342, 0.2429, 0.1323, 0.2678, 0.1753, 0.5566, 0.5193,\n",
      "        0.1269, 0.3827, 0.5771, 0.2468, 0.1855, 0.3447, 0.6658, 0.2563, 0.5910,\n",
      "        0.4365, 0.6524, 0.2072, 0.3784, 0.5721, 0.5233, 0.5179, 0.1682, 0.4191,\n",
      "        0.3363, 0.1859, 0.4191, 0.4666, 0.2138, 0.5327, 0.1774, 0.8771, 0.4987,\n",
      "        0.4521, 0.4601, 0.2581, 0.5879, 0.2381, 0.5180, 0.1471, 0.6313, 0.4191,\n",
      "        0.4122, 0.4894, 0.4332, 0.1076, 0.3294, 0.4087, 0.5902, 0.1571, 0.0823,\n",
      "        0.3164, 0.6001, 0.4641, 0.1655, 0.4765, 0.2666, 0.3435, 0.5855, 0.2230,\n",
      "        0.3866, 0.0921, 0.3702, 0.1477, 0.0829, 0.4696, 0.1234, 0.5448, 0.2610,\n",
      "        0.5360, 0.4456, 0.2664, 0.1611, 0.1221, 0.2425, 0.1246, 0.4130, 0.3615,\n",
      "        0.2143, 0.2582, 0.4935, 0.4261, 0.0928, 0.2229, 0.3533, 0.7679, 0.5112,\n",
      "        0.3662, 0.7792, 0.2635, 0.6206, 0.0931, 0.2417, 0.2325, 0.4117, 0.1852,\n",
      "        0.1656, 0.6144, 0.6083, 0.5970, 0.1322, 0.2072, 0.1903, 0.4268, 0.2172,\n",
      "        0.3057, 0.0766, 0.3521, 0.3815, 0.1923, 0.2265, 0.2949, 0.6589, 0.7060,\n",
      "        0.3241, 0.5585, 0.4621, 0.5913, 0.5929, 0.4474, 0.4814, 0.1071, 0.5169,\n",
      "        0.1507, 0.4252, 0.1000, 0.4854, 0.3942, 0.5287, 0.2979, 0.4738, 0.2635,\n",
      "        0.2734, 0.4534, 0.2693, 0.3885, 0.2259, 0.2221, 0.4116, 0.4782, 0.3838,\n",
      "        0.2117, 0.5190, 0.4595, 0.3046, 0.2720, 0.4193, 0.4453, 0.1520, 0.3751,\n",
      "        0.4869, 0.4997, 0.1322, 0.7076, 0.4838, 0.3941, 0.5802, 0.2398, 0.5173,\n",
      "        0.7754, 0.2917, 0.2531, 0.4503, 0.2789, 0.4180, 0.3023, 0.2997, 0.5065,\n",
      "        0.2015, 0.1960, 0.8899, 0.3659, 0.1541, 0.5184, 0.4957, 0.4665, 0.2850,\n",
      "        0.4739, 0.4872, 0.2994, 0.2339, 0.5352, 0.2622, 0.3667, 0.0837, 0.1441,\n",
      "        0.2119, 0.2444, 0.3635, 0.4175, 0.5090, 0.2748, 0.3437, 0.2060, 0.1385,\n",
      "        0.3814, 0.4983, 0.1879, 0.4746, 0.2147, 0.2371, 0.5381, 0.1195, 0.4917,\n",
      "        0.1711, 0.4738, 0.4251, 0.3503, 0.5716, 0.1665, 0.2350, 0.4658, 0.7105,\n",
      "        0.0811, 1.0409, 0.4097, 0.4740, 0.5988, 0.2715, 0.4726, 0.5941, 0.5165,\n",
      "        0.2149, 0.4099, 0.5664, 0.0725], device='cuda:0')), ('bf2.num_batches_tracked', tensor(18750, device='cuda:0')), ('fc3.weight', tensor([[ 0.1713, -0.2436, -0.1403,  ..., -0.2091,  0.1353,  0.0509],\n",
      "        [-0.2611,  0.1715, -0.0406,  ...,  0.0655, -0.1365, -0.0098],\n",
      "        [ 0.1318,  0.1448,  0.0908,  ..., -0.1535, -0.2157,  0.0033],\n",
      "        ...,\n",
      "        [-0.1208,  0.0648,  0.1623,  ...,  0.1356, -0.2433, -0.0050],\n",
      "        [-0.0493,  0.1004, -0.2242,  ..., -0.0200,  0.1077,  0.0324],\n",
      "        [ 0.1166, -0.0882,  0.1599,  ...,  0.1287,  0.1087,  0.0524]],\n",
      "       device='cuda:0')), ('fc3.bias', tensor([-9.0609e-05, -5.3343e-02,  4.4531e-02,  1.3080e-02, -5.5188e-02,\n",
      "        -5.1140e-02, -2.0954e-02,  1.5644e-02, -2.4250e-03,  3.4124e-02],\n",
      "       device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n",
      "torch.Size([16, 10])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images_eval, labels_eval in testloader:\n",
    "        images_eval, labels_eval = images_eval.to(device), labels_eval.to(device)\n",
    "        outputs_eval = model(images_eval)\n",
    "        print(outputs_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a2ef1e232d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Maybe you want to modify the last fc layer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 2. Load part of parameters of a pretrained model as init for self-defined similar-architecture model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Directly Load a Pre-trained Model\n",
    "# https://github.com/pytorch/vision/tree/master/torchvision/models\n",
    "import torchvision.models as models\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "# or\n",
    "model = models.resnet50(pretrained=False)\n",
    "\n",
    "# Maybe you want to modify the last fc layer?\n",
    "resnet.fc = nn.Linear(2048, 2) \n",
    "\n",
    "# 2. Load part of parameters of a pretrained model as init for self-defined similar-architecture model.\n",
    "# resnet50 is a pretrain model \n",
    "# self_defined indicates model you just define.\n",
    "resnet50 = models.resnet50(pretrained=True) \n",
    "self_defined = Net(...) \n",
    "\n",
    "pretrained_dict = resnet50.state_dict() \n",
    "model_dict = self_defined.state_dict() \n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict} \n",
    "\n",
    "# update & load\n",
    "model_dict.update(pretrained_dict) \n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "# 3. Save & Load routines.\n",
    "# routine 1\n",
    "# torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# model = ModelClass(*args, **kwargs)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# routine 2\n",
    "# torch.save(model, PATH)\n",
    "# model = torch.load(PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
