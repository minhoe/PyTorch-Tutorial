{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of GPUs available :  4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']=\"0,1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(' # of GPUs available : ', torch.cuda.device_count())\n",
    "\n",
    "log_interval = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR  = './results/'\n",
    "\n",
    "# Input info\n",
    "INPUT_DIR  = '../Data/'\n",
    "INPUT_DIR  = '/input/AIRLab/PaintInsReport/Output'\n",
    "INPUT_FILE = 'insp_data_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Dataset size :  torch.Size([60000, 28, 28])\n",
      " Training Label size   :  torch.Size([60000])\n",
      " Testing Dataset size :  torch.Size([10000, 28, 28])\n",
      " Testing Label size   :  torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(' Training Dataset size : ', trainloader.dataset.train_data.shape)\n",
    "print(' Training Label size   : ', trainloader.dataset.train_labels.shape)\n",
    "\n",
    "print(' Testing Dataset size : ', testloader.dataset.test_data.shape)\n",
    "print(' Testing Label size   : ', testloader.dataset.test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7     1     3     6     8     4     4     3     7     7     3     8     9     5     8     6\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j].item() for j in range(16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "        \n",
    "#         # Layer 1\n",
    "#         self.conv1 = nn.Conv2d(1, 64, 3) # 28x28 -> 26x26\n",
    "#         self.b1    = nn.BatchNorm2d(64)\n",
    "#         self.pool  = nn.MaxPool2d(2, 2)  # 26x26 -> 13x13\n",
    "        \n",
    "#         # Layer 2\n",
    "#         self.conv2 = nn.Conv2d(64, 128, 3)  # 13x13 -> 11x11\n",
    "#         self.b2    = nn.BatchNorm2d(128)\n",
    "#         #self.pool                          # 11x11 -> 5x5\n",
    "        \n",
    "#         # Layer 3\n",
    "#         self.conv3 = nn.Conv2d(128, 128, 3) # 5x5 -> 3x3\n",
    "#         self.b3    = nn.BatchNorm2d(128)\n",
    "#         #self.pool                          # 3x3 -> 1x1 \n",
    "        \n",
    "#         # FC Layers\n",
    "#         self.fc1 = nn.Linear(128 * 1 * 1, 512)\n",
    "#         self.bf1 = nn.BatchNorm1d(512)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.bf2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "#         self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Layer 1\n",
    "#         x = self.pool(F.relu(self.b1(self.conv1(x))))\n",
    "#         #print(self.num_flat_features(x))\n",
    "        \n",
    "#         # Layer 2\n",
    "#         x = self.pool(F.relu(self.b2(self.conv2(x))))\n",
    "        \n",
    "#         # Layer 3\n",
    "#         x = self.pool(F.relu(self.b3(self.conv3(x))))\n",
    "        \n",
    "#         # Flatten tensors\n",
    "#         x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "#         # FC Layer 1\n",
    "#         x = F.relu(self.bf1(self.fc1(x)))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "        \n",
    "#         # FC Layer 2\n",
    "#         x = F.relu(self.bf2(self.fc2(x)))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "        \n",
    "#         # FC Layer 3\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "#     def num_flat_features(self, x):\n",
    "#         size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "#         num_features = 1\n",
    "#         for s in size:\n",
    "#             num_features *= s\n",
    "#         return num_features\n",
    "\n",
    "# net = Net()\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#     net = nn.DataParallel(net)\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n",
      "DataParallel(\n",
      "  (module): Net(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (b1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (b2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (b3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (bf1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (bf2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3) # 28x28 -> 26x26  /40x40 -> 38x38 / 60x60 -> 58x58 / 80x80 -> 78x78 / 100x100 -> 98x98\n",
    "        self.b1    = nn.BatchNorm2d(16)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)  # 26x26 -> 13x13  /38x38 -> 19x19 / 58x58 -> 29x29 / 78x78 -> 39x39 / 98x98 -> 49x49\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)  # 13x13 -> 11x11 /19x19 -> 17x17 / 29x29 -> 27x27 / 39x39 -> 37x37 / 49x49 -> 47x47\n",
    "        self.b2    = nn.BatchNorm2d(32)\n",
    "        #self.pool                          # 11x11 -> 5x5  /17x17 -> 8x8 / 27x27 -> 13x13 / 37x37 -> 18x18 / 47x47 -> 23x23\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3) # 5x5 -> 3x3  / 8x8 -> 6x6 / 13x13 -> 11x11 / 18x18 -> 16x16 / 23x23 -> 21x21\n",
    "        self.b3    = nn.BatchNorm2d(64)\n",
    "        #self.pool                          # 3x3 -> 1x1  /6x6 -> 3x3 / 11x11 -> 5x5 / 16x16 -> 8x8 / 21x21 -> 10x10\n",
    "        \n",
    "        # FC Layers\n",
    "        self.fc1 = nn.Linear(64 * 1 * 1, 256)\n",
    "        self.bf1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bf2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        # Layer 1\n",
    "        x = self.pool(F.relu(self.b1(self.conv1(x))))\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.pool(F.relu(self.b2(self.conv2(x))))\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.pool(F.relu(self.b3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten tensors\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        \n",
    "        # FC Layer 1\n",
    "        x = F.relu(self.bf1(self.fc1(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # FC Layer 2\n",
    "        x = F.relu(self.bf2(self.fc2(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # FC Layer 3\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # For Multi-gpu processing\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        net.train(True) # Set to Train mode\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate Training Accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()    \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % log_interval == 0:    # print every 200 mini-batches\n",
    "            print('Train Epoch : %2d [%6d, %6d] loss: %.3f TrnAcc: %.3f' %\n",
    "                  (epoch, total, len(trainloader.dataset), running_loss / 2000, correct / total))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    # Calculate Validation Accuracy\n",
    "    total_eval = 0\n",
    "    correct_eval = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images_eval, labels_eval in testloader:\n",
    "            images_eval, labels_eval = images_eval.to(device), labels_eval.to(device)\n",
    "            outputs_eval = net(images_eval)\n",
    "            _, predicted_eval = torch.max(outputs_eval.data, 1)\n",
    "            total_eval += labels_eval.size(0)\n",
    "            correct_eval += (predicted_eval == labels_eval).sum().item() \n",
    "    val_acc = correct_eval / total_eval\n",
    "    print('Test | Size : %6d  | ValAcc: %.3f\\n' %\n",
    "          (len(testloader.dataset), val_acc))\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | Size :  10000  | ValAcc: 0.098\n",
      "\n",
      "Train Epoch :  0 [    16,  60000] loss: 0.001 TrnAcc: 0.125\n",
      "Train Epoch :  0 [  8016,  60000] loss: 0.485 TrnAcc: 0.355\n",
      "Train Epoch :  0 [ 16016,  60000] loss: 0.350 TrnAcc: 0.467\n",
      "Train Epoch :  0 [ 24016,  60000] loss: 0.274 TrnAcc: 0.538\n",
      "Train Epoch :  0 [ 32016,  60000] loss: 0.235 TrnAcc: 0.586\n",
      "Train Epoch :  0 [ 40016,  60000] loss: 0.212 TrnAcc: 0.620\n",
      "Train Epoch :  0 [ 48016,  60000] loss: 0.185 TrnAcc: 0.648\n",
      "Train Epoch :  0 [ 56016,  60000] loss: 0.170 TrnAcc: 0.670\n",
      "Test | Size :  10000  | ValAcc: 0.955\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [0] \u001b[0m\n",
      "Train Epoch :  1 [    16,  60000] loss: 0.000 TrnAcc: 0.688\n",
      "Train Epoch :  1 [  8016,  60000] loss: 0.154 TrnAcc: 0.830\n",
      "Train Epoch :  1 [ 16016,  60000] loss: 0.144 TrnAcc: 0.834\n",
      "Train Epoch :  1 [ 24016,  60000] loss: 0.141 TrnAcc: 0.837\n",
      "Train Epoch :  1 [ 32016,  60000] loss: 0.142 TrnAcc: 0.839\n",
      "Train Epoch :  1 [ 40016,  60000] loss: 0.133 TrnAcc: 0.841\n",
      "Train Epoch :  1 [ 48016,  60000] loss: 0.129 TrnAcc: 0.844\n",
      "Train Epoch :  1 [ 56016,  60000] loss: 0.128 TrnAcc: 0.846\n",
      "Test | Size :  10000  | ValAcc: 0.972\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [1] \u001b[0m\n",
      "Train Epoch :  2 [    16,  60000] loss: 0.000 TrnAcc: 0.875\n",
      "Train Epoch :  2 [  8016,  60000] loss: 0.116 TrnAcc: 0.869\n",
      "Train Epoch :  2 [ 16016,  60000] loss: 0.115 TrnAcc: 0.871\n",
      "Train Epoch :  2 [ 24016,  60000] loss: 0.113 TrnAcc: 0.873\n",
      "Train Epoch :  2 [ 32016,  60000] loss: 0.108 TrnAcc: 0.875\n",
      "Train Epoch :  2 [ 40016,  60000] loss: 0.105 TrnAcc: 0.876\n",
      "Train Epoch :  2 [ 48016,  60000] loss: 0.108 TrnAcc: 0.877\n",
      "Train Epoch :  2 [ 56016,  60000] loss: 0.100 TrnAcc: 0.879\n",
      "Test | Size :  10000  | ValAcc: 0.976\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [2] \u001b[0m\n",
      "Train Epoch :  3 [    16,  60000] loss: 0.000 TrnAcc: 0.938\n",
      "Train Epoch :  3 [  8016,  60000] loss: 0.098 TrnAcc: 0.890\n",
      "Train Epoch :  3 [ 16016,  60000] loss: 0.096 TrnAcc: 0.893\n",
      "Train Epoch :  3 [ 24016,  60000] loss: 0.098 TrnAcc: 0.893\n",
      "Train Epoch :  3 [ 32016,  60000] loss: 0.092 TrnAcc: 0.895\n",
      "Train Epoch :  3 [ 40016,  60000] loss: 0.093 TrnAcc: 0.895\n",
      "Train Epoch :  3 [ 48016,  60000] loss: 0.093 TrnAcc: 0.896\n",
      "Train Epoch :  3 [ 56016,  60000] loss: 0.091 TrnAcc: 0.897\n",
      "Test | Size :  10000  | ValAcc: 0.978\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [3] \u001b[0m\n",
      "Train Epoch :  4 [    16,  60000] loss: 0.000 TrnAcc: 0.938\n",
      "Train Epoch :  4 [  8016,  60000] loss: 0.088 TrnAcc: 0.904\n",
      "Train Epoch :  4 [ 16016,  60000] loss: 0.086 TrnAcc: 0.906\n",
      "Train Epoch :  4 [ 24016,  60000] loss: 0.088 TrnAcc: 0.907\n",
      "Train Epoch :  4 [ 32016,  60000] loss: 0.088 TrnAcc: 0.906\n",
      "Train Epoch :  4 [ 40016,  60000] loss: 0.084 TrnAcc: 0.906\n",
      "Train Epoch :  4 [ 48016,  60000] loss: 0.082 TrnAcc: 0.906\n",
      "Train Epoch :  4 [ 56016,  60000] loss: 0.084 TrnAcc: 0.907\n",
      "Test | Size :  10000  | ValAcc: 0.981\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [4] \u001b[0m\n",
      "Train Epoch :  5 [    16,  60000] loss: 0.000 TrnAcc: 0.938\n",
      "Train Epoch :  5 [  8016,  60000] loss: 0.084 TrnAcc: 0.905\n",
      "Train Epoch :  5 [ 16016,  60000] loss: 0.083 TrnAcc: 0.909\n",
      "Train Epoch :  5 [ 24016,  60000] loss: 0.079 TrnAcc: 0.910\n",
      "Train Epoch :  5 [ 32016,  60000] loss: 0.082 TrnAcc: 0.911\n",
      "Train Epoch :  5 [ 40016,  60000] loss: 0.078 TrnAcc: 0.911\n",
      "Train Epoch :  5 [ 48016,  60000] loss: 0.080 TrnAcc: 0.912\n",
      "Train Epoch :  5 [ 56016,  60000] loss: 0.074 TrnAcc: 0.913\n",
      "Test | Size :  10000  | ValAcc: 0.982\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [5] \u001b[0m\n",
      "Train Epoch :  6 [    16,  60000] loss: 0.000 TrnAcc: 0.938\n",
      "Train Epoch :  6 [  8016,  60000] loss: 0.081 TrnAcc: 0.912\n",
      "Train Epoch :  6 [ 16016,  60000] loss: 0.078 TrnAcc: 0.914\n",
      "Train Epoch :  6 [ 24016,  60000] loss: 0.080 TrnAcc: 0.914\n",
      "Train Epoch :  6 [ 32016,  60000] loss: 0.075 TrnAcc: 0.916\n",
      "Train Epoch :  6 [ 40016,  60000] loss: 0.076 TrnAcc: 0.916\n",
      "Train Epoch :  6 [ 48016,  60000] loss: 0.077 TrnAcc: 0.916\n",
      "Train Epoch :  6 [ 56016,  60000] loss: 0.068 TrnAcc: 0.918\n",
      "Test | Size :  10000  | ValAcc: 0.982\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [6] \u001b[0m\n",
      "Train Epoch :  7 [    16,  60000] loss: 0.000 TrnAcc: 0.812\n",
      "Train Epoch :  7 [  8016,  60000] loss: 0.065 TrnAcc: 0.932\n",
      "Train Epoch :  7 [ 16016,  60000] loss: 0.071 TrnAcc: 0.926\n",
      "Train Epoch :  7 [ 24016,  60000] loss: 0.071 TrnAcc: 0.925\n",
      "Train Epoch :  7 [ 32016,  60000] loss: 0.073 TrnAcc: 0.924\n",
      "Train Epoch :  7 [ 40016,  60000] loss: 0.071 TrnAcc: 0.924\n",
      "Train Epoch :  7 [ 48016,  60000] loss: 0.069 TrnAcc: 0.924\n",
      "Train Epoch :  7 [ 56016,  60000] loss: 0.062 TrnAcc: 0.925\n",
      "Test | Size :  10000  | ValAcc: 0.984\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [7] \u001b[0m\n",
      "Train Epoch :  8 [    16,  60000] loss: 0.000 TrnAcc: 0.875\n",
      "Train Epoch :  8 [  8016,  60000] loss: 0.072 TrnAcc: 0.921\n",
      "Train Epoch :  8 [ 16016,  60000] loss: 0.066 TrnAcc: 0.925\n",
      "Train Epoch :  8 [ 24016,  60000] loss: 0.069 TrnAcc: 0.926\n",
      "Train Epoch :  8 [ 32016,  60000] loss: 0.065 TrnAcc: 0.927\n",
      "Train Epoch :  8 [ 40016,  60000] loss: 0.065 TrnAcc: 0.927\n",
      "Train Epoch :  8 [ 48016,  60000] loss: 0.066 TrnAcc: 0.928\n",
      "Train Epoch :  8 [ 56016,  60000] loss: 0.070 TrnAcc: 0.927\n",
      "Test | Size :  10000  | ValAcc: 0.985\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [8] \u001b[0m\n",
      "Train Epoch :  9 [    16,  60000] loss: 0.000 TrnAcc: 0.938\n",
      "Train Epoch :  9 [  8016,  60000] loss: 0.066 TrnAcc: 0.929\n",
      "Train Epoch :  9 [ 16016,  60000] loss: 0.066 TrnAcc: 0.929\n",
      "Train Epoch :  9 [ 24016,  60000] loss: 0.065 TrnAcc: 0.928\n",
      "Train Epoch :  9 [ 32016,  60000] loss: 0.060 TrnAcc: 0.929\n",
      "Train Epoch :  9 [ 40016,  60000] loss: 0.066 TrnAcc: 0.930\n",
      "Train Epoch :  9 [ 48016,  60000] loss: 0.063 TrnAcc: 0.930\n",
      "Train Epoch :  9 [ 56016,  60000] loss: 0.066 TrnAcc: 0.930\n",
      "Test | Size :  10000  | ValAcc: 0.984\n",
      "\n",
      "Train Epoch : 10 [    16,  60000] loss: 0.000 TrnAcc: 1.000\n",
      "Train Epoch : 10 [  8016,  60000] loss: 0.060 TrnAcc: 0.935\n",
      "Train Epoch : 10 [ 16016,  60000] loss: 0.064 TrnAcc: 0.933\n",
      "Train Epoch : 10 [ 24016,  60000] loss: 0.067 TrnAcc: 0.932\n",
      "Train Epoch : 10 [ 32016,  60000] loss: 0.061 TrnAcc: 0.932\n",
      "Train Epoch : 10 [ 40016,  60000] loss: 0.063 TrnAcc: 0.932\n",
      "Train Epoch : 10 [ 48016,  60000] loss: 0.061 TrnAcc: 0.932\n",
      "Train Epoch : 10 [ 56016,  60000] loss: 0.059 TrnAcc: 0.933\n",
      "Test | Size :  10000  | ValAcc: 0.985\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [10] \u001b[0m\n",
      "Train Epoch : 11 [    16,  60000] loss: 0.000 TrnAcc: 0.938\n",
      "Train Epoch : 11 [  8016,  60000] loss: 0.056 TrnAcc: 0.942\n",
      "Train Epoch : 11 [ 16016,  60000] loss: 0.062 TrnAcc: 0.936\n",
      "Train Epoch : 11 [ 24016,  60000] loss: 0.064 TrnAcc: 0.934\n",
      "Train Epoch : 11 [ 32016,  60000] loss: 0.060 TrnAcc: 0.935\n",
      "Train Epoch : 11 [ 40016,  60000] loss: 0.062 TrnAcc: 0.935\n",
      "Train Epoch : 11 [ 48016,  60000] loss: 0.061 TrnAcc: 0.935\n",
      "Train Epoch : 11 [ 56016,  60000] loss: 0.060 TrnAcc: 0.935\n",
      "Test | Size :  10000  | ValAcc: 0.985\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [11] \u001b[0m\n",
      "Train Epoch : 12 [    16,  60000] loss: 0.000 TrnAcc: 1.000\n",
      "Train Epoch : 12 [  8016,  60000] loss: 0.053 TrnAcc: 0.942\n",
      "Train Epoch : 12 [ 16016,  60000] loss: 0.055 TrnAcc: 0.941\n",
      "Train Epoch : 12 [ 24016,  60000] loss: 0.061 TrnAcc: 0.940\n",
      "Train Epoch : 12 [ 32016,  60000] loss: 0.052 TrnAcc: 0.940\n",
      "Train Epoch : 12 [ 40016,  60000] loss: 0.055 TrnAcc: 0.941\n",
      "Train Epoch : 12 [ 48016,  60000] loss: 0.058 TrnAcc: 0.940\n",
      "Train Epoch : 12 [ 56016,  60000] loss: 0.055 TrnAcc: 0.941\n",
      "Test | Size :  10000  | ValAcc: 0.985\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [12] \u001b[0m\n",
      "Train Epoch : 13 [    16,  60000] loss: 0.000 TrnAcc: 1.000\n",
      "Train Epoch : 13 [  8016,  60000] loss: 0.051 TrnAcc: 0.943\n",
      "Train Epoch : 13 [ 16016,  60000] loss: 0.058 TrnAcc: 0.941\n",
      "Train Epoch : 13 [ 24016,  60000] loss: 0.056 TrnAcc: 0.941\n",
      "Train Epoch : 13 [ 32016,  60000] loss: 0.056 TrnAcc: 0.940\n",
      "Train Epoch : 13 [ 40016,  60000] loss: 0.055 TrnAcc: 0.941\n",
      "Train Epoch : 13 [ 48016,  60000] loss: 0.056 TrnAcc: 0.941\n",
      "Train Epoch : 13 [ 56016,  60000] loss: 0.057 TrnAcc: 0.941\n",
      "Test | Size :  10000  | ValAcc: 0.985\n",
      "\n",
      "Train Epoch : 14 [    16,  60000] loss: 0.000 TrnAcc: 0.875\n",
      "Train Epoch : 14 [  8016,  60000] loss: 0.050 TrnAcc: 0.946\n",
      "Train Epoch : 14 [ 16016,  60000] loss: 0.053 TrnAcc: 0.945\n",
      "Train Epoch : 14 [ 24016,  60000] loss: 0.055 TrnAcc: 0.944\n",
      "Train Epoch : 14 [ 32016,  60000] loss: 0.051 TrnAcc: 0.944\n",
      "Train Epoch : 14 [ 40016,  60000] loss: 0.061 TrnAcc: 0.942\n",
      "Train Epoch : 14 [ 48016,  60000] loss: 0.053 TrnAcc: 0.943\n",
      "Train Epoch : 14 [ 56016,  60000] loss: 0.059 TrnAcc: 0.943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | Size :  10000  | ValAcc: 0.984\n",
      "\n",
      "Train Epoch : 15 [    16,  60000] loss: 0.000 TrnAcc: 1.000\n",
      "Train Epoch : 15 [  8016,  60000] loss: 0.055 TrnAcc: 0.942\n",
      "Train Epoch : 15 [ 16016,  60000] loss: 0.050 TrnAcc: 0.943\n",
      "Train Epoch : 15 [ 24016,  60000] loss: 0.054 TrnAcc: 0.943\n",
      "Train Epoch : 15 [ 32016,  60000] loss: 0.052 TrnAcc: 0.943\n",
      "Train Epoch : 15 [ 40016,  60000] loss: 0.054 TrnAcc: 0.942\n",
      "Train Epoch : 15 [ 48016,  60000] loss: 0.050 TrnAcc: 0.943\n",
      "Train Epoch : 15 [ 56016,  60000] loss: 0.054 TrnAcc: 0.944\n",
      "Test | Size :  10000  | ValAcc: 0.986\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [15] \u001b[0m\n",
      "Train Epoch : 16 [    16,  60000] loss: 0.000 TrnAcc: 1.000\n",
      "Train Epoch : 16 [  8016,  60000] loss: 0.051 TrnAcc: 0.944\n",
      "Train Epoch : 16 [ 16016,  60000] loss: 0.053 TrnAcc: 0.944\n",
      "Train Epoch : 16 [ 24016,  60000] loss: 0.049 TrnAcc: 0.945\n",
      "Train Epoch : 16 [ 32016,  60000] loss: 0.053 TrnAcc: 0.944\n",
      "Train Epoch : 16 [ 40016,  60000] loss: 0.056 TrnAcc: 0.944\n",
      "Train Epoch : 16 [ 48016,  60000] loss: 0.055 TrnAcc: 0.943\n",
      "Train Epoch : 16 [ 56016,  60000] loss: 0.046 TrnAcc: 0.944\n",
      "Test | Size :  10000  | ValAcc: 0.987\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [16] \u001b[0m\n",
      "Train Epoch : 17 [    16,  60000] loss: 0.000 TrnAcc: 1.000\n",
      "Train Epoch : 17 [  8016,  60000] loss: 0.048 TrnAcc: 0.947\n",
      "Train Epoch : 17 [ 16016,  60000] loss: 0.052 TrnAcc: 0.945\n",
      "Train Epoch : 17 [ 24016,  60000] loss: 0.050 TrnAcc: 0.945\n",
      "Train Epoch : 17 [ 32016,  60000] loss: 0.051 TrnAcc: 0.945\n",
      "Train Epoch : 17 [ 40016,  60000] loss: 0.048 TrnAcc: 0.945\n",
      "Train Epoch : 17 [ 48016,  60000] loss: 0.051 TrnAcc: 0.945\n",
      "Train Epoch : 17 [ 56016,  60000] loss: 0.051 TrnAcc: 0.946\n",
      "Test | Size :  10000  | ValAcc: 0.988\n",
      "\n",
      "\u001b[31m BEST EPOCH UPDATED!! [17] \u001b[0m\n",
      "Train Epoch : 18 [    16,  60000] loss: 0.000 TrnAcc: 0.938\n",
      "Train Epoch : 18 [  8016,  60000] loss: 0.053 TrnAcc: 0.943\n",
      "Train Epoch : 18 [ 16016,  60000] loss: 0.054 TrnAcc: 0.942\n",
      "Train Epoch : 18 [ 24016,  60000] loss: 0.047 TrnAcc: 0.945\n",
      "Train Epoch : 18 [ 32016,  60000] loss: 0.048 TrnAcc: 0.945\n",
      "Train Epoch : 18 [ 40016,  60000] loss: 0.051 TrnAcc: 0.945\n",
      "Train Epoch : 18 [ 48016,  60000] loss: 0.049 TrnAcc: 0.945\n",
      "Train Epoch : 18 [ 56016,  60000] loss: 0.048 TrnAcc: 0.946\n",
      "Test | Size :  10000  | ValAcc: 0.987\n",
      "\n",
      "Train Epoch : 19 [    16,  60000] loss: 0.000 TrnAcc: 1.000\n",
      "Train Epoch : 19 [  8016,  60000] loss: 0.049 TrnAcc: 0.946\n",
      "Train Epoch : 19 [ 16016,  60000] loss: 0.049 TrnAcc: 0.948\n",
      "Train Epoch : 19 [ 24016,  60000] loss: 0.047 TrnAcc: 0.949\n",
      "Train Epoch : 19 [ 32016,  60000] loss: 0.048 TrnAcc: 0.949\n",
      "Train Epoch : 19 [ 40016,  60000] loss: 0.050 TrnAcc: 0.949\n",
      "Train Epoch : 19 [ 48016,  60000] loss: 0.052 TrnAcc: 0.948\n",
      "Train Epoch : 19 [ 56016,  60000] loss: 0.054 TrnAcc: 0.948\n",
      "Test | Size :  10000  | ValAcc: 0.986\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "test() # Show initial performance\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    train(epoch)\n",
    "    val_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        # Save model\n",
    "        torch.save(net.module.state_dict(), './results/model.pth')\n",
    "        torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "        print (\"\\x1b[31m BEST EPOCH UPDATED!! [%d] \\x1b[0m\" % (best_epoch))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "module.conv1.weight \t torch.Size([16, 1, 3, 3])\n",
      "module.conv1.bias \t torch.Size([16])\n",
      "module.b1.weight \t torch.Size([16])\n",
      "module.b1.bias \t torch.Size([16])\n",
      "module.b1.running_mean \t torch.Size([16])\n",
      "module.b1.running_var \t torch.Size([16])\n",
      "module.b1.num_batches_tracked \t torch.Size([])\n",
      "module.conv2.weight \t torch.Size([32, 16, 3, 3])\n",
      "module.conv2.bias \t torch.Size([32])\n",
      "module.b2.weight \t torch.Size([32])\n",
      "module.b2.bias \t torch.Size([32])\n",
      "module.b2.running_mean \t torch.Size([32])\n",
      "module.b2.running_var \t torch.Size([32])\n",
      "module.b2.num_batches_tracked \t torch.Size([])\n",
      "module.conv3.weight \t torch.Size([64, 32, 3, 3])\n",
      "module.conv3.bias \t torch.Size([64])\n",
      "module.b3.weight \t torch.Size([64])\n",
      "module.b3.bias \t torch.Size([64])\n",
      "module.b3.running_mean \t torch.Size([64])\n",
      "module.b3.running_var \t torch.Size([64])\n",
      "module.b3.num_batches_tracked \t torch.Size([])\n",
      "module.fc1.weight \t torch.Size([256, 64])\n",
      "module.fc1.bias \t torch.Size([256])\n",
      "module.bf1.weight \t torch.Size([256])\n",
      "module.bf1.bias \t torch.Size([256])\n",
      "module.bf1.running_mean \t torch.Size([256])\n",
      "module.bf1.running_var \t torch.Size([256])\n",
      "module.bf1.num_batches_tracked \t torch.Size([])\n",
      "module.fc2.weight \t torch.Size([128, 256])\n",
      "module.fc2.bias \t torch.Size([128])\n",
      "module.bf2.weight \t torch.Size([128])\n",
      "module.bf2.bias \t torch.Size([128])\n",
      "module.bf2.running_mean \t torch.Size([128])\n",
      "module.bf2.running_var \t torch.Size([128])\n",
      "module.bf2.num_batches_tracked \t torch.Size([])\n",
      "module.fc3.weight \t torch.Size([10, 128])\n",
      "module.fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {139996222079840: {'momentum_buffer': tensor([[[[-6.3967e-03,  1.7631e-02, -9.8743e-02],\n",
      "          [-6.4545e-02, -1.3599e-02, -4.1100e-02],\n",
      "          [-1.3580e-01, -6.7913e-02,  5.5964e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.7733e-02, -5.0893e-03,  2.4242e-03],\n",
      "          [-3.4480e-02,  4.9378e-03, -1.1845e-02],\n",
      "          [-3.0210e-02,  3.0202e-02,  4.5257e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.2730e-03, -1.1304e-02, -9.5130e-03],\n",
      "          [-1.5830e-02, -1.9715e-02, -1.5069e-02],\n",
      "          [-1.0786e-02, -1.4275e-02, -1.0988e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4457e-01,  8.5060e-02, -2.4670e-02],\n",
      "          [ 1.3015e-01,  2.6988e-02, -4.3934e-02],\n",
      "          [ 1.3433e-01,  2.6210e-03,  1.6452e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4941e-01,  8.7032e-02,  2.1357e-02],\n",
      "          [ 8.0582e-02,  1.8434e-02,  2.2431e-02],\n",
      "          [-7.1949e-02, -1.2392e-01, -1.3693e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3696e-01,  6.9225e-02,  1.0392e-01],\n",
      "          [ 5.9264e-02, -3.2784e-03,  1.8359e-01],\n",
      "          [-3.4640e-02, -7.7859e-02,  3.5198e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3145e-02,  5.4957e-02, -3.4920e-02],\n",
      "          [ 1.6690e-01,  5.4802e-02, -1.1444e-01],\n",
      "          [-4.5485e-02, -6.2820e-02, -1.6854e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2017e-02, -1.9216e-02, -2.0568e-01],\n",
      "          [ 2.2523e-02, -4.7027e-02, -1.1848e-01],\n",
      "          [ 8.3794e-02, -2.9993e-02, -1.2852e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6400e-01, -8.3849e-02, -1.5848e-02],\n",
      "          [-1.7416e-01, -1.6019e-01, -8.7295e-02],\n",
      "          [-1.8152e-01, -1.1682e-01, -9.0447e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4689e-01,  6.5973e-02,  4.9369e-02],\n",
      "          [ 1.9999e-01,  4.8971e-02,  6.0121e-02],\n",
      "          [ 2.3588e-01,  2.3425e-02, -2.1583e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2797e-02,  1.8986e-03,  1.4630e-02],\n",
      "          [-2.3445e-02, -1.4066e-02,  1.0614e-03],\n",
      "          [-2.7096e-02, -6.3884e-02, -2.8760e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.6965e-02, -1.5426e-01, -5.3138e-02],\n",
      "          [-6.5825e-02, -4.1814e-02,  1.1307e-02],\n",
      "          [-1.2399e-01, -3.5696e-02, -1.7575e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4778e-02,  9.6698e-02, -3.5860e-02],\n",
      "          [ 4.0737e-02,  9.8001e-02,  4.3843e-02],\n",
      "          [ 2.1126e-02,  1.5937e-03,  8.6550e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0733e-01,  2.5021e-01,  1.1837e-01],\n",
      "          [ 2.8184e-01,  1.7963e-01,  9.2121e-02],\n",
      "          [ 2.1109e-01,  1.1498e-01,  8.5310e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1486e-02,  2.4732e-01,  1.7412e-01],\n",
      "          [ 7.7610e-02,  1.9707e-01,  2.0518e-01],\n",
      "          [ 4.4298e-02,  1.1948e-01,  1.1998e-01]]]], device='cuda:0')}, 139994194521904: {'momentum_buffer': tensor([-3.2681e-08, -2.6996e-08, -7.1880e-09, -4.2862e-09, -8.4166e-08,\n",
      "         1.3034e-08,  1.8915e-09,  3.1405e-08, -5.3416e-08, -5.4668e-08,\n",
      "         3.0685e-08,  3.0511e-08, -5.9027e-08,  2.7447e-08, -5.6052e-45,\n",
      "         2.2862e-08], device='cuda:0')}, 139994194521976: {'momentum_buffer': tensor([-1.2183e-01, -1.4886e-02, -7.9471e-03,  1.4223e-02, -3.8049e-01,\n",
      "        -1.1904e-01,  1.3566e-01, -1.2879e-01, -4.6490e-02,  9.1473e-02,\n",
      "        -7.9004e-02, -3.0132e-02,  1.4559e-01,  1.5199e-01,  5.6052e-45,\n",
      "         1.9283e-01], device='cuda:0')}, 139994194522048: {'momentum_buffer': tensor([-4.2244e-02, -6.6923e-02,  4.3263e-03, -9.4831e-04, -4.8567e-03,\n",
      "         9.4871e-02,  1.9422e-04, -2.7951e-02, -5.2360e-02,  6.9505e-02,\n",
      "         1.7883e-04, -1.5977e-02,  6.7731e-03,  3.2886e-02,  5.6052e-45,\n",
      "         8.6247e-02], device='cuda:0')}, 139994194538784: {'momentum_buffer': tensor([[[[ 3.4030e-02,  8.1957e-02, -5.9580e-03],\n",
      "          [ 1.1733e-02,  7.8516e-03, -3.2192e-02],\n",
      "          [-2.0852e-02, -5.8474e-02, -3.8548e-02]],\n",
      "\n",
      "         [[-6.0028e-02, -3.7840e-02,  2.3656e-02],\n",
      "          [-2.7662e-02, -1.5314e-02, -3.7369e-02],\n",
      "          [ 2.1210e-02,  2.2815e-02, -3.7376e-02]],\n",
      "\n",
      "         [[ 9.0130e-03,  9.4746e-03, -5.1871e-03],\n",
      "          [ 2.0208e-02,  6.9770e-03, -1.1082e-02],\n",
      "          [ 7.7271e-03,  6.2790e-03,  4.6240e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3142e-03,  2.4625e-02, -1.6328e-02],\n",
      "          [ 8.9426e-02,  4.3288e-02, -3.7744e-02],\n",
      "          [ 5.1788e-02,  4.6147e-02,  4.5256e-02]],\n",
      "\n",
      "         [[ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[ 3.5511e-02, -5.2816e-02, -7.9847e-02],\n",
      "          [-3.8402e-02, -4.8312e-02,  5.0809e-02],\n",
      "          [ 1.2579e-03, -5.8498e-02,  2.8024e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0181e-02, -8.0268e-02, -6.5765e-02],\n",
      "          [-2.0792e-02, -6.3317e-02, -5.9669e-02],\n",
      "          [-7.3882e-03, -1.4993e-03,  4.4403e-02]],\n",
      "\n",
      "         [[ 1.0334e-02, -1.0603e-03, -8.9287e-02],\n",
      "          [-1.9727e-02, -1.7720e-02, -4.2803e-02],\n",
      "          [ 4.0337e-03, -2.1764e-03, -5.8830e-02]],\n",
      "\n",
      "         [[-9.8946e-03, -1.8758e-02, -2.0882e-02],\n",
      "          [ 5.4217e-04,  1.3806e-02,  1.4554e-02],\n",
      "          [ 7.3402e-05,  1.0288e-02,  1.2125e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7815e-02, -5.9172e-02, -1.0472e-01],\n",
      "          [ 1.1090e-02,  5.5557e-02,  2.2661e-02],\n",
      "          [ 1.0729e-02,  2.7539e-02,  3.6529e-02]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45, -5.6052e-45, -5.6052e-45]],\n",
      "\n",
      "         [[-4.0300e-02,  2.9081e-02,  1.3425e-01],\n",
      "          [-1.8415e-02,  4.5546e-02,  4.1391e-02],\n",
      "          [ 1.8339e-02,  4.6579e-02,  5.9504e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8183e-02, -3.8195e-03, -1.7842e-02],\n",
      "          [ 9.6580e-03,  2.0282e-02,  3.1437e-02],\n",
      "          [ 1.0853e-02,  7.8744e-03,  5.8249e-02]],\n",
      "\n",
      "         [[-4.3048e-02,  3.0990e-03,  3.4464e-02],\n",
      "          [-2.0337e-02, -6.6890e-03, -1.0663e-02],\n",
      "          [-1.1338e-02, -3.4006e-02, -5.1226e-02]],\n",
      "\n",
      "         [[-2.4450e-02, -2.2278e-02, -9.3218e-03],\n",
      "          [-3.8359e-03, -3.4148e-03, -2.6216e-03],\n",
      "          [ 7.9657e-04,  2.5409e-03, -1.0759e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.6696e-02, -8.6919e-02, -1.8473e-02],\n",
      "          [-2.5267e-02, -2.1852e-02, -1.3063e-02],\n",
      "          [ 1.5914e-03, -4.6016e-03, -4.6470e-02]],\n",
      "\n",
      "         [[-5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 4.2781e-02,  1.9191e-02,  4.0965e-02],\n",
      "          [ 1.2136e-02,  1.9390e-02,  6.6557e-02],\n",
      "          [ 1.3121e-03,  4.5400e-02,  6.7595e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7451e-02, -2.6801e-02, -4.7136e-03],\n",
      "          [-2.6689e-02, -2.1489e-02, -2.1821e-02],\n",
      "          [-1.7054e-02, -5.1304e-03, -2.9185e-02]],\n",
      "\n",
      "         [[ 1.6331e-02,  1.0137e-02,  3.2702e-02],\n",
      "          [-9.0507e-03,  9.4511e-04,  1.8768e-02],\n",
      "          [-1.8694e-02,  1.9231e-03,  5.7869e-03]],\n",
      "\n",
      "         [[ 1.2660e-03, -6.6851e-04, -1.2270e-02],\n",
      "          [-1.7504e-02, -1.6052e-02, -1.6669e-02],\n",
      "          [-2.9230e-03, -2.6312e-03, -1.0161e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8632e-02,  7.6384e-03, -3.2253e-02],\n",
      "          [-7.2396e-02, -6.2929e-02, -7.4013e-02],\n",
      "          [-5.6206e-03, -2.5829e-02, -4.0672e-02]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-4.8810e-02, -3.8225e-02, -9.5409e-02],\n",
      "          [-7.3621e-03, -6.0315e-03, -2.8630e-02],\n",
      "          [-1.9812e-04,  2.8552e-03, -4.1637e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1815e-02,  8.8382e-04,  3.9646e-02],\n",
      "          [ 2.6914e-02,  2.9296e-02, -3.8373e-02],\n",
      "          [ 6.7175e-03,  4.6195e-02, -4.0974e-02]],\n",
      "\n",
      "         [[ 3.4141e-02,  1.4057e-02,  1.4301e-02],\n",
      "          [ 5.3276e-03,  3.3779e-02,  9.0244e-03],\n",
      "          [-1.3182e-02, -1.0851e-02, -3.8381e-03]],\n",
      "\n",
      "         [[-2.1208e-02,  2.0523e-03,  2.0315e-03],\n",
      "          [-2.0768e-02, -1.4067e-02, -2.7337e-03],\n",
      "          [-1.2626e-02, -2.6228e-03,  2.7747e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.2271e-02, -4.9332e-03,  2.6183e-02],\n",
      "          [-1.1359e-01, -6.3810e-02, -9.6653e-03],\n",
      "          [-7.3534e-02, -2.9876e-02,  1.7322e-02]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [ 5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[-1.2530e-02, -5.5721e-02, -4.4056e-02],\n",
      "          [-1.3126e-02,  1.2127e-02, -8.8935e-03],\n",
      "          [ 2.0260e-02,  4.6139e-02,  1.6202e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1572e-02, -1.7805e-02,  8.2214e-03],\n",
      "          [-2.4898e-02,  8.8346e-03,  4.5342e-02],\n",
      "          [-2.1368e-02,  7.6713e-03,  1.6762e-02]],\n",
      "\n",
      "         [[ 2.1608e-02, -1.4322e-03, -1.3062e-02],\n",
      "          [-4.8381e-03, -4.4544e-03,  6.0965e-03],\n",
      "          [ 2.7699e-02, -2.4297e-02, -1.2449e-02]],\n",
      "\n",
      "         [[-1.0616e-02, -5.2191e-03,  1.1901e-04],\n",
      "          [ 4.6334e-04,  1.3875e-03, -4.4237e-03],\n",
      "          [ 8.8017e-03,  9.1733e-03,  9.1058e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2062e-02, -4.9723e-03, -6.0147e-03],\n",
      "          [ 1.4301e-02,  8.0314e-03, -4.3366e-02],\n",
      "          [ 4.2942e-02,  3.1792e-02,  2.4573e-02]],\n",
      "\n",
      "         [[-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "          [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "          [-5.6052e-45,  5.6052e-45,  5.6052e-45]],\n",
      "\n",
      "         [[ 2.2676e-02,  4.4986e-02,  2.4554e-02],\n",
      "          [-1.3540e-02,  2.1019e-02,  3.8282e-02],\n",
      "          [ 9.1512e-03,  6.4175e-02,  5.8092e-02]]]], device='cuda:0')}, 139994194538856: {'momentum_buffer': tensor([-5.8389e-10, -6.8962e-09, -5.6021e-09, -1.1671e-08,  1.6178e-09,\n",
      "        -3.7544e-09,  3.0265e-08,  1.6739e-09, -4.9301e-09,  1.0642e-09,\n",
      "        -1.6376e-09, -4.6203e-10,  1.7826e-08,  7.7979e-09, -1.3828e-08,\n",
      "         9.8464e-09,  1.4960e-08, -2.2433e-09,  9.1634e-09,  1.1081e-08,\n",
      "         2.6958e-09, -7.2166e-09, -6.2914e-09,  4.3487e-09,  6.9087e-09,\n",
      "        -4.1421e-10, -1.4630e-08, -1.5395e-08,  1.7678e-08, -5.1337e-09,\n",
      "         3.3960e-09,  6.9922e-09], device='cuda:0')}, 139994194538928: {'momentum_buffer': tensor([-0.0866, -0.0155,  0.0218, -0.1173,  0.1074,  0.0294,  0.1371, -0.0534,\n",
      "         0.0249, -0.0664,  0.0303, -0.0577,  0.1009, -0.0222, -0.0610, -0.2116,\n",
      "        -0.0226, -0.0360,  0.0600,  0.0073, -0.0692, -0.0498,  0.0647, -0.0308,\n",
      "         0.2556, -0.0026, -0.0126, -0.1992,  0.1840, -0.0601,  0.0005, -0.0042],\n",
      "       device='cuda:0')}, 139994194539000: {'momentum_buffer': tensor([-0.0226,  0.0132,  0.0289, -0.0543,  0.0109,  0.0013,  0.0400,  0.0066,\n",
      "        -0.0743, -0.0909,  0.0645, -0.0485,  0.0790, -0.0463, -0.0988, -0.0122,\n",
      "         0.0334,  0.1114,  0.0425, -0.0062, -0.0060, -0.0344,  0.0503, -0.0633,\n",
      "         0.0644,  0.0405, -0.0199, -0.1477,  0.0768, -0.0648,  0.0763,  0.0385],\n",
      "       device='cuda:0')}, 139994194539288: {'momentum_buffer': tensor([[[[ 2.1984e-02,  3.4748e-02, -1.2051e-02],\n",
      "          [ 1.8751e-02, -2.6614e-02, -4.3360e-02],\n",
      "          [ 1.0303e-02, -1.2225e-02,  1.1854e-03]],\n",
      "\n",
      "         [[-1.6024e-02, -1.3541e-02,  1.2386e-02],\n",
      "          [-4.9766e-02, -4.4907e-02, -8.2530e-03],\n",
      "          [ 3.4688e-02, -2.7278e-02, -3.6286e-02]],\n",
      "\n",
      "         [[-2.2070e-02, -4.1535e-02, -3.3475e-02],\n",
      "          [-1.3373e-02,  3.3713e-02,  4.5600e-02],\n",
      "          [-1.8163e-02, -1.0979e-02, -1.2996e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5538e-03, -3.1586e-03,  4.7919e-02],\n",
      "          [-1.0503e-02,  2.0126e-02,  3.6971e-02],\n",
      "          [-1.5897e-02, -2.2151e-02, -2.0924e-02]],\n",
      "\n",
      "         [[-9.6388e-03, -3.9597e-02, -4.1439e-02],\n",
      "          [-1.1074e-03,  6.3940e-04,  2.0512e-02],\n",
      "          [-2.6605e-02,  1.3128e-02,  7.8092e-03]],\n",
      "\n",
      "         [[-1.3999e-02,  1.3944e-02, -1.0692e-02],\n",
      "          [ 1.5568e-02,  3.7577e-02, -2.8580e-02],\n",
      "          [-4.5276e-03,  1.5999e-03, -1.4869e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5634e-03,  1.3951e-02,  7.5882e-03],\n",
      "          [ 1.9744e-03,  5.2491e-03, -3.3393e-02],\n",
      "          [-1.0981e-02, -2.1761e-02, -3.2947e-02]],\n",
      "\n",
      "         [[ 4.9898e-02,  6.0431e-02,  5.8948e-02],\n",
      "          [-3.8639e-02, -1.6360e-02,  2.5467e-02],\n",
      "          [ 1.7330e-03, -3.2698e-02, -1.8798e-02]],\n",
      "\n",
      "         [[ 3.0583e-03, -2.6769e-03,  2.3793e-02],\n",
      "          [ 1.8320e-03, -9.0251e-03,  2.3140e-03],\n",
      "          [ 2.4446e-02,  3.3500e-02,  2.7817e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4457e-02,  2.4335e-03,  2.2324e-02],\n",
      "          [ 3.8872e-03,  3.2618e-02,  6.7224e-02],\n",
      "          [-4.0989e-02, -7.5012e-04, -8.1552e-03]],\n",
      "\n",
      "         [[-1.1012e-02,  7.2908e-03, -2.7050e-02],\n",
      "          [ 1.7291e-02, -2.4881e-02, -4.9672e-02],\n",
      "          [ 4.2520e-03,  4.5015e-04,  1.9442e-02]],\n",
      "\n",
      "         [[ 1.5597e-03, -8.9639e-03,  2.4594e-02],\n",
      "          [ 1.1120e-02, -6.9789e-04,  6.2548e-03],\n",
      "          [ 1.7811e-02, -3.5123e-03, -1.0226e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5723e-03,  3.1837e-02,  1.0874e-02],\n",
      "          [-1.7549e-03, -2.9550e-02, -2.0650e-02],\n",
      "          [-2.1192e-02, -4.9665e-02, -3.5119e-02]],\n",
      "\n",
      "         [[ 4.7198e-02,  2.0392e-02,  2.5914e-02],\n",
      "          [-3.2695e-02,  8.8371e-03,  1.9983e-02],\n",
      "          [ 3.5062e-02,  5.0582e-02,  1.4946e-02]],\n",
      "\n",
      "         [[ 9.4352e-03,  4.7711e-02,  2.1620e-02],\n",
      "          [ 8.3708e-03, -1.2542e-03,  2.6763e-02],\n",
      "          [ 2.2922e-02,  1.0815e-02,  1.8631e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6827e-02, -5.0758e-03,  1.5559e-03],\n",
      "          [ 2.5310e-02,  1.1662e-02,  4.5986e-02],\n",
      "          [ 2.1421e-02,  2.4731e-02,  1.2649e-02]],\n",
      "\n",
      "         [[ 2.2612e-02, -2.0321e-02,  1.1233e-02],\n",
      "          [-2.5294e-02, -2.0747e-02,  8.9644e-03],\n",
      "          [-1.9883e-02, -3.1493e-02, -1.1934e-02]],\n",
      "\n",
      "         [[-8.8114e-03, -2.6529e-02, -2.6658e-02],\n",
      "          [ 2.1836e-02,  4.7202e-02,  3.2660e-02],\n",
      "          [-5.6650e-03, -2.2654e-02, -1.6695e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.6412e-02,  4.4962e-02,  1.9796e-02],\n",
      "          [ 9.7524e-03, -1.2556e-02,  2.1676e-02],\n",
      "          [ 2.5421e-05, -7.8561e-03,  3.4437e-02]],\n",
      "\n",
      "         [[ 1.4642e-02,  6.1304e-02,  2.4828e-02],\n",
      "          [ 3.9069e-03, -3.1376e-02, -4.0060e-02],\n",
      "          [ 4.3293e-02,  6.7196e-02,  4.1842e-02]],\n",
      "\n",
      "         [[-2.0312e-02,  1.1850e-02, -1.7068e-02],\n",
      "          [-3.1626e-02, -6.9456e-03, -3.5307e-02],\n",
      "          [-8.7815e-03,  1.4572e-02,  4.1432e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8126e-02, -3.5796e-03, -4.0024e-07],\n",
      "          [ 2.9575e-02,  1.8246e-02,  2.3301e-02],\n",
      "          [ 1.3679e-02, -1.4550e-02, -1.4232e-02]],\n",
      "\n",
      "         [[ 1.8369e-02,  7.6436e-03,  1.3503e-02],\n",
      "          [ 2.8962e-03, -3.2441e-03,  1.3834e-02],\n",
      "          [-7.8825e-03, -3.6386e-03,  4.1565e-02]],\n",
      "\n",
      "         [[-1.6075e-03,  2.6455e-02,  6.2143e-04],\n",
      "          [ 4.0961e-02,  3.2587e-02,  1.9717e-02],\n",
      "          [-1.1225e-02,  6.9654e-03, -3.5653e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2526e-02,  2.8501e-02,  3.0984e-02],\n",
      "          [ 9.4284e-03,  1.9547e-02, -8.8873e-03],\n",
      "          [-3.0428e-02, -6.6160e-03, -1.9784e-02]],\n",
      "\n",
      "         [[-7.9763e-03, -3.1948e-02, -6.8034e-03],\n",
      "          [ 3.8705e-02, -5.2611e-03, -4.3584e-02],\n",
      "          [-8.8411e-03,  8.0691e-03, -2.3335e-02]],\n",
      "\n",
      "         [[ 1.8096e-02, -4.8893e-03,  2.5346e-02],\n",
      "          [-2.1420e-02, -4.2732e-02, -1.5952e-02],\n",
      "          [ 1.7161e-02, -1.1417e-02, -4.8381e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5564e-03, -2.3753e-02, -1.3233e-02],\n",
      "          [ 9.9872e-03,  4.8574e-03,  1.1399e-02],\n",
      "          [ 2.4374e-02,  9.2175e-03, -6.3375e-03]],\n",
      "\n",
      "         [[ 8.8445e-03,  4.8004e-03, -2.0694e-02],\n",
      "          [-1.4506e-02, -1.9221e-02, -8.7270e-03],\n",
      "          [-2.0640e-02, -2.3102e-02,  2.4157e-02]],\n",
      "\n",
      "         [[ 5.2630e-03, -1.3034e-02,  6.9486e-03],\n",
      "          [ 9.0336e-03,  1.4293e-02,  1.7472e-02],\n",
      "          [-1.7022e-02, -3.0299e-02, -1.1178e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1788e-03, -4.8279e-03, -2.9715e-03],\n",
      "          [ 1.7553e-03,  1.3511e-02,  9.2011e-03],\n",
      "          [-7.4194e-03,  2.4420e-03,  1.3693e-03]],\n",
      "\n",
      "         [[ 6.4383e-03,  5.1738e-03,  2.2050e-03],\n",
      "          [ 4.4207e-03,  1.6293e-02,  4.7510e-03],\n",
      "          [ 9.0410e-04,  1.9645e-02,  8.2421e-03]],\n",
      "\n",
      "         [[-1.6075e-03,  2.9563e-03,  2.6883e-03],\n",
      "          [-3.2453e-03,  5.3618e-03, -1.0053e-03],\n",
      "          [ 5.4265e-03, -4.0540e-03, -4.0157e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6944e-03, -4.2054e-03,  3.5110e-03],\n",
      "          [ 7.1962e-03, -3.2906e-03, -3.9420e-03],\n",
      "          [ 5.0888e-03,  1.1806e-02,  1.0628e-02]],\n",
      "\n",
      "         [[ 1.3918e-03,  1.0163e-02, -6.8146e-03],\n",
      "          [-2.6216e-04, -3.1548e-03,  9.3637e-03],\n",
      "          [ 2.3743e-03,  1.4460e-03, -2.5972e-03]],\n",
      "\n",
      "         [[-9.9227e-06, -4.3774e-03,  5.4403e-04],\n",
      "          [-7.9024e-04,  3.2299e-03,  6.7852e-03],\n",
      "          [ 8.5549e-03,  7.3662e-03,  4.5687e-03]]]], device='cuda:0')}, 139994194539360: {'momentum_buffer': tensor([ 4.9344e-09,  1.1089e-08,  6.9477e-09,  1.3415e-08, -3.1770e-10,\n",
      "        -5.7868e-10,  3.1270e-09,  2.5011e-09, -9.3356e-09,  2.7231e-09,\n",
      "        -3.5404e-09,  8.1541e-10, -1.5104e-09,  2.5654e-09, -2.5882e-09,\n",
      "         1.0942e-08,  3.4596e-09, -4.1991e-10, -1.7832e-09,  6.3576e-09,\n",
      "         2.2204e-09,  2.5418e-10, -3.7479e-08, -1.5372e-08, -6.3271e-10,\n",
      "        -3.9748e-09, -3.0038e-09,  8.7537e-09,  7.0591e-09,  1.3931e-09,\n",
      "        -1.1196e-11,  8.7008e-09,  6.4464e-09, -8.5306e-09,  3.3874e-09,\n",
      "        -2.5526e-09, -6.5644e-09, -4.7280e-09,  3.7387e-09,  1.1709e-08,\n",
      "        -3.5187e-09, -2.1015e-09, -1.3527e-09, -1.9928e-10,  2.0638e-09,\n",
      "        -4.2574e-10, -5.3103e-09, -1.9571e-09, -1.2283e-09, -1.7959e-09,\n",
      "         1.2976e-09,  5.6172e-09,  8.2133e-09, -3.4339e-09,  1.0264e-09,\n",
      "        -5.9028e-10, -1.7526e-08,  4.1575e-09, -2.5429e-09, -1.2932e-09,\n",
      "         6.6649e-09,  8.0618e-09,  3.6990e-09, -1.3990e-09], device='cuda:0')}, 139994194539432: {'momentum_buffer': tensor([-0.0230,  0.0037, -0.1346, -0.0142,  0.0757,  0.0011,  0.0761, -0.0636,\n",
      "         0.1345,  0.0164, -0.0484, -0.0338, -0.0476, -0.0410, -0.0004,  0.0371,\n",
      "        -0.0068,  0.1323,  0.1012, -0.0812,  0.0378,  0.0512, -0.0522, -0.0360,\n",
      "         0.0858, -0.0078, -0.0278, -0.0341, -0.0341,  0.0678,  0.0421,  0.1102,\n",
      "        -0.0482, -0.1158, -0.0218,  0.0481,  0.0533, -0.0013,  0.0301,  0.0273,\n",
      "        -0.0724,  0.0229,  0.0470, -0.0499,  0.1003,  0.0164, -0.0334,  0.0981,\n",
      "        -0.0503, -0.0878, -0.0503, -0.0723, -0.0611,  0.0060, -0.0043, -0.0468,\n",
      "         0.0286, -0.0263,  0.1061,  0.0237,  0.0490, -0.1207, -0.0513, -0.0409],\n",
      "       device='cuda:0')}, 139994194539504: {'momentum_buffer': tensor([-4.5055e-03,  1.2033e-02,  5.5526e-03,  2.4098e-03,  1.5382e-02,\n",
      "        -2.1708e-02,  5.1591e-04, -5.3065e-02,  7.8128e-02,  1.3209e-01,\n",
      "        -4.4185e-03, -1.9631e-02, -2.6796e-03, -2.3850e-02,  6.6809e-03,\n",
      "        -3.4164e-02, -1.8614e-02, -1.8847e-03,  7.8469e-03, -3.2212e-02,\n",
      "        -1.1160e-02,  8.0403e-03, -6.8149e-02,  3.5200e-03,  2.8860e-04,\n",
      "         2.2018e-02, -3.7889e-02, -3.6393e-03, -6.6998e-03,  4.9378e-02,\n",
      "         1.8482e-02,  1.0745e-02,  4.7906e-03,  3.1036e-02, -1.9529e-03,\n",
      "         5.6341e-03,  2.0731e-02, -1.6562e-02,  1.7524e-02,  1.4708e-03,\n",
      "        -7.0383e-09,  2.1045e-02,  2.0780e-02, -3.7413e-03,  5.3820e-02,\n",
      "        -1.8139e-02, -1.5581e-02,  4.6856e-02, -1.0186e-01, -9.1690e-03,\n",
      "        -3.0117e-03, -1.1696e-03, -1.0229e-01, -7.6617e-04, -7.1798e-03,\n",
      "        -9.4942e-03,  4.3391e-02, -4.9060e-02,  1.0897e-04, -2.3464e-02,\n",
      "        -1.5804e-03, -2.4848e-02, -6.5714e-03,  1.1929e-02], device='cuda:0')}, 139994194539792: {'momentum_buffer': tensor([[ 1.9643e-03, -2.2267e-02, -8.3020e-03,  ..., -7.8512e-03,\n",
      "         -1.8809e-03, -7.2920e-03],\n",
      "        [-4.1262e-02, -2.2359e-02, -4.2972e-02,  ..., -2.0830e-02,\n",
      "         -1.0824e-02, -8.1560e-03],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        ...,\n",
      "        [-9.2014e-03, -1.1151e-02,  2.9365e-02,  ...,  1.6186e-02,\n",
      "          5.6024e-03,  4.3236e-03],\n",
      "        [-4.3035e-03,  5.1241e-03,  1.1060e-02,  ...,  6.8387e-03,\n",
      "          1.4348e-03,  5.1052e-03],\n",
      "        [ 7.3284e-03,  2.0723e-02,  6.0792e-03,  ...,  5.1689e-03,\n",
      "         -1.2320e-02, -3.8348e-03]], device='cuda:0')}, 139994194539864: {'momentum_buffer': tensor([-9.4543e-10, -1.1813e-09, -5.6052e-45, -2.2944e-09,  3.5472e-09,\n",
      "        -3.1824e-09, -2.2746e-09,  1.5071e-09, -1.1223e-08,  2.1500e-08,\n",
      "         6.7090e-09, -4.2429e-09, -5.2277e-09, -5.8987e-10,  4.9489e-09,\n",
      "         8.4940e-09,  1.7079e-09, -4.5581e-09,  3.4440e-09,  1.1921e-09,\n",
      "         3.7235e-09, -1.0028e-09, -3.7096e-10, -3.4661e-09, -5.3939e-09,\n",
      "         6.0440e-09, -1.4869e-09, -4.5852e-10, -3.0223e-09, -6.4425e-09,\n",
      "        -3.8256e-09, -4.0249e-09,  2.7966e-09, -5.5622e-09, -1.3763e-08,\n",
      "         4.9616e-08,  5.3354e-09,  9.7613e-09, -2.6323e-09,  3.5892e-10,\n",
      "        -1.4571e-08, -9.4527e-10,  1.8820e-09, -7.1768e-09,  3.7780e-09,\n",
      "        -5.8733e-10,  3.3614e-09,  7.8565e-09,  3.3683e-08,  2.3313e-10,\n",
      "         1.3880e-08, -1.0446e-08,  7.6132e-09, -3.1179e-10,  8.7463e-10,\n",
      "         1.5332e-09,  1.0983e-08,  3.0809e-09, -2.1315e-11,  7.6936e-10,\n",
      "        -1.0033e-09,  3.7176e-09,  8.7326e-09,  6.6661e-08,  6.2802e-10,\n",
      "         5.6052e-45,  1.6133e-08, -9.0690e-09, -3.5089e-09,  1.6402e-09,\n",
      "        -2.7089e-08, -3.5197e-09, -4.0855e-09, -6.3241e-09, -4.8385e-09,\n",
      "         2.4500e-09,  1.7313e-09,  3.7010e-09,  4.1433e-10, -5.7229e-09,\n",
      "         6.5126e-10, -3.6372e-09,  1.2361e-08,  1.2367e-09, -6.4157e-10,\n",
      "        -1.6838e-09, -7.7517e-09, -1.1837e-09, -4.0441e-09, -2.4897e-09,\n",
      "         2.2399e-09,  4.0489e-09, -6.7899e-11,  1.2255e-09, -1.9221e-09,\n",
      "        -6.9794e-09, -2.3142e-08,  6.4161e-09,  1.2910e-08,  7.2136e-09,\n",
      "         2.2971e-09,  4.7485e-09, -4.1116e-09, -6.9844e-10, -5.6052e-45,\n",
      "         2.8780e-09, -7.4778e-10, -2.3820e-08,  1.7144e-08, -2.7099e-10,\n",
      "        -2.6429e-09, -1.5060e-09,  3.3570e-09,  1.6463e-08, -2.5012e-08,\n",
      "        -3.0719e-09, -2.4362e-09,  7.9481e-10, -4.9792e-09,  2.5127e-09,\n",
      "         1.8011e-10, -4.8247e-10,  7.0889e-10, -8.5776e-09, -1.7493e-09,\n",
      "         2.5107e-10, -9.3303e-09, -5.2106e-09,  2.6322e-09, -2.3130e-08,\n",
      "         6.6545e-10, -3.0246e-09, -2.9229e-09,  1.3484e-09, -5.6052e-45,\n",
      "         4.8031e-09, -1.2732e-08, -3.7777e-10, -2.4901e-08,  1.1204e-08,\n",
      "        -1.6813e-08, -2.6483e-09,  6.2720e-09, -2.6464e-09, -6.2133e-09,\n",
      "         6.7522e-09, -3.5836e-09, -4.4575e-09,  5.1364e-09, -4.8854e-09,\n",
      "         2.2184e-09, -3.6896e-09, -1.7227e-09, -6.9670e-09,  5.5510e-09,\n",
      "         2.8676e-09, -1.3663e-09,  2.8993e-09,  1.0902e-08, -7.9534e-10,\n",
      "         1.9040e-09, -2.8427e-09,  1.3379e-09, -2.7494e-09,  9.1826e-10,\n",
      "        -4.0503e-09,  2.1628e-09, -4.0326e-09, -2.4248e-09, -1.6929e-09,\n",
      "        -5.1592e-08, -5.4410e-09, -4.1485e-09,  3.4803e-09, -8.5536e-09,\n",
      "         6.3357e-09, -2.2859e-10,  1.5151e-09,  7.0994e-09, -1.3014e-08,\n",
      "         8.1379e-09,  1.2268e-08,  6.9579e-10, -1.6240e-08, -8.2969e-09,\n",
      "        -9.1465e-10, -4.1707e-10,  3.6232e-09,  2.3066e-10, -5.0812e-09,\n",
      "         2.8285e-08,  1.0101e-08,  5.6052e-45,  6.9305e-09, -3.0885e-09,\n",
      "        -1.0333e-08, -4.5275e-10,  5.0726e-09, -7.2584e-09,  9.9666e-10,\n",
      "        -1.5151e-09,  6.3419e-09, -1.2039e-08, -3.0821e-09,  2.5345e-09,\n",
      "         2.1492e-09, -1.6136e-09, -7.4347e-10, -5.6166e-08,  7.2262e-08,\n",
      "        -1.3959e-08,  4.3395e-09,  8.7877e-09, -3.9064e-09, -1.1809e-09,\n",
      "         8.1720e-10,  2.0757e-10, -3.4205e-08,  1.8141e-10,  1.2559e-09,\n",
      "        -1.2909e-09,  3.4518e-09,  7.5124e-09,  1.0610e-08, -9.2002e-09,\n",
      "         2.7705e-09,  8.4177e-10,  7.8658e-10, -8.6585e-10, -2.6544e-08,\n",
      "        -4.5412e-09,  2.5564e-09, -6.3946e-09,  2.9507e-10,  3.2432e-10,\n",
      "        -1.2061e-08, -1.3142e-08, -5.1558e-10, -2.0726e-08, -8.1517e-09,\n",
      "        -6.1319e-11,  5.0393e-09, -9.3104e-09,  8.0107e-09, -1.6847e-08,\n",
      "        -2.6121e-09, -2.1706e-08, -5.0236e-08,  1.8434e-09, -6.2865e-08,\n",
      "         6.0168e-10, -2.9141e-08, -2.2244e-09,  1.2502e-08, -6.8995e-09,\n",
      "        -1.9720e-09], device='cuda:0')}, 139994194539936: {'momentum_buffer': tensor([ 8.4878e-03, -2.5352e-02,  5.6052e-45, -2.8943e-02, -2.0456e-02,\n",
      "        -6.1167e-04,  9.4746e-03, -4.1714e-03,  4.7124e-04,  3.2818e-02,\n",
      "        -2.3025e-02,  1.6162e-02,  3.7670e-03, -3.3159e-02,  7.3817e-03,\n",
      "        -2.0668e-02, -2.7111e-03, -4.5271e-02, -1.9446e-03,  5.5810e-03,\n",
      "        -2.2634e-02,  1.2319e-02,  3.0435e-02,  5.4675e-03,  3.5037e-03,\n",
      "        -3.2549e-03,  1.2165e-02, -5.1623e-03, -3.0668e-02, -3.0914e-02,\n",
      "        -7.0279e-03,  8.7392e-03, -4.0320e-02, -9.4079e-03,  2.5688e-02,\n",
      "         4.0260e-03,  5.8556e-03, -1.0266e-03, -1.1969e-02, -2.5661e-02,\n",
      "        -4.2626e-02, -3.4258e-02,  5.2350e-03, -2.4278e-02,  1.5360e-02,\n",
      "        -9.6239e-04,  8.0449e-03, -7.8560e-04,  1.7681e-02, -2.2027e-02,\n",
      "         9.0216e-03,  6.3078e-03, -2.2752e-02, -3.1555e-02, -1.0364e-02,\n",
      "         7.9105e-03, -1.0318e-02,  1.5000e-02,  3.2682e-03,  1.0113e-02,\n",
      "         1.8389e-02,  8.0642e-03,  5.0406e-03,  1.0601e-02,  3.9252e-02,\n",
      "         5.6052e-45, -5.9745e-03, -3.9887e-03,  9.4430e-03, -1.3333e-02,\n",
      "         5.1141e-03,  1.2694e-03,  2.0920e-02,  3.0583e-02, -4.3513e-02,\n",
      "        -5.8652e-04,  1.3907e-02, -2.3732e-03, -1.5518e-02,  2.2878e-02,\n",
      "        -2.5115e-02, -1.8815e-02,  2.7985e-02,  1.9204e-03,  1.0821e-02,\n",
      "        -4.7456e-03,  2.5689e-02, -2.0185e-03, -3.7963e-03, -7.3847e-03,\n",
      "         5.1813e-03,  9.0312e-03,  2.4332e-02, -1.8419e-02, -2.6584e-02,\n",
      "        -2.9115e-02,  3.3211e-03,  4.2549e-02, -4.4095e-02, -2.5822e-03,\n",
      "         3.9933e-03,  3.0605e-02,  3.5659e-03,  1.3454e-02,  5.6052e-45,\n",
      "        -1.3291e-03,  3.3859e-02,  3.4590e-02, -1.0474e-02, -1.9064e-02,\n",
      "         9.2284e-03, -2.3070e-02, -5.7273e-03,  1.9735e-02, -6.0573e-03,\n",
      "         3.2967e-03, -2.1260e-03,  1.7040e-02,  4.4242e-02,  2.2533e-02,\n",
      "        -2.6963e-03,  4.5110e-03, -3.2277e-02, -1.0535e-02, -1.7326e-02,\n",
      "        -3.9108e-02,  1.9923e-02, -2.8343e-02,  2.5258e-03, -2.3763e-02,\n",
      "        -1.4550e-02,  4.1805e-03,  6.3186e-03, -1.9169e-03,  5.6052e-45,\n",
      "        -9.3377e-03, -1.3426e-02, -3.4057e-02, -3.0722e-02,  6.5716e-03,\n",
      "         4.7168e-02,  1.6488e-02, -1.9134e-03,  1.1724e-04,  1.3659e-02,\n",
      "        -4.1561e-02,  2.0974e-03,  2.4415e-02, -3.7405e-02, -1.4135e-02,\n",
      "        -2.5821e-02, -3.0095e-03,  2.2574e-02, -1.5308e-02,  4.9245e-03,\n",
      "        -2.3776e-02,  5.3516e-02, -2.2192e-02,  1.2855e-02,  2.4688e-02,\n",
      "        -1.0431e-02, -8.8972e-03,  2.2268e-02, -9.7264e-03, -3.7517e-02,\n",
      "        -6.6086e-03, -2.7322e-02, -1.1173e-03, -4.3779e-05, -3.5001e-02,\n",
      "        -2.7283e-02,  3.2630e-03,  2.6942e-02, -1.7230e-02,  1.3729e-02,\n",
      "        -3.2086e-04,  1.1688e-02,  3.6229e-02,  1.3888e-02,  2.0133e-02,\n",
      "         4.2675e-03,  3.6593e-02, -1.7271e-02,  9.3065e-03,  1.3129e-02,\n",
      "        -4.3141e-02, -2.8468e-02,  3.3931e-02,  1.7407e-02, -1.5103e-02,\n",
      "         7.0971e-03,  3.4349e-03,  5.6052e-45, -3.4057e-02,  2.3631e-02,\n",
      "        -3.5756e-02, -1.9805e-02,  4.0583e-02,  4.3794e-03, -1.5248e-02,\n",
      "        -1.1726e-03,  2.3187e-02, -9.5676e-03, -3.2890e-03,  2.6826e-02,\n",
      "        -2.0421e-02,  4.8199e-02,  3.1459e-02, -2.1315e-02,  3.6686e-02,\n",
      "         2.5959e-03, -1.5959e-02,  1.0304e-02, -1.9035e-02, -1.1310e-02,\n",
      "        -4.0813e-03,  1.2761e-02, -2.9231e-02,  3.6391e-02,  9.8645e-04,\n",
      "        -6.0591e-03,  9.1217e-04,  1.0597e-02,  1.7157e-02,  5.9240e-03,\n",
      "        -1.0490e-02,  3.6137e-03,  1.5837e-02, -1.5849e-02,  4.2696e-02,\n",
      "         3.1037e-02,  8.0433e-03, -3.0589e-03,  6.9052e-03, -2.1595e-02,\n",
      "         5.6122e-04, -4.2438e-02, -3.6373e-02, -1.9202e-03, -2.1948e-02,\n",
      "         7.6962e-03, -1.4504e-02,  2.0686e-02, -1.4618e-02, -4.6798e-03,\n",
      "        -9.1948e-03, -2.9903e-02,  5.5001e-02, -1.2311e-02,  2.9532e-02,\n",
      "        -4.1815e-02, -2.3027e-02, -1.6453e-02,  5.9848e-03,  1.7505e-02,\n",
      "         1.0118e-02], device='cuda:0')}, 139994194540008: {'momentum_buffer': tensor([ 2.7345e-03,  3.1000e-03,  5.6052e-45, -1.4588e-02, -4.7490e-03,\n",
      "         6.3271e-03,  9.4339e-03, -7.2113e-03, -5.1983e-03,  1.4355e-02,\n",
      "        -1.3157e-02,  1.1242e-03, -1.0152e-02, -4.0644e-02,  7.5700e-03,\n",
      "         9.6516e-03,  5.9038e-03, -2.9400e-02, -4.0813e-02,  3.4825e-04,\n",
      "        -1.4181e-02,  1.7306e-02,  1.8269e-02,  1.2479e-02,  5.2108e-03,\n",
      "        -1.2547e-02,  2.2820e-02, -1.7618e-02, -2.6826e-02, -1.3587e-02,\n",
      "         1.5191e-03,  1.7729e-02, -2.5337e-02, -2.0851e-03,  2.3939e-02,\n",
      "         1.1691e-02, -1.9504e-02, -1.5221e-02, -3.0204e-02, -1.5084e-02,\n",
      "        -2.9152e-02, -5.1745e-02,  4.6879e-03, -3.0175e-02,  1.6637e-02,\n",
      "        -1.7029e-02, -4.2330e-03,  2.3294e-02, -8.0545e-03, -2.2437e-02,\n",
      "        -4.0815e-03, -9.4297e-03, -1.6842e-02, -2.0137e-02, -1.0058e-02,\n",
      "         6.0395e-03, -1.5198e-02,  4.4713e-03, -6.5373e-03,  7.9376e-03,\n",
      "         2.1685e-02, -2.4092e-03,  6.6060e-04,  2.2105e-02,  2.5865e-02,\n",
      "         5.6052e-45,  1.6916e-03, -9.4703e-03,  1.8658e-02, -1.4860e-02,\n",
      "         7.5209e-04, -6.0751e-03,  3.1050e-02,  5.0624e-02, -3.3425e-02,\n",
      "        -4.2819e-03,  4.4944e-03, -2.2378e-03, -4.0011e-02,  3.0578e-02,\n",
      "        -3.2963e-02, -2.2211e-02,  3.2828e-02,  1.7130e-02,  9.8321e-03,\n",
      "         1.2319e-02,  7.2631e-03,  2.3071e-02, -5.2360e-03, -2.0244e-02,\n",
      "         2.2504e-03,  6.1409e-03,  3.8867e-03, -2.0355e-02, -2.0066e-02,\n",
      "        -2.5738e-03, -2.8897e-03,  4.3728e-02, -4.3096e-02,  5.5712e-03,\n",
      "         1.1820e-02,  2.5175e-03,  1.5169e-02,  1.0152e-02,  5.6052e-45,\n",
      "         1.3401e-02,  4.4360e-02,  3.1849e-02,  7.9762e-03, -3.2229e-02,\n",
      "         7.4649e-03, -2.9869e-02, -1.0039e-02,  6.9792e-03,  2.6593e-03,\n",
      "         7.5448e-03,  1.2668e-02,  2.9109e-02,  3.2319e-02,  2.5498e-02,\n",
      "        -5.7499e-03, -1.2059e-02, -3.6576e-02,  8.0957e-04,  8.8790e-03,\n",
      "        -2.9112e-02,  1.5651e-02, -3.2904e-02,  2.6418e-02, -2.0828e-02,\n",
      "        -2.0865e-02,  1.3246e-02, -8.1305e-03, -1.7565e-03,  5.6052e-45,\n",
      "        -1.6143e-02, -4.8037e-03, -2.2874e-02, -2.4553e-02,  1.0136e-03,\n",
      "         2.4629e-02, -9.0689e-04,  9.8877e-03,  6.0888e-03,  2.3909e-03,\n",
      "        -2.7365e-02, -1.5204e-02,  1.0318e-02, -1.3244e-02,  1.2819e-02,\n",
      "        -3.7320e-02, -3.2055e-03,  1.4229e-02, -1.2377e-02,  8.0400e-03,\n",
      "        -1.4081e-02,  3.9907e-02, -1.9002e-02,  9.3212e-03,  1.6529e-03,\n",
      "        -5.4218e-03, -1.4007e-02,  3.7611e-02,  3.1751e-03, -2.9199e-02,\n",
      "        -4.4477e-03, -2.9094e-02, -1.0914e-02, -1.8026e-03, -1.1315e-02,\n",
      "        -2.0991e-02, -7.1982e-03,  1.7642e-02, -1.8019e-02,  2.1266e-02,\n",
      "         4.9805e-03,  2.6686e-02,  1.5503e-02, -1.3881e-02,  1.2301e-02,\n",
      "         2.2727e-03,  4.2419e-02, -6.3729e-03,  1.8412e-02,  1.3828e-02,\n",
      "        -3.1837e-02, -3.7901e-02,  4.0885e-02,  1.9440e-02, -1.5436e-02,\n",
      "        -2.5004e-03, -2.9674e-03,  5.6052e-45, -9.4751e-03,  2.5290e-02,\n",
      "        -1.5635e-02, -2.1185e-02,  2.9195e-02,  3.9978e-02, -1.0323e-02,\n",
      "         5.5044e-03,  2.3237e-02, -7.5096e-03, -1.8144e-03,  2.8730e-02,\n",
      "        -5.9491e-04,  2.9512e-02,  3.0197e-02, -3.7959e-02,  1.0703e-02,\n",
      "         7.7370e-03, -4.1199e-02,  1.7032e-02, -1.6446e-02, -1.0534e-02,\n",
      "        -9.9564e-03,  1.2737e-02, -3.2666e-02,  2.8414e-02,  1.5172e-02,\n",
      "        -2.7434e-03,  1.6481e-03, -5.1030e-03,  1.4976e-02, -3.5475e-03,\n",
      "        -2.1213e-02,  2.9371e-03,  1.7577e-02, -1.8692e-02,  5.7295e-02,\n",
      "         3.0812e-02, -5.5394e-03, -8.6437e-03,  7.2907e-03, -3.0480e-02,\n",
      "        -7.8279e-04, -3.2076e-02, -1.0499e-02, -1.1603e-02, -2.1017e-02,\n",
      "         9.9455e-03, -5.1902e-03,  1.2722e-02, -3.2445e-02, -8.1206e-03,\n",
      "        -1.1292e-02, -2.6365e-02,  2.5457e-02,  1.2643e-03,  2.9474e-02,\n",
      "        -2.4679e-02, -1.6885e-02, -2.6076e-02,  2.0367e-02,  1.9391e-02,\n",
      "         3.9659e-03], device='cuda:0')}, 139994194540296: {'momentum_buffer': tensor([[ 5.8132e-03,  3.1236e-03,  5.6052e-45,  ..., -2.1834e-03,\n",
      "         -2.4632e-02, -1.2059e-03],\n",
      "        [ 6.6236e-03,  5.6279e-05,  5.6052e-45,  ..., -5.2432e-03,\n",
      "          6.5150e-03, -2.8873e-03],\n",
      "        [-1.7480e-04, -1.4252e-02, -5.6052e-45,  ..., -1.2013e-03,\n",
      "          1.8261e-02,  1.2972e-02],\n",
      "        ...,\n",
      "        [-5.1494e-04, -5.4482e-03,  5.6052e-45,  ..., -2.1528e-03,\n",
      "          1.9099e-03, -1.7182e-03],\n",
      "        [ 1.8868e-03, -6.0814e-03, -5.6052e-45,  ...,  4.9047e-03,\n",
      "         -1.7968e-03,  1.1206e-02],\n",
      "        [ 7.0010e-03, -2.5997e-04,  5.6052e-45,  ..., -4.0965e-03,\n",
      "         -1.7177e-03, -7.9239e-04]], device='cuda:0')}, 139994194540368: {'momentum_buffer': tensor([ 3.8867e-11,  2.0821e-09,  7.7985e-10,  2.6968e-09,  1.4569e-09,\n",
      "         2.3140e-09,  6.3996e-10, -4.5928e-10,  2.0985e-09, -3.3641e-09,\n",
      "         6.9407e-10, -5.5811e-09,  2.1099e-10,  1.4177e-09,  1.3001e-10,\n",
      "         3.2439e-10, -4.4617e-09,  1.4282e-09, -2.2214e-10, -3.3617e-09,\n",
      "         8.0096e-10,  6.6650e-10,  1.0346e-08,  1.6614e-10, -1.5407e-10,\n",
      "         7.5992e-10,  1.5211e-09,  2.2836e-09,  2.6737e-09,  2.4912e-09,\n",
      "        -4.4446e-08, -6.9163e-10,  2.6195e-10, -8.6284e-10,  1.5320e-09,\n",
      "        -2.7573e-09, -2.1328e-09,  2.1298e-10, -1.3071e-09,  1.1186e-09,\n",
      "        -1.3994e-09,  5.8294e-10,  1.0306e-10,  2.0568e-09, -6.1334e-11,\n",
      "         2.6893e-10, -2.2279e-09, -6.0636e-10, -9.1095e-10,  1.4446e-09,\n",
      "         1.5659e-09, -3.2801e-10, -3.0726e-10,  2.7936e-09,  1.3589e-11,\n",
      "         1.7810e-09,  1.4205e-09, -1.7775e-09,  5.4503e-09,  5.1355e-09,\n",
      "        -1.3987e-09,  3.5180e-09, -1.3179e-09, -5.7705e-10, -8.8623e-10,\n",
      "        -6.3059e-10, -4.1820e-09,  6.2504e-09,  3.6961e-09, -6.2939e-10,\n",
      "         2.5248e-10,  1.7027e-09,  7.7079e-10, -2.2834e-10, -6.2979e-10,\n",
      "        -2.4561e-09,  7.2524e-10,  1.3179e-09, -2.9265e-09, -2.4634e-09,\n",
      "        -5.8504e-10, -1.5576e-09, -1.1482e-09,  5.3673e-10, -7.6475e-10,\n",
      "         3.0837e-09,  2.7441e-10,  2.5204e-10,  3.2595e-10, -5.4370e-09,\n",
      "         7.6126e-10,  6.8549e-10,  2.1136e-09,  3.3420e-09, -2.7553e-09,\n",
      "        -1.9838e-09, -7.4764e-10, -1.0696e-08,  2.2240e-09, -1.9962e-09,\n",
      "         2.2022e-10,  8.8806e-10,  1.1050e-09, -1.5646e-09,  3.1459e-10,\n",
      "        -2.8095e-10, -6.1392e-10,  2.6865e-10, -1.4353e-09, -6.9526e-09,\n",
      "        -2.0116e-09, -1.4560e-10,  4.9213e-09, -1.6781e-09, -1.5824e-10,\n",
      "        -6.6879e-09, -4.2905e-09, -6.3837e-10, -1.1030e-09, -7.7762e-11,\n",
      "        -2.0245e-09, -1.0320e-09,  1.0009e-09, -6.8634e-10,  3.1095e-09,\n",
      "        -8.3201e-10,  2.4959e-09,  7.5853e-10], device='cuda:0')}, 139994194540440: {'momentum_buffer': tensor([-1.8646e-02, -1.8798e-02,  1.4148e-03, -1.5878e-03, -1.5987e-02,\n",
      "         3.3400e-03,  1.2751e-02, -6.6778e-03,  4.3436e-03, -1.0125e-02,\n",
      "         1.5852e-04, -1.4357e-02, -2.4307e-02, -4.6948e-03, -1.1881e-02,\n",
      "         2.1309e-02,  9.6775e-03,  9.6237e-03,  5.1536e-03,  6.2287e-03,\n",
      "        -2.3221e-02,  2.0278e-02,  1.5175e-02, -1.4565e-02,  4.8909e-03,\n",
      "        -4.1504e-03, -1.5506e-02,  9.6818e-03, -4.1842e-02,  8.9428e-03,\n",
      "        -1.6376e-02, -1.2905e-02, -1.0313e-02, -2.4915e-03, -7.7157e-03,\n",
      "        -1.2682e-02, -1.8355e-02,  1.0995e-02,  3.8129e-03,  1.6585e-02,\n",
      "         6.9257e-03, -3.2721e-02, -4.3333e-03,  1.5391e-02,  3.8933e-03,\n",
      "         6.2046e-03, -2.4377e-02, -1.1184e-02,  9.7877e-02, -3.3612e-03,\n",
      "         1.6812e-02, -1.3808e-02, -8.5826e-03,  1.2493e-02, -1.6245e-02,\n",
      "        -1.8115e-02, -1.8286e-02, -1.4068e-02,  2.0616e-03, -1.6495e-02,\n",
      "        -2.3981e-02,  2.8252e-02, -7.0078e-03, -6.7481e-03,  4.3202e-03,\n",
      "        -4.9895e-03,  3.3796e-03, -9.7606e-05,  1.2707e-02, -1.7267e-02,\n",
      "         7.5354e-03, -5.8149e-03,  1.8586e-02,  2.0175e-02, -1.4278e-02,\n",
      "        -3.4709e-02, -1.3602e-02, -4.3714e-02,  5.4128e-03, -2.1523e-02,\n",
      "        -2.6562e-02, -2.1833e-03, -8.6997e-03,  2.1957e-02, -3.9586e-03,\n",
      "        -1.7424e-02,  8.9129e-03, -1.3044e-02, -1.3854e-02, -7.9879e-03,\n",
      "        -1.2674e-02, -1.4063e-02, -1.7426e-02,  6.3467e-03, -1.8458e-02,\n",
      "        -6.6458e-04, -1.4761e-02, -6.0742e-03, -2.5773e-02, -1.5135e-02,\n",
      "         7.0271e-04, -2.2352e-03,  1.3122e-02,  2.0698e-02, -1.4018e-02,\n",
      "        -2.3711e-02, -3.3764e-03, -2.8050e-03, -1.0542e-02, -1.1027e-03,\n",
      "        -4.5665e-03,  1.8371e-02,  1.0754e-02,  7.2806e-03, -1.3144e-02,\n",
      "        -6.3909e-03, -1.0285e-02, -5.9885e-03, -7.8498e-03, -8.9319e-03,\n",
      "        -1.1481e-02, -9.3965e-03, -3.6502e-03, -8.0040e-03, -1.0307e-02,\n",
      "        -1.6776e-02, -4.0197e-02, -1.1696e-02], device='cuda:0')}, 139994194540512: {'momentum_buffer': tensor([ 0.0023, -0.0258, -0.0066,  0.0283,  0.0015, -0.0421,  0.0215,  0.0090,\n",
      "         0.0015, -0.0125,  0.0143, -0.0383, -0.0389,  0.0071, -0.0280,  0.0364,\n",
      "         0.0264,  0.0099,  0.0169,  0.0075, -0.0259,  0.0391, -0.0075, -0.0407,\n",
      "         0.0102, -0.0027, -0.0248, -0.0111, -0.0914,  0.0110,  0.0050,  0.0285,\n",
      "        -0.0028,  0.0095, -0.0145, -0.0402, -0.0047,  0.0149,  0.0169,  0.0049,\n",
      "        -0.0201, -0.0198, -0.0035,  0.0493,  0.0240, -0.0020, -0.0275, -0.0312,\n",
      "         0.0998,  0.0070,  0.0547,  0.0031, -0.0111, -0.0125,  0.0149, -0.0008,\n",
      "         0.0084, -0.0299, -0.0120, -0.0041, -0.0353,  0.0189, -0.0107, -0.0089,\n",
      "         0.0327,  0.0131,  0.0050, -0.0282,  0.0210, -0.0308, -0.0047,  0.0144,\n",
      "         0.0152,  0.0328, -0.0246, -0.0620, -0.0109, -0.0428,  0.0084, -0.0375,\n",
      "        -0.0405, -0.0175, -0.0069, -0.0101, -0.0012,  0.0018,  0.0070, -0.0334,\n",
      "        -0.0318,  0.0047,  0.0108, -0.0149, -0.0457,  0.0023,  0.0517,  0.0070,\n",
      "        -0.0370,  0.0072, -0.0509, -0.0171,  0.0204, -0.0140,  0.0061,  0.0185,\n",
      "        -0.0071, -0.0556, -0.0261, -0.0085, -0.0210, -0.0281,  0.0384,  0.0501,\n",
      "         0.0045, -0.0036, -0.0225, -0.0280, -0.0390, -0.0074, -0.0459, -0.0440,\n",
      "         0.0178, -0.0220,  0.0067, -0.0243, -0.0347, -0.0315, -0.0459, -0.0204],\n",
      "       device='cuda:0')}, 139994194540800: {'momentum_buffer': tensor([[-0.0233, -0.0299, -0.0284,  ..., -0.0522, -0.0714, -0.0248],\n",
      "        [-0.0087,  0.0301,  0.0012,  ...,  0.0141,  0.0199, -0.0017],\n",
      "        [ 0.0263,  0.0099,  0.0092,  ...,  0.1150,  0.0635,  0.1051],\n",
      "        ...,\n",
      "        [-0.0427,  0.0026, -0.0241,  ..., -0.1556, -0.0375, -0.0295],\n",
      "        [ 0.0042,  0.0183,  0.0005,  ...,  0.0126,  0.0214,  0.0038],\n",
      "        [-0.0069, -0.0801, -0.0002,  ...,  0.0193, -0.0435, -0.0834]],\n",
      "       device='cuda:0')}, 139994194540872: {'momentum_buffer': tensor([-0.0501,  0.0084,  0.0850,  0.0043,  0.0241,  0.0145,  0.0272, -0.1171,\n",
      "         0.0544, -0.0508], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [139996222079840, 139994194521904, 139994194521976, 139994194522048, 139994194538784, 139994194538856, 139994194538928, 139994194539000, 139994194539288, 139994194539360, 139994194539432, 139994194539504, 139994194539792, 139994194539864, 139994194539936, 139994194540008, 139994194540296, 139994194540368, 139994194540440, 139994194540512, 139994194540800, 139994194540872]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in net.state_dict():\n",
    "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Epoch :  4 [ 56016,  60000] loss: 0.051 TrnAcc: 0.940\n",
    "Test | Size :  10000  | ValAcc: 0.987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refs\n",
    "https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist\n",
    "\n",
    "https://nextjournal.com/gkoehler/pytorch-mnist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
